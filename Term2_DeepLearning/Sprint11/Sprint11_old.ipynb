{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ 畳み込みニューラルネットワーク1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.このSprintについて\n",
    "### Sprintの目的\n",
    "- スクラッチを通してCNNの基礎を理解する\n",
    "\n",
    "### どのように学ぶか\n",
    "スクラッチで1次元用畳み込みニューラルネットワークを実装した後、学習と検証を行なっていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1次元の畳み込みニューラルネットワークスクラッチ\n",
    "\n",
    "**畳み込みニューラルネットワーク（CNN）** のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "このSprintでは1次元の **畳み込み層** を作成し、畳み込みの基礎を理解することを目指します。次のSprintでは2次元畳み込み層とプーリング層を作成することで、一般的に画像に対して利用されるCNNを完成させます。\n",
    "\n",
    "クラスの名前はScratch1dCNNClassifierとしてください。クラスの構造などは前のSprintで作成したScratchDeepNeuralNetrowkClassifierを参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1次元畳み込み層とは\n",
    "CNNでは画像に対しての2次元畳み込み層が定番ですが、ここでは理解しやすくするためにまずは1次元畳み込み層を実装します。1次元畳み込みは実用上は自然言語や波形データなどの 系列データ で使われることが多いです。\n",
    "\n",
    "畳み込みは任意の次元に対して考えることができ、立体データに対しての3次元畳み込みまではフレームワークで一般的に用意されています。\n",
    "\n",
    "### データセットの用意\n",
    "検証には引き続きMNISTデータセットを使用します。1次元畳み込みでは全結合のニューラルネットワークと同様に平滑化されたものを入力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# MNISTデータ　ロード\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 適当なテストデータを作る¶\n",
    "1dCNNは多くの場合で時系列解析に用いられます。そのため、テストデータは簡単な異常検知モデルにしてみましょう。\n",
    "\n",
    "※本来、時系列の異常検知システムは逐次的に見ることが多いので、本当はこんな風にバッチごとに見るようなことは少ないです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOy9d5Qk133f+7nV1TlMT9ydzbvYRVgABECAIMAAihSTyEdKJiVbokVTsmxaspIt6elY78nm07MtKlOWZJmmTNlPMk2RkiiLAQYJkQRgBuSMTcDmMDt5pnNVV3h/3LpV1WnCTs9iZ6a+5+AMtkN1dfftb33v95eE67pEiBAhQoSNC+3VPoEIESJEiLA2REQeIUKECBscEZFHiBAhwgZHROQRIkSIsMEREXmECBEibHDor8aLjoyMuPv27Xs1XjpChAgRNiyeeuqpGdd1R9tvf1WIfN++fTz55JOvxktHiBAhwoaFEOJst9sjayVChAgRNjgiIo8QIUKEDY41E7kQIiWEeFwI8ZwQ4iUhxK/148QiRIgQIcLK0A+P3ADe5rpuRQgRB74lhPhfrus+2odjR4gQIUKEZbBmIndls5aK98+491/UwCVChAgRrhL64pELIWJCiGeBKeBB13Uf68dxI0SIECHC8ugLkbuua7uuezuwC7hbCHFL+2OEEB8VQjwphHhyenq6Hy8bIUKECBHoc9aK67oLwEPAu7vc9ynXde9yXfeu0dGOfPYIfcRTZ+c5cqn0ap9GhAgRrhL6kbUyKoQoev+fBt4OHFvrcSNcOX7tSy/xew8ef7VPI0KECFcJ/chaGQf+PyFEDHlh+Lzrul/uw3EjXCFqpk2j6bzapxEhQoSrhH5krTwP3NGHc4nQJxiWjWlHRB4hwlZBVNm5CWFaDs2IyCNE2DKIiHwTwrAcLDtK5Y8QYasgIvJNiEiRR4iwtRAR+SaEYTmRRx4hwhZCROSbDJbtYDtupMgjRNhCiIh8k0Ep8aYVeeQRImwVRES+yWBaksgtJ1LkEbYGzs/VXu1TeNUREfkmg+ERuSL0CBE2M75zcoY3/9Y3efHi4qt9Kq8qIiLfZFAE3ozSDyNsATxyYgaAk9OVZR65uRER+SaDYdkAUbAzwpbAo6dmAbi82HiVz+TVxaYj8qlyg9/56vEtay0YvkfuImd+RIiwOVExLF7wLJWJiMg3F755bIo/+uYrPHJia/Y8N0IXsMheibCZ8eSZOWzHRYhIkW86Ii/VLQAePDL5Kp9Jdzx2apa3/e5D1ExrXY5vthD51tyVRNgaePTUHPGY4M49g0yUIiLfVCg1mgB8/dgktnPtKdLnLixwarrKZMlYl+MbEZFH2CJ49NQst+0qcmA0y+XF+qt9Oq8qNh+R1yWRz1RMnj0//yqfTSfma/L8qsb6K/KoTD/CZoXyx+85MMz2gTRTZWNLC5dNR+SL9SbD2QS6JvjaNWivLNRMQC7E9YDKWgGiDogRNi2UP37PgWHGB1K4LkyX12eXuxGw6Yi81LAYL6a458DwNemTz1evniLfygolwuaG8sdfu7fI9oEUsLUzVzYfkdebFFJx3nF4G6emq+tSKPCJB0/wh19/+YqeO7/uijwi8gibH8ofzyR0xj0i38qZK5uPyBuSyN9+eBuwPtkrDx6Z5EvPX7qi5y74Hrm9zCOvDC0eedQ4K8ImRNgfBxgvpAGY2MIBz81H5HWLgXScncU0N+8orAuRlxpNzs/Vr6jgRiny9Uo/DHvkkSKPsBnx9Nl5bMfl9QeGACikddLxWKTINxMW600KaTlT+h2Ht/H0ufm+B0FK9Sb1ps1MxVzV81zX9RX5elkrYUUedUCMsBkxV5W/u12DGQCEEIwPpLZ0LvmmInLTcqg3bQqpOAB37BnEdeHsbLVvr+E4LmWPhM+tsn1mzQym269XsNOIrJUImxxq15nQA/raVkhFinyzoOwVAxXSkshT3hfdz74rZcNCOSqr7YOsbBWAylXwyCNrJcJmhFrjiVhAX+MDEZFvGpQaUuUqayUZjwGtKnXNr+EVHMHqiVzZKnB1FHlE5BE2I9QaT8YD+to+kGKy1Lgmq7mvBjYXkXskO+Ap8qSnyMMBwDW/RiMg49VaK2FFHhF5hAhXBqOHIrccl9nK1iwK2lREvugRufLIAyLvpyKXBBzTxBUQuTy/4WziqlR2Rt0PI2xGKGslqYcVuUpB3Jr2yqYi8lKbR+5bK83+Ebm6WBwczV2BtSIV+c7BNNV17H4Y0wQQKfIImxOG5ZCIaQgh/NvGt3h155qJXAixWwjxTSHEUSHES0KIn+/HiV0JlFruVOT9t1Zu3llgotRYVSBVlefvLKbXrSDIsByyCXkBi4g8wmaEaTktahzwy/S3ahfEfihyC/hF13VvAu4BfloIcbgPx101FMl2euT9D3beunMA14WLCytfOPM1k3xSZyAdX9c88rx3ITMjayXCJoRh2S2phwBDmQSJmLZlc8nXTOSu6064rvu09/9l4Ciwc63HvRKU6k3iMUHKi2Yn9XXIWmlYCAE3jReA1QU8F2omxWycbFJfx2CnTTbpKfItOu4uwuaGaTkdRK5pgm0DyS2bgthXj1wIsQ+4A3isy30fFUI8KYR4cnp6fcawLXoNs5R3Fo8JhACj2Udrpd4kl9TZN5wFVkfk87Umg5kE2aROzbRx1iFVyrQcckmZfhlVdkZYKxzH5a+fuoB1Ddl0pt1prYDsuRIR+RohhMgBfw38C9d1S+33u677Kdd173Jd967R0dF+vWwLSg3LD3R650RS1/purRRSccbySRK6xoXVKvJMgpynmGt9vMAoGJZD1iPyKGslwlrx5Nl5fvEvn+O73rT6awFGs1ORg/TJL0fWypVDCBFHkvhnXNf9Qj+OeSWQJKu33JbUY322VpoMpONommDXYLpVkU88By/9z57Pna81KabjPtGuh71iWg7ZhO7/f4QIa4HqU7ReVuCVQCryWMft4wMpJhYbV9TMbqOjH1krAvg0cNR13d9b+yldOUqNZosiBzxF3k9rxfIrR/cMZVqJ/Lv/Eb7yiz2fO18zGczEfetjPQKehuWQimvomoiyViKsGXNeymyjjym8a0W3YCdIRW5ajl+vsZXQD0X+RuDDwNuEEM96/72nD8ddNUr1LkQe1/qaR676nYMk8pZc8sYi1Oegizdt2Q7lhkUxk/AV83op8qQeIx7TsLZouXKE/mHO6/BZXwcb8ErRLf0QwrnkWy8FsR9ZK99yXVe4rvsa13Vv9/67vx8nt1os1i2fZBX6bq2ELha7BzOUGhaLSgE0FsF1oLHQ8bwFL21xMBNYK+ujyKVaicfEiq2VFy8u8lsPHFuX4GuEjY15X5FfHSL/22cv8k//7MklH9MtawVkB0TYmpOCNl1lp7I9FPptrajMGIDdQ7Ifsm+vNLwYb3Wm43mqqnMwm/DTA9ejKEiplXhMW7G18pUXJvjjh07ylRcm+n4+ETY2ZqtXV5E/fnqOB49M+j3Hu0FVdrZjMJMAgurrrYRNQ+SNpo1pOV0UeZ+yVl5+EOvC01RN2y842tNB5Ivyb60zwq98u6KXfgjrY60YnlpZDZFXvK6Rv/u145GvHqEFc1UZ7LxaHrm6YByb6Eh882Fajt9+I4y8l+hQioj82sa//fIR3vSb3+h6X3tVp0JSj63dI2/W4S9/DPdrHwOCNrm7h2SjnvPz7UTeqcjnPYWxnsFO23GxHFd65LpYcfph1bDQBJyZrfEXT5zv6zlF2NiY89pKXC1rpW7K1zmyBJH3UuSqorncuHYybK4WNhSR65pgqsfYNnUV7hrsXKu18vLXwKygTT4PuL7qz6fiDGbiUpE7Nphl+fiu1oryyNdPkfsN91epyMuGxaGxPK/bN8gffP3ldZsnGmHjIVDkV4fIax6RH50o93yMYTktvcgVErpGKq75E7y2EjYUkRfScUzL6bqoFv2GWd088lUocrsJ7XmoL8rU+JixwG4x1XKx8DNXjJCC6GqtSEVezMTJeNvCqtnfH0e4vWdcWzmRVw2LfErnX33fjUyXDf7rt8/09bwibEy4rus3eqv3ea32gnqdY5eXUuR2V0UOUlxF1so1DmWbLHTJE21vYauwqqwV14X/cBs89PHgNqMMJ74Ku14HwK3idMvFYvdQhrOztSDQCV2JfKHeRNcEuaSOpgmyidiaFflMxWjZbYRnGa7GWqkYFtmkzp17h3j7Tdv45EMnr5oCi3DtomJY/ozZxlUqLqs15W/i5clKTyHSK/0QpE8eWSvXOIoZSdLdotKltqESCkldW3mvlWYNShfhW78P82flbccfAKsOb/tVHBHnVu00A5ngNfYNZ7kwX6NZDaUcdiNyrzxf9YFZa+OsqXKDt/7OQ/ynh076txlhRb6aYKdhkfMuTu84PEbZsPxshQhbF+HMkaupyHVNYNoOp2c6h6a7rtuz1wrI3394itdWwYYi8kCRd5KMmtfZEeyMr8JaUaraNuAb/1b+/0tfgPwO2HcfC/mD3CJOt1ws9g5ncFyYmQ01Auvikc9XmwyGLgC5pL6mYOcnHjxBuWG15MwabR75SvPIKw2LnFekpAJGW3F7GqEVYSLvZwrvUqibNod3yM6iR7sEPJu2i+vSNY8cpCIvRYr82kYx3TtPVBFPfi29VlTWycgN8MJfwslvwMsPwi0fAE1jMnsjt2qt1sr+EdkFcWZmSt6Q29Y9a6Vm+nmusDZFfvxymc952SXhi0HgkcdIrKKyM6zIC1s48h+hFYrIs4nYVVPktabNzTsGSMS0rpkryurp1msF5PotR4r82oZS272IPKlrpNryS1dVEKSI/K2/ApkR+Nw/AqcJN38AgPOp6ymKKtnaBf8pe712tgtzHnkPHYDaXMehF2pN3xoCyCRiV1wQ9O/vP0ouqbNnKNNyMVDvM6lr6LGV9VqxHZeaafuZNCq1MlLkERSR7yimaVwlRV4zbQppnYNjOY51yVxRNmkvRV5IRx75NY+BpTzyLg2zQF65m7aL3aZOp0pduqSpzJPCLknmZhmKe2HnawE4FT8EgJh4zn/KSC5BNhGjsuj54kMHulsrbYr8Sq2Vh09M88iJaX7uew+xo5jqochXbq2o2aH5ZJu1sgVVTYRWtBD5VSgIsh0X03LIxHVuHM93tVYCRR5lrYSxoYg8n9QRopcitzpSDwE/3zRMatNlgzf8xjf4+tGp1gcrRZ4agNd+BPbfB/f8FHgBypfZjUUMLj3jP0UIwd7hLPXyvLxhcL8MjppBoMZ1XanIs8GFJpvUVz2A2XVdPn7/UfYMZfjwvXu9i0E4ayXwyBMrDHYqRe8rcu8z3IqqJkIr5momCV1jOJu4KtaKqupMJzQOjxeYKhvMVlrrRlRxX0+PPKljWM6Wa+G8oYhc0wQD6XjP9MP2QCd0H8A8XTawHLczKq6aXaUGIBaHj3xJErmHOUPjbGwvTDzb8rR9Ixms2gLEs5DfJm8MZa7UTBvTdqQiXzgHz/3FFaUfGpbDsctlfujOXST1WIfP3loQtLL0Q1WerzzyKNgZQWGuYjKcTZBKxK5KsFMVoqUTuj9K8djlVntFKfLe1oqK8fRev3/+3TNd1f5GxoYicpA+eTdFvtilhS0EQRGzNAX/+T6YO03dy1XtSLFTWSupQtfXLjUsziWvh0vPthQN7R3OIhqLuKkB6a0DVGd8O0cVAx00XoJPvRX+5p+x172wamtFKe50Qr6ndiI3QsHOeExb0XgudQ7KWtnK1XFbGbbj8spUpeW2uaq0A9PxqxPsVK+Rice4cXse6MxcCQf0u8Hvt9JjR+m6Lr/2pSP85ZMXOu77g6+/zGcfP3dlJ/8qY8MReTEd91vChlEKdSUMQylyd+qYnOBz8Sm/DLh920ZjEWIJ0FNdX3ux3mQie6NU7gtn/dv3D2fJUqMZz0FmGID7H3uRN/zG1zk3W2Oh1uT92nd466M/Aa587Z32BRpNZ1WzEMMeOHT67KYdBIL0mIa5EkXeZq2Al4sbKfIthS8/f4l3fuJhLi4EvbznaibDuQSpuEbDctZ98o76XWYSMYZzScbyyY5S/XDRWzcE/Va6r9+mLfsRVYzO+//mmYt85fm1dwC9vNjg3335yFWdc7rhiLzQQ5HLeZ29PXK77l3Za7MBkbcrcqMEyYLviXe8Rr3JXOGw/MelwF7ZO5yhQJW6loOsVOQvnz7DZMngx//b49Rf+CJ/kPgjqqO3w0cfAmCbKdMHu87tnDwCv38rXGjty9y+rcwmpB/YtB14/E8oTnxbvmddI7HCrBWl6HMhIt+q1XFbGSenqzhua9fBsCK3HXfdZ8Cq36Xacd44XuhQ5Ia1dLBzuRiPUv3ddsPlhrVk+9yV4pvHp/gv3zrNmdmVz/NdKzYckQ+kO9Wi67qU6r08crko7IZ3Za/N+l9mp7WyKP3xHig1mlQHbwBNb/HJ941kyYs6FTK+Iq/OT/LmQyOcn6tz6tEvUnIzTH3/Z2FwH+S2MWLILVyHT26Z8IWPSi/9xb9uuSvsgUPga1frDfjar7L/7F/596+0slMt+DCRF9JbszpuK2PCU+Ivh+yVuarJUDbhp/SudwqiaguR8YrTbtqe55WpSkvGmWEtE+xcJsajWgB0I/pyo+nboGuB+k1fzeZzG47Ii5l4R2VnvWljOe6S1ooTIvIlrZUeRG5YNo2mQzaThdGb4PIL/n1j+SQDosa8k4bUAI7QGaDEP33zAX7rB1/DbvsCr7g7GMhL34+R6ynWzgBdiPyhj8PkC5AflwVJIfhEHpM/rJw3oKJx+ThYDRLGvP+e4/oyRF6fh5mXA0WeCivyyFrZapjwKoSVT25acjThcJjI23zyB16c6OsQB1+Re683nEtg2k7LUIt2e7Ed+WUUuXqN9vtNy8GwHOaq5potJKX212MCWC9sOCJXwc7wWLLFHi1sIeSRNwJrRS2Mjm1Uo9Qz0Km++EI6DoN7YfGif58QgqJWZ7qZAiGo6QOMiDJ37h3kB+7YyW3pKaaSe4MS/eGD5CtnAFrSBzn3GHz79+GOD8O9Pw3Tx2AxCMq0K3Lla7uXZF57sjnn3y8Vudt7UT7yO/Cn76biKW81tQjk9jSyVrYWLi22KvL50EQrn8hDueSzFYOf/O9P84WnvfV58ptQ7ewxtBoEWSsx76/ecjuswFpJL10H0ctaUYLGsJw1T0NSmWDrMQGsFzYckRfTCRwXKqEvt+S3sO1C5KrS0/S2jLVZ6qba+tit0fglFPliuClXfjuUQ0ER1yXnVpkwZMHPrJNjX7ohibaxSNac4d1vuQ9dtd4cOUTcXGCQkr+AFhcWmPnzH8Mp7IZ3fxyu+1752JAqDwczISBybVLuDpKmTJ9MxDTimvT5e5bpL56H2gxWbZ5ETGvJAshv0cZDWxWu63LJs1ZOTlVwXdcXOcPZBGldrqUwwanfw3TZgGYD/vsH4dE/XtN51EPBTgiUecMMLiDtu9J2KIuwV9aKeg+VtvvDwmW+S3rzalA1I2tlWfhl+qEPO2hh2yXYqa7chrJW5vztFcBsNWSvLEHkymoYSMel7dFYkJODAKwGOhYX6wlKjSaXmll2Jr0c9ZmX5d+R64ODDcsK0evEJV8ZvPydLzDSvMTzt/8bSOZh7KYOe8X3B2NB1gpAcuZFANLWAgldIIQg7r3vnvaKp57i5fMtahzk57gVGw9tVSzUmjSaDvtHslQMi8mSEVR1Ns/w7i/ewU3ibEtrY6U256omVCZlNlYok+tKUGsjcvVX+doQsla6DJYAiHmtontlrdR6KPJyKItlfo0BT7XLjqyVJdCtTL+FZNugiFyEFHkLkVdCX5rKWumCkm+t6JJgAcqX5V+vInTBSfPl5yaYdQsM4V04Zk7Iv2EiH5FEfkCb8BW5dv5Ram6S0/k75WOEgOveJresjjzfjmBnUgdcsnNHQMSIuTYjuvQ64x7ZN60eitxr7JWuXmzxx0HuOnoN8Iiw+aBslfsOeRlXU2WfyHde/iYx2+AW7XSLIlckNauIHGBhbWMCg8rOWMvf8O/VTz/sMVgClrYG1W68Ylgt9mz48WvNXPGDnZG10hvdGmf5inwJa0Vregq5Nks9dKX0Fbllyn7kqaJ/328+cIyvviTJutRurUBgr3hEXnIzfO6JcyyQJ215VaLTx0GLy2wVheIe3FiSAyIg8uHZp3nGOchc0JVWEnljwU917JZHvkvMEG+WYNddAIzF5AUrEZPb4abTS5FLIs/WL5FLtn5uBb+oIrJXtgIuLchF9+ZDo4AMeCoyK1z+DgC7xEybIpfrdq5qBoJmsbPIZjWomzaaCEhaTdIK25/LKXJYOlhfM23epT3BLjHVYs9WWqyVtSryKNi5LFQHwXCZvvr/pYKdmpqnaZs4Rpm4R3S+IlcNszxrpWk7fOqRU/z6/UdxHLd1ApGvyBWRy+eWyfDchUXihTFEfR5sS1orw9dBLKR6tRju4H7PWrGhUWKXeZIn3RtYDC+iA28FBJz8OtAljzypc7M4E3osjMXkBctX5N2sFceBugyMDhiX/OwXhaDMObJXtgImFuvsZJo3vPI7jKRkwHO2apIUJvFLTwCws53IzRCRK0VeviRHJV4haqZNJqH7w1eUIq+3KPJWe7EblqqDqBlN/ij+B/yj2IMt5B0m3b4p8sgj741uinxisUFS11oGNygoItetoK9KrDHLjmIaCOWS+w2zpLVyfq6G7bicna3xrVdmOoOd0GGt1LUcAMNjHtHX52HmuG+lhCFGr+c6T5E3zjxGDIcnnBtaq1azw7Djdt8nN9sWcTYZ47B2BgdNNvgCRjR5wdKXslbq8+DKYw2Zl1tyyCFU5hylIG4+HLsfPvejLS0mLi00+PvxR8g8/Sl+eOBFXpmqMF81eUvqFMJq4Go6u8R0S9ZKxehC5K4DpUtXfGr1puWTN4Q98lZFHtNEkDjQBYV0vMXzDsOpzRMXNgWqLeQd9tTXHOz0FXlkrfREt+ES5+dq7BxM+1fyMFQ2RsyqyvJ7IG7MM5JLktS14Oob7nwIfkMtTcCfP3qWUt0iEZN9SEgPQiwZKHJDPjdfHAJg547d8vbyJZg7LQdVtEGMHGK3mKJuNFg8/giWq/GMc7BzEV33Njj/ODQWOzzypB7jVu0ss+m9MLALgGEhrRW14zC7KXJ/8IVgxJ5sKc+HaLjEpsbph+Hol2A2GBE4sVjn3rj893uchzjpWSv3xY+ApmPsexs7mWnxyP1sq3oTp3Q5OP4a7BWpyAMiV+mH9Zb0Q5vDsYuyb1J9oeMY4E0Jqndfu8JrZpcXtZb1rXoLpeOxvgU71zqTdzXYcESeissWrQv14MO+MF9n92Cm6+PjMYEQELeqsrc4kDAWyCRijOSSzKiiIGWteMFOReQ/fPcevn50kuOXSxTS3rZPCC8FsVWRF4dGiccE+/fu8U7sCRnNDwc6FYYPERc2qfI5xLnvcsTdSyJT6Bxjd933ymOc/t9dO7/drJ3hUuqQX1E6JKQiTyxlrah+6aM3sM2ZJN/DWok88k0IVU9x9tv+TZfnK9zinoBYghsrjyGq05ycrnC3+wLsvBN39Ca2izkMI8jwCqvN5uIEJORulMUrD3jWTNtPOYTAI6+1eeR3xE7JvkkqI6wN0lrpvnaFJ2Ly1NsUuYWuCcYHUsyt0SPfsNaKEOJPhRBTQogX+3G8ZV5LlpCHFPmF+Rq7BtM9H5/UNRJWVRbyAKnmAul4jKFsoqciPzVTZTAT56fech0u8M3j063B1MKOEJHLH8cH33CYX/m+m0gVxuTtZ78r/452IXLPbhksv8Lg/PM8w43csnOgs0Xvjjvk35njHYqc6gzbmONM/CAkspjEGRLyXJRHbnXrj6EU+Y7XkqXBiNbazne56rgIGxhKsJz9jn9Tcv5lMm4N7v0ZNNfm/bHvcGlykoPNl2H/W9CH9hIXNlo1UN5htemWJ4N1ukIiv7hQ50xbG+lG026xVnyPPGyt2A6DmtfDpD7f9dhy3JvVtRhObyhFXm8h+0rDIp/SGcwm1qTIbccNctU3oCL/b8C7+3SsZSHL9OWXUDEs5mtNdg91V+QAyZhGwq76mSNpa97rsJYIgp3t1sp0lf0jWXYPZXjbDZKY8+FgargoqLEIms69N+zmH79pv984i3MekQ93euQMHwTgtsW/I+4YXCzczkgu2bLTACCRkVZO6VJnoMebVPRK7AAIQUkbYMD1iNwj+67WiqfInR1y8tE4rQM2ChukJ7ntuJycriz/wAgB1Dr3iNx2XPbVvHYTd34Ec+w2PhD739wtjqLhwAFJ5ADJSuB/hwOFWnVS/rYyIytOQfylzz/Hv/x8a1//dmslqWsI0RbsbDoUlfCod45UBJm1YoUINYx4Qz4nR73lPZQbTXIpncFMYk3BzjB5165C61+FvhC567qPAN0/1XVAuCf5hXl5de6lyAHyuk0MW2abaDoZa5F0Qm9T5K29yE/PVNk/IreLP3rvXv91g4OOB4rcKMkLgPLoPZuD0kUo7IRkrvOk0kUWtEHuqEuyN3a8rufQDAo7oXSpI9jJ5ecBOIY8v0VRoKiI3Kvs7GqteDNFayOvAWDMnmy5O5OIEdPENW+tfPWly7zzE4909syJ0BuKyBfPwcI5ZioGt4sT1JIjUNyL/toPcYt2hh+PPUBTS8Ku1yGK0ipM1YK2FBXTQgjQcIjXZ6SwKe5ekSI3LJvh8w9w9/xXWm6X1koQrxFCkInHWvPIbYcB4SnyLrNxYekdZcKUKj4vai2kWzEs8sk4Q9nO3+Cnv3Waj/3tysyGqtE9E2a9cdU8ciHER4UQTwohnpyenl7TsYohwjs/J4sZennkAINx74eeLEBmmLyz2OKRu67rLXABiTxVw+JyqcGBUTlY+S2HRrluNNt6schvl2X/Rlk+N1xIFItD0qsQ7eaPe5hM7EbH5rSzjR0791HMyC1hRx/jwg4oXcS0HXRNoHkkzcRzTMe2MdWU731R5Ck4rYq8O5HPQLJAOSsvAMNWK5ELITZEK9vZqontuF3700foAaMEY14r5rPf4eJCnbvEcSqjd4IQaLf+IBYx3hh7icniHaAn/UB6rh4o8qphsWMgzTAlBA7ktsnHrSDY+fy5WT82ETAAACAASURBVD6m/Sn/0vxUCxnXTatFkYMMeNbaFHlBEXkPRb7UlKCUInLagp0NSyrybIK5WmvjrAdenOCLz60sG0cReSYR25wFQa7rfsp13btc171rdHT0yg5y5G/hG/9u1Yq8GFNEnsfNDFNwSmQS0iM3LIeqaXvl+QXQNM7Myq3b/hFJ5Jom+NufeRMfe9/h4KDh6s5upf1ZT5UvQeSzSal0nnBu5IbteX84c0dHucIOX5G3tO+ceJ6LqYNBKphbIO9IxbVkHnl1BjLDlEWWRTfDoNm5SGXk/9omyKa3Q4kqUFeBRgl2v16u17PfZm7iHHu0adzdd8v7syMczd0LwMJ2+ZdEhjkGyNWD/kJVw2JnMc2o5mWO5LbBwB5prSzTPXDy6a8wKhZJiSb2U3/m395urYCc39lo88gLLO2RK0W+2CVzRRXqZYVBtRHs5MoNOfN3MJPAtJyWi8f5uTrzteaKgpfqtziWT0ZZKz1x5tvw2KcYyATBzvNzdT9w2QtFTRF5Dic1xKAok07EGPaeM1cxvfL81tRDReQgqyhbxkuFqzu7dU1U9kqXHHKFhew+AJ5wb+CG7Xm/2KkjBbGwE6rT2GYjIHLLhPnTzGSuC/pekCdnKyJX1kqPYGd2hIphcd4dI9/oJHIVMLqWoS5SV2PC+0bGH33jZX7gP35bEqxRgnQR9rxB+uQXHgMge92b/Mef3fdDWK5Gfe/b/dsmtTEKZhDsrBg2hbTOgaQXo1DWilXvaXkobDv118y6eZ5wrocnPu23oKi3BTsBMnG9tfth0yaHqtLuoch9a6VTiGStIGWxWVsMvR+LXFJnyBNTynI1LJvJsqx8vRSantQL6rc4VkhRNbsHXNcDG4vIk3kwSgykdMqGtCAuzNfYPdQ9h1yhoDX851vpIYYok4nLYCfATNVoUdWnp+VC2Tec7Xo8IFDkpYnuilzN7hztzCFXuDx4FxPuEM/E72B7IUXRV+RtwZbCDgBSjanAH188D65DJbM7KJd28qSdCtjNZRT5LGRGqDQsLrijZGrdifxa98jVezMiRb4kTk1XOX65LJu8OZZcq3vfALOvMHbxQQw3TnbfHf7jB257L3can2TowO3+bTOxMQbNVkWeTersTXoV08paAem/94BdmeW26ne5X9zHp633ECudgxNfBWRQM5x+CDJzpSX90HbIuUsHO5eqg8jbAZHb9YDI/WCnJ+5Umf7F+bq/wbi4EO6f0R1KkW8vpHDcqycy+pV++Fngu8ANQogLQoif6MdxO5AqAC4jCUkwpYbF+fk6u5bwxwEGFJEn8jQTgwyKMpmEznA2CXiKPEzkM1V2DKQ61EELwoo8pOZ9rMBaqQzdwr3GH1Hctk/2NE93th8AfCLPGpOBIp8/DUAjv4eKd+WfdrzBFbW5pYm8NgPZYaqGxQV3hGTlQsd2eCN45Gom6XpPrtnoqDdt6k0bo+oRX7IAe98IwM1zf8cJ/RBCT/qPf9PBEb70f76P60aDIP1sfDtD1pRs70BA5Lv0MJF7hXBLZK5MfuczJITF5f0f4EHnTszsODz+KUzLwXLcDmslk4h19FrJOt4uoKe10pvIC06JuiYFmuONf3RdVwY7UzLYCcGu+Px8oMIvzq9EkQfWCly9gGe/slZ+xHXdcdd1467r7nJd99P9OG4HvIDisBe8XKiZUpEv4Y8D5H1FnsNIFClSIR3HV+SzVaPFHjk1U2X/6BJqHOTuIJHv7ZFvuxWGrpMLvAdUReX13sTwJa0VIGtMBUQ+J4m8WdiL60p/cdr2fni1mcBaaS/Rd13PIx+hbEhFrln1oEhIvWSXkXrXGja1tWKZ8IlbO8b9XQn8vOZFj8hTAzD+GohnieFwJnNry+OFEOwZbhVH8/FtJGhCVSYqyCwPne3aAmWyEE+Bl92yVMAz8cJnecnZy+E73ohNjAsHfhhOfRNj4hgQVHMqpOOxljRCw3LIKEVeW9oj79hRui5FFplL7vQOVvaP2bRdckndj1OpXHIVg4MVWiueDbStIAe4X62ioI1nrQBDMUnM5+Zk5Hk5RZ4TgbXSiA8SEy4Fqr4in60Gitx1XU5NV1r88Z7Ib5cWh1np9Mjv+Un42ad6DnKGYFTbDdsUkctF1FHd6dk4eSNkrcyfkW0CvJ1BxbCYchSRz/qP68gjN0rgNKVH3rA473qB54XW7XA+de33JFfpmMZmVOS1WWlRHLt/7YfyFG2tFFLksTjseT0As4O393qqj1LSsxIXzmHZcixaNqkzIhaYZlDelx6EeKZ3CuLkS4yUj/C1xNs5vEP+Xo7u/HsQS6A99ScAXYKdrYrcbjZJO0tnraj02Q6P3CiTwGIxJS0g4RVH+dO/UgGRK4/8/FydeExWfF5cAZH7wc7CBlTkVw2e6lVWyUuX5BexeyikyCePwH99DxhBoUgO7wtI5Kjp8hgFZ5F0IkYmEZNFQYYk8vlak1LD8nPIl0R+e1Am3G0gxRIkDvjtY6/3iDyf1NFEF2slVYBEnkJzKhiUMX8GBveR87aRc1WTOVdZK7Ohys42IlfKOzPiWSuKyFuHAhRScSqG1TL49lrDplbkDc/LvfD42g/lKdpGxVOwnuiw9t2H4eoY469b9hjllEfki+f8gF42qTPkzDHpFGRvbyGkvbLQ3SN3n/kMTXRm97/ftxGn7ALc+F6SJ2ROeTdrJeyR65Zn5WRGpICyOot3eqXPut7aL2fkziHmdURVZJtL6RTScTQReOTn52vsLKbZPZhZEZFXDYuYJvzki6tVFLSxiNxT5AVNfqAvXZLBihZFfu67so/EbNCHIRsi8mpMEm7OlheBoWyCuXJdWivJAqdn5AXgwIoU+TjMec2HegykWArfc8Mov/rem7h7v2y2pWmCYibRWd0JUNhB0ZoOeeRnJJF7F4P5qsm8IvLqDHqvrBWvaZDKWpmKee0E2n58Khe3fSTWleJnP/sM/+mhk8s/cBUIiHwTKnLVEGrhHJQnl37scofyyMSoeMf01uqlG36cd5m/yeDo9mWPUU3v8M7nvN9ZMJeMkbfmmHSLQcpscXd3a2XqKO4Tn+YB+y4OHzzgr6/FehPGb0evTVKg6s8HVcgkWrNWkpYn0Ib2e2+ut73Sbg0aJVnBXMtJIte9YynlnkvGiXm/QaXIL8zV2D2UYedgekUeeaVhkU3EfNs0UuTd4C1ApbBfvCjJuCWHXH2xIc83S50qKdA0Sh6RZ7w0pOFckmplEXAhNcCp6c7Uw57Ib5dZANBzRNxSyCZ1/smbDxDTAuVe7FnduYNBReSu6xO5GtM2WzWZR1krQbCzw1rxFfkwFcNCSxbklriLtQL9aZzlui5ffekyv/nAMb55fGr5J6wQpuf/b05FHmRUcOGJNR1KeczNqkfk3lq9VLE5446zY2DpGBOASBUokYWFkCJPxMiYM0y5g0E76IFdndZKswF/9ROYsQy/1vwId+8fJKZJ1bxQa/qZXQfFxQ5FnorHWr7flO0pcjWoZYnMlXZFbnpE3vCIPGFVcBzXFytqzQ+GWoCoZIodxRSXS41ld6gVwyaX1Ml6Xv/VyiXfYEQuFacKdpybq5FP6q2l84rIKwFhpN06VVcu1kUhLwbppkfk2QRGaMt5eqaKroklC4x8qBREuCIi74aBTO8y/WF7RnrftVm5rRza7/cSn6uaWOiYeqHFWunIWlENszxFnkvpsitkF2sF+kPkFcPCtByEgF/43LMrChqtBJtakTdCLVpXSuQP/hv42r/uPJT3+Vg1ReSeIve+h/FiatlDp+MxLrqjsHjeV5kFrYFuN5hyi0Gri4Hd3voMgoQ8+G9g6iX+bPuv4GRH/WyYYsYr7PMyu67TLnW1Vkzb8S3CtO0p8kFPkS9Rpt9O5FZJBmrtwm4cESMn6lRNy29hq35Lqt9K1bCYq5rsHkqzs5jBdlwmS0unIKpsHiWwrlZ158Yicm8B6maFrPeFd/QhV1vSatAGIO3WqCAX6yLyYpAMEbkdUiqnZ6rsGc4s2bjeRyFM5Ku3VrphcAlrZdCdJxVzpBoHT5HLxacUkZksQm2GmCaIaaKTyNs88mxCl9kG7daKP1xi7YpixmtM9jNvPYhpOfzsZ5/pPRR6FfCJfDMGO9U6Hty/ciI/+Q14+Wudh/KsFadRAqH5LWcnSzL7a3xgeSJPxTUuuCO4C+d9lTnoSBKddgeYUyMT2zNXTnwVHv/PuK//KT59+QD3HBjyf6/FdEIG9gf3YWsJDoqLLb1WoHW4hO24ZFXGyrLWSmcdhO1xgpYboann/DL9INgpxctgNsF8zeS8l7Gy21PksHzmStWU4igXWStLQPU8Nkq+Cu/oeqi2WmEid2qU3TS241K2E9TcpN88ZziXxGm0EvmK/HFYF0VeTMeZr3a3VjRcRlj0Uw8ZDBS5SpdqJod8HzweE51tbGuzMrMgkfH7S/hEHhrTtVS/itVCNbW6a98QH//ga3jq7Dyf7INfHhQEbUZrxVuTB98OF5+WYwOXQ20+6MjpwXWDLoCiUZK7WqHGHBqk4zEybSl/3ZCOx7jgDEtrxVsT+ab8rU0xyJxas+GioKNfhr/6x7DtFp694eeZLBm883Dgxw+k47JPjhajktvHQdGpyMPj3kzLoSA8Il+BtVKttzZTc6uz1N0EyUweO54jL2RP8oryyD3xMuQpcr+P01DG36EvF/BUFaLqM60ZzUB4rSM2FpFrMZm73Sgx4KUJdVggXayVpFOj6qYwLYe6aTFHHt1rZzmcTZB25OKYtVIyh3zFRB4KEl1BsLMbiplEZ68V8HPJR52ZYGEU9/iKXG1trdSQrNwE4prW3SP3qk6rplx07HszWA14+cHg5XxrpX+KfDib4P237eDG7XmePd99ustqoAqCNmX6YWNRrvU998iy98kVdN+rz8nnhWwN03ZQtq4wWwvX5qrmkq0twkjFY1xwRxHNKmZFrq9cU+7upLXikaYqCnroN+Bz/1D63//wr3jg2AK6JnjrjWP+MQcyQc+khcx+qci7WCsQInLVZ2UZa2VMr/K/jA/D8QeCG6uzzFIgnYjhJArkqbcoct9aUYp8TinytD8acjkiV7vchC4H4AxPPw7/4Ta4vL6jGjYWkYNXpl9mIC0/9I6uh36wM1DkCbtGlTSGZVMzbRbJ+yOfhnMJf3H8+jcuoQk5FWhFyK0Hkcu0vw7rwavuHFZEntsOiQyZeAwhAiJ3UiFFrmvdPXKv6rTS8Ij84PdCdgye/Yz/sPwS/SpWCzWFadSrdiuk433ZcgZNszahIq8vyJ4oqpnVcvZKsw5Nj+RCqrxhBp+N3iy3WICzVZOR3GqIXAoA4QUzM4Yk8kZiOAh25sdBxOT53vYh+LH7cfPb+epLl3nDwZGWeFYxHWfRiwfNpvexW0yTFiFb8fgDvPnRjyKQTawMy6YgqnJGbW6bHN3YQ5FfZ71Cjjru6Uf827T6DHNunnQ8hpvM+61sK4Ylh894GWGDmThN2+XY5aC5XiahM5iJL5u5UjVsX1xlkjGGSkfkHZeeXsnHfMXYeESeKoCx6M/u7KnIQ0SetKuUSWNYDrWmTUkUfLIbyib8tpjfOGPwr/+Pwy2lyUsinpIZH4kcxJbfnq4EaoB0rzL9YXtGlud7HqGmCbIJPSDyzLB8b65LPCZaKjubtoNTCRR5RS26WBxe8/fhxAO+h57vo0euhnco9ZdL6n4F3Fqw6YOdqaJUuLntyxN5WJmGiDxcFZloVloswNmqsWpFDpBZOCGPZ0xDLEksMxgEO2M6vPkX4b2/Cz/wxxBPcXyyzJnZGu+6ubXKuZiR1orrukwm9qAJl0z5TPCAZ/6ckclvM0SZetPC8BR5M54DzZud28Mj39WUx7FDSlhvzDHv5skkdESq4A+XKBuWv94Bv9/K8xcW2T2Y8T39HcV0i0fuum5HUyxprchdRDahU6h5SQRTR5f7iNeEjUfkyYKnyCXhteSQu25XIo/b0loxmg5105YpiB6Rj+SS5D1FfveN+/nQStW4Qn68b/444FtGHY2z0oPU3QSD9rSfeqiQTcZ8ReSmh8A2wKwQj2k0nUCR/fuvHGVm6qI/wahiNIMFfPuHZCrlC38FgB7TyCRifVPkxUzcz6TJJfW+5KdvaiKvLwTDSnbdJQdwLwVVHwCykZs6TOizSdqVlp3jXMVkKBv0WFkK6XiMY+4ejMFDvPbsn5CJ2ejVKchvYyiXbJ2q87b/G173T3wv/oEXLyMEvONwG5GnE9iO7HMyEfdyu+e8+g/HhjP/G4BtYt5T5LIXuRX33kN6qLe1Uj8FgJh6yb9Nb8wxS4FMIoaWHvCCnU3KDcvvzwL4HRBPTJZbig13FtMt1sqffvsM9/32N30yd13Xz1oB+bscanipmFNHlvmE14YNSOTSI1d9SXaFqzqbNbBNWbpenfEb/OhWJWStWLIoyFsASpHXSfLrP3jHkl0Uu6KwQyqnPqFX4ywXuOwOMWxchNKlNiLX/Uo0oZp1eWX677z8J/DA/wXA2dkqeXuRslbAsh0aTcfPd2XbzTB+Ozz3P4K31qcOiLNVw28ZrM630oe0LGMzWyuNRWmtgLRX5k939MNpQb2HIvcyVoqZOBmn6lsrrusyWzX9fkPLIRXXsIlx8e5fZahxgX+S+JrsM5TbznA2NDKxC7760iR37R1kLN+aHTMQKgq6pO/CQcC0VPtMPOvn0m8T8yGPvIqV8Ig8M9RTkQ9VZTA9Vpvx42VJc05aK4kYerpALhTsVP44BIrccVuF4o5i2uuGKJX4Zx476/cqB7keLccNEbnOmKmIPFLkrUhJRf7+23fwS++8vnUgsvpSRw7JyfP1ebBMYk6TsiutlXrToaYXZc8Ry2RbIcWtwy6xdJHh3MrUSQu+92Pw3t/pz3uDoGlPG5FbjsuEO8TO8nOAGwR7kApXFSoINS+0Nss2Mcc75j4Lj30SKlMY9QppYXK6lvaLOnKhLSW3f0jOAfW2o7I6rj/BzvBnm0vG+lIo4WetbMpg50IgEHZ5JfRL2Ss9rZWgrWrGrfqKXCnclVorqr3s1LY3cyR7Dx91/1q2p8iNtY5MbMO52RpHJ0q86+bO6tGBkI1YsmJcYgxmjss7Tz3sP26bmKfetOVQCVHDSXg74F7WiuOQL7/CUccLvE6+CM06cbvOnCsVuZ4pSkVeV4o8ROSZgFPCWXG7BtNUTZtS3eLIRMkvHry8KHPLK2356CNxU6ZoZkehMuknIawHNh6Rez3Jb94xwM+8rW1og0/kXuvY6pQsnAGqpDAsm7ppYcS9H0h9jpgmuHdnnET2ClX1+Gtkb+c+oegv7tYfhmk5TDBE2vIq/kKKPKwmNEXk1Vl+oHm/HMPl2vD859C8YqAXFuJUPI86H3out/wgaHF47rOADEqqcuy1YKZiMBoi8mxSp+7lBa8Fqv3AplTkKtgJckK9psP5x3o/XlkryQG5Y1OH8YKd2wtJctSx4rKOQhHvSok86RF5o2nz2cGfJIUB5UuQ385QThJ5tyEKX31JDqPoRuTFkCKvmTbnY7sDRX76YRi5HhfBNjxrpWkzQBVb2UPpwe7WyuI5YlaNL9ne73LyJX83M0uBlB5DS+VJCJtGo+qnDCqEP5NwZ9Vw5sqXngsulpdL0m5R4kQp8r3Ce8yN75V/p9dPlW9AIi/47Sc7oIhcDXOoTEnlDVRIYzS96HfC69amFn+3NrSvEoo9gp2m5XDZHQpuaLNWFGI5j8gXz/Ee43/xZPpNsPMuePZ/+BPEn5zW/D4U4eeSHYYb3g3Pfw5sOfqqX8HO8BZe/WjWGvDctAVBdhOa1WBNxtPyOwxlYHRArf2xm4Kh4AQe+Z6ciy4cGjGZWqtiKivNWkmHiPwU49yffp+8w7NWTNvpmon0wEuXOTxe6Kz3INzts0ndtLkU3wOzr8j0yXOPwnXfi5sdZZuYo2YGitxVn0tmSFpK7RcQz8Z41LmJenJUErknYsragJx5610MrFqpwyMvpGTjLGhV5Ds9Ir8wX+NLz13iRq/99ESHIpef1R7XI/Kb3tdyXuuBjUnkzVpL8YqPsLUCMuDpdUGsKGvFtGkmPSJXnmO3UW2vEnJJnZgmOqo7m7bDhOv53/EM5MZanqOgF7zbv/vH5N0KX85+QFomU0e4w3wKgLP1NE+elZ9Vi7UCcP275ee2eI58Ku4HO09OV/jonz3Z2WJ3GZiWw2K9yUiLteJVva0x4LlpC4JUVWc49rL/Prj0THBfO2qz8rdR3COVsjqUR+S7MvKzrnpDFVSR1kqDnam4pIpG06Fi2Hxl6B/Jc9r/Zv8Y7YVs81WTZ87N8/bD3XvyK498oW5SM20mE3tkoP6Fz8u6hgPfA/ntbBMLNJq2HLxMYA+RHpIxsWat9cBeYPGEu4vZ3CFprXi2Rk3txr1j2PUFyo1mi7WiacK3OMNErhT5/S9McHGhzj9+4340EVgrvl3pNbLbaV+Uvv/eN8qL8joGPDcekSvC7abKfSL3FHl1usNaqZm2LJqB4IO9hhS5mhTUrsiNsCIf3NfSIlf1dQBIZgbkNnzuJC8nbuJI7Ea45YO4eooPCVkcMUuBr3lb3lyytQDDV/oL5yikZU9y03L4uc8+w9eOTHLEax28UqgtfFiRq13AWn1yc7MOX1YNs9IhIj/wFnAdOWczhM8/cZ4Hj0xKiyE9KNtGlC/7KrXhBTt3puV6qtCqyIdX6pGrwpymLVu1ZorwkS/Bnnv8Y8xWWyspv/XKDI4ru3x2g9p9Ltab1Js2M2kv7vP4n8hc9L1vQOTHvawVi2bTICsMSIc8cui0V6aO4g7soq5luZQ8ANPHoSLXe133nuPxiNMoB9bKV35RFjIhA56DmXiLSBrJJUjoGl96foKErvHuW7czlk+FiFxZK/Kz2ta8yCV3WO6oxg5HirwFXuMsZZm0QH2hQ/vlQqhO+4SvFHnNtKjm98Ouu+FrvwrHvnJNETl4+bXt1ortMBEm8hDC9khCj/mDn79a+KBUrekizUPvYUTIz6w4Ms53T3rVecl4y7H8XhkLUpGX6k0+8Xcn/N7vq81iUcVAw9kuinyNRB545JuNyLso8l2vAz0tveMQPvnIST758EmpyDPDkN8hVar3W1CKfHtSfg8lR6rK1XrkKT2wVvwePR7UMdoDng+fmGYgHee2Xd3jT6l4jKSusehZK/OKyCdfhJ13QqqAKIwz7qUfut5oNk19Lhnv99BeFDR1FDF2mOFsglPaPvl5ePEFQ+3GPUVuVBZwXK9u4sgX4bt/DJaM6extm9krhGBnUbb6eOsNoxRScbYNyK6I0BnsHDXOccoZl4Jj7CYpHNdpGPMGJPJlFLmegkTWixRPBUTueeT1pk0ymYQf/SsYvw0+/xG5EPpUmdkPdOtJ3uKRhzJWAHLejyoR06T/lx2DgT08n7vPL2NfuP6HAHCEzh0H92B5gcZsuyLP75AXwYVzFFJxLMflkw+f5L7rpaparWceVHV2U+RrI+Aga2WzWishcaEnZbn+qVYir5s2xy+Xcetzktj8WbLSXlFEPqp74xFDRJ7UtY7eJr0QVuSVUK40BEQ+GyJyx3F5+MQ0bz400tKmuR1KtNSallTaajTigbfIv/lxhsUihmHgehc4kfGIPO39HsKK3G7CzAkYu4mRXJKjjidMTj2MhY6rUhc9QWh4DfMG4k2ZHGEswslv8P+8/2Y+/oHWEXgQ+OTvv022zBgvpHyPvCXY6boUG+c47W6X/dTHDkvB2NYLp1/YgETuKfJGF0Venw+2W9lR6YEra8VNeaXvLpl4TP5IfvQLsP1WuWW9hhT5YKazcZZpOcxS4MJ1H4Kb/17Lfcrn9odOfN9vwt//b+hx3Se7qZF7uOQOYSaHeOOhYKubb1fkMR0GdvrWCsCeoQy/+/YB/jbxqzQXV7cQZ/0+K+GsFUkKa1HkjuNiOS4xTWA5buckpI0MpcjTbUr2wFtk5kOoj1DNlMRqV2YlsXkVwCrgqfLIh3RJNvO2zOWerZgMZxMrrptQk6kaplTk3bI8psuBtXL0conpssFbru9uqygU01K01E1bXixUxtl+ReTywhSvT/uWk55pV+ShFMS5U1KBjx1mOJfgRXObtBoXzlLSCqTUTkJ1Um1KoTdmBwWEvPgFbtie56bxTnG3dzhDLqnzNq9nzPaBFJNtwc5sUofqNEmrwml3XN4+dpM8wDr55BuPyJfzyBWR50a9K2ygyFWgzm/Mky7Ch/8G7vgwHHrHep/5ijGQ7mycJZtfCU7f8//C7tbRXEod+WPg9r0Rdt5JPKb5BFcyHX69+Q+ZPPzjvP7AkK+SOhQ5eP3Jz7F/JEsmEeMT/+B2hqcf5TbtFLmZZ1f1XpQiH8kHRK4uHmvxyFXFqgpSNTaTKu9mrUBAbqHsFX+epW+teB05vRTERtOWyttr/zpjeUReNVZVNyGEIBXXmK81cdxWOy+TiHF4vMDnnjjvxy0ePiGJcTkiH/DiQTXTlgJr+2tkszDVYyYvL0yp+iTCkEQe8xW591sPWyuKKMduYjSX5HLF8WNmi6IQ7EC8Hbiq6h5uepk+ozfB8ftl75ou+IV3XM9f/9QbfA4ZH0hRNizKjWbLwA1mXwHgtDsux72NKiJfH5984xG5b610U+QLIUU+BpUga6VKyi+yaemwli7C9/+RVObXCOR2s9NaAYLhyyEodeQrcg/xmOb7yKW6xZedeynf+dMUUnFu2zVAKq5177vutbV9w3UjPPexd/LaPYNo3ui8ePniqt7LrLeFz4Y+834ocvW+FJE3Lz4Lv32opTx9w6LeQ5GP3yZ3jqceAuQ8VtN2iGOhW1WpUJU1oRR505Yl6d7vZbopiXw1nQ8VUvGYf2EOB8mFEPzSu67n3FyNzz0pKxkfPj7N4fECY4Wle52rDojqPHnLL8M//Ya0ksBX5Glj2n8P8awa9qyslZAinzoqe66PXM9wLsFs1cDddrN8DlXUoAAAIABJREFUzxSClr3ezl5NGxswvXXzxp+Xu/gufd1Btr2+wUs7BKnIASZLDaqmFfymPCI/5W6X6zw7LL+biMg9LEnkYWtlxAt2lnD1NI6I+WXsK/UFXy0MZuJUvZJkBZ/I9c6vrEORe4jHhN/GVgUpVcrXj96zl++7ZZyuKO6Ris4y/f4oash0un6p+3N6YKZsMJJLtmzh+zHPUH0evjV08Wm5A1tJu9drHY0FGdjU2xSzFpMth72AZ83zv4uogcRDoCekrag8ctOWOeBGCQuNGcMbDehZK6tBSo/5VllL/QHw1hvGuGvvIH/49ZeZKjd46uw8b+mRrRJGMR1nstTAdSGd0OXFa/T64AHeDiMbJnKlyPWEbFgXtlamjsDQAYinGcklaTQdzOEbAfzyfABicZpairyQRJ6vX5StPW79QdlU7sUvdD/hl/8Ovvlx/5/bvQvVxGKjtbBo9hUcLcFFdzSYEqQCnuuAjUfkylrp6ZF7X3JuTPZxrkwiknmSuuZngrRPIbnWoBpnhQOexhJErtRRd0Uun1dum0v4gdfu4hP/4PbuJ1DcA7hQCg3RnZEVd4XGKom8S6vUpK6ha2Jt1ordaq04JW9r3D4vciNCNczqhv1vkUNA5s/4tsqg8MafKYWa3+7vTOpNm1QiBo1FaiLLorcOrkSRpxOBIm8nciEEv/zuG5kqG/z0Z57Gcly+ZxlbBeTu098px7vQUWYYC52CNY1uSmtFKLEGXpl+2Fo56vvRyjpayMsLw4yTbxFxVjxHzrNW0rWLcnB0LA6Hv19ONvJ28y149jPwyG/71su4N+/08mJDDl72ifwk5sBeHLRAsIwdhqljfg+ofmLjEbmeksGLZRW5t4jmTkEyR1LfWIocWqs7lbJuV90QVuSt7yse0/ye3aqSM5dcwUUslIIIgGX4wyyK5uomus9WOr1YIQTZpL4mIvcVuVeRJ1Q2QLcJ7hsN4YZZ7VDZHKcelt4rcENBfremSq3L7/CzI3xF3ijR0LLSxjBt6k2boRVWdSokdS1krXSuo7v3D/HWG0Z54sw8uaTOa/cOdjymHeH+5F0nFWkaJX2YAWuWeLOM5WoyK00hXKbfrMvf+9hhIKhanUxfJ//aeb9CFcCO5yl4ijxRuRCs+1s+KEXgidBQCoXFC7LlxaRU1mMFubYvLzaoNYwWRW4Pytf11/nYTfK4C2eW/VxWi41H5EJ0L9Nv1uWHFPbIQX6xiVyLIr/WiVz1Wm8hct8j7zz3JT1yL82w7A2RWNEs0nYinzsNrkNNyzJsr47IZypG1zLw3Bo7ICpFrmaLalXvvBZX5+Ffkwg3zGrHyPVSpJx7VKa1AXcMy8/xbM3zowvjAZE3A2vFiOVYrDf9wp3VWivpRMyfGNVLEPzSu2Rg8Q3XDQe23BJQu091/G4ox0cYtGeJN0tURLalGM4v0wc4912ZgeZ54qqa+JIzhPO+P+Qvmve1vIaTyPvBztji+WDd77lXWjpH/mfnyZS89XX5OUDGDYayCUbPfpk/PPcDvMP5lmzBO3cKMXwQwP+e1AVmPXzyjUfk4LeybYEfIAp55CBVerJAMq51Zq1co1AVb/OhgOdSHnmuh0eeiMnhy67rUmorQ14SoVxywLdVXsndRdEtgVld0WFc1/X6rHRmR0giv/KGXO3BTr2irJVNoMjDDbPaIYRUdjMnfGvlpqIkimMlT93mx2V8yDIlkSekIm/GPSLvkhK6EqT0cMC6+1q6eccAf/gjd/DL775hRccstijy7r/LanKUEWeWhFX2K1N9hDsgfusTcgjHoXcBAZHPVg2qN/8IlxlufY1UnpyoM5JoImozAZFrGux+va+6fdhWkAc+8bx/8/ZCiv0zD5F26/yLhd+AL/4s2Cb6qGwV4guWbbfAP38UDr1zRZ/NatAXIhdCvFsIcVwI8YoQ4l/145hLItVFkasvU/mEoV4kylqpegt/JcNmX00ocgr3IjG9xlBLBTvb79NjGq6LHDrdaLa2/F0KoVxywCfyc4P3yH+vkCwX600sx+2q/LLJ2JoKgpQiVzn08bpS5JvAI28s4ZEDDB+C2ZepeVv2XUlpDzw/55GUSkGsTFI3bVIq2JkosFhrBlWdq7RWwgJoKYvufbft4OBYvuf9YRRDLWN7Cax6aoxR5klaFb9XTPAkb7jEucdkWuYbf05O7iLIb58pm/5FLx367YtkgTw1DiY8RV/cGxx3cK9cS2E/uzwhFT/Ids8etheSXFd/gUdi9/Ktgff5IxPjY4fQREiRx1PyIhxb4e9wFVgzkQshYsB/BL4POAz8iBDi8FqPuySShU6PXG2vlCL3xpkBvrWicK1bK/4E7lB3QOWRdyPyeEzOG+zMWpH/btoupbq1ckUOfi45IDNWCjupF6TCsOfOrugQaujyaL5T+cnhEmvwyO3AI9exSDRmZdpZ6dK6BJOuKhqLSw8rGbkeGotYZVkYlLYWqZPipSmvIMcvCpqg0Qw8cieRx7Qdf8rNqrNWQsHIrvUHV4BlPXLASI1REDXy5jRV0TaGMTMkL3yP/JbMo7/zx/y7ErrGQDrOTMXwK1wzIY9cSw+QE3UOxLsQeXGvLCwKV2IqATPqZZ/Ycv3emFlkxJ3lUfcwX9n7y/De34O9b0KMv4ZsYm3rfKXohyK/G3jFdd1TruuawF8A39+H4/ZGVyJXitwjcj0R/Bi8rBWFa91aCXqRBIp1qTxy9ZxER7BTeomm7VA2mhTSq1ACXi45IBX5yCHcomzU35hZGZHPdumzEj7fNWWtWEHWygiLCFwYuxkcr9R6o8JxpG3Yy1oBGJHeqz4vc5WT5gKN+ADHLpdlT3C/TH8i5JEH/YROz0hr7EryyBWyfdrVqngQ0BKIDKOZkbnx25rnqcfaiDw9JFXyK38H9/50ayAUGfCcrRp+YDgs4vTMAHnq7I15XVCVtQJSkQMshNa6IvIb3yO7M3o71ducYwB82zgoP5fX/QT8+FcgmSeTjAXph+uIfhD5TiC8n73g3dYCIcRHhRBPCiGenJ6ebr97dejqkbcROQT2imetKGR6LJhrBam4hiZaKx8VkStybsdr9xS5abx1O6vUu2U7V6DIg1xyZl+BkevRi+M03RjNFSry+sRxkpiM5LtZK2skct8jj7NNeN/9rrvk33765GYNmo0re+6x++E393dPY+sFYxFwl1fkQHJBjjNLmPM4KTkAebpi+NWQlCaomzaZuIBGCc1L3T09UyUR01aWwRSCIvJMIiZ7+vQBA5nlPXI7Jy9MSUzqWjuRqyZYA3JOaBtGcklmyqZP5KnQa8QzA+RFnd1MyWy4sB1b3Cf/zofWukrHveE98u9l6ZNf13iRipviRXtXR+wgm9T9IS7riX4QebdvtKPFl+u6n3Jd9y7Xde8aHV0+v3RJLOmRh4hcpSB6wU6QinZFmRuvIoQQZBOtk+YN2yGhaz17Y/yXj7yOf/49B1tu07XAWlmVRw5yejsuXHxK7n5GrqeQTjHhDuEqpb4U7CZv/MYH+b34H/dU5OU+5ZF3EnkfffLPfxi+9PNX9tzLz0vLr7SK3PteVZ1hFHaBniZT8uZSGgv+QJFjE2VpN8QSUL5Eo+mQ1wzA9XuUnJquMJxbeZ8VBaWYewU6rwT5pO4Pcei1U3bzwXShht7FWgF4/T/rGlcYySWZqRq+R95irXiP3++ckcIl/HkUdwOiU5GninK2rZ7yA57bS8/xjHMQm1jHxTGbWJtgWSn6wWgXgN2hf+8CVlc1slp4495aWkLW5+WYsvDWShF5yCO/1m0VhXbFaloOyVVegHxrxXIoNSy/CdaKoLaZr/yd/Dt8kEI6zkV3VKZqLYf5s8TtGu+NPc7QpYc77lbWSrfxYCuB6acfxhkTHvmp2Zb9TEGcPu6XW68aqrlVdRU7UL/PyhLBTk2D4YPkKmcAiDXmyAzItX7sckkSUn47TmkC03YY0LxcaW+c4fn5+qptFQg88tUq+aWgacL3yXspcpEPKpCNWFsQde8b4U2/AG/4ma7PHcklmCkbfrypxYf3yvT3mCdbbRWQVbWFHX79BCDX1cAumQyw7RYZ8GyUyC4c5ylX7pI6FfnGsVaeAA4JIfYLIRLADwNf7MNxeyNZAMeSPpWCKgYKX1V9RR5YK9d6oFOhPavDtBziXQKdS0FZK6VGE9txW8ZZLYt2Ih+5nkJa5yIjxKsrIEqvN0uFNLEHfrnDnsgmdRz3yudtmiGPfLuYwyEmszkSuf5ZK64rh+a297teKRSBe2PGVgQ1VGIpawVg5BDF2hkSMQ1RmyNRGGVbISkVOUB+B463Exjwil6SOalebce9IiIPFHl/f0OKyFN69+PGMwNUXbmrM+NtRJ7Mwds/1vPCN5xLUmpYfhO6FiHnWU1Za6GTyEEGPOfbFPnALvn/46+Byy/AhccRrsOTjky3bP9scm1B/bXOqe2FNRO567oW8DPAV4GjwOdd131prcddEt3K9MNVnQq+R57fmIrcbFXkvQKdvaCyVlSf6FVZK4WdMpd84lmIZ6Gwg0IqzkV3hFR9SnrnS8HrzfJ7mZ+H+dPw7d9vuTu3xsZZzVCl67i2QCUxLJXqwK7+WSuNBZm50G1S+0qgiHw1inwl1grAyCEGjEsMxZvyPNNDXDea48ysl+M/dADt8vNkqZMT/3975x0l2VXf+c+tnKtz94TWJI00o1HOIkiABJJtrbSkNcZ4MYthbWCdWHuB3T3Ye4zX9u5xxt5lCU46gMEGY8AEgW0BQgiB0GhGaUaa1Oocq6urK9/947776lXsqu7q7qqe+zlnTk9XV7iVvu/3vvcXVNFLKFr6frSasQIlj7ydETmooqCA11XXdw/5PUxJtfast7W5ATqXfGxBHczKAjm/46BQS8h795VbK4kx9b0A1aUxswTHPwPCxXNe1c+lch8q5PPYZwNjCyle/rvf5OHTLRzYm6QtZrGU8stSysuklIeklB9qx302pNZwiVpCrouCfFHbI++aiLzCW8taHnkr2EJuZY+0tNnp9pQ+tAOHQQhiQS9jckBliOgKt3wWvvbfq6Pg2edYEnGe6X0lXPkG+Nbvw9zzpee3wXFvWsi9bhcjrkUSHuu9ju1pX0SetAR4dVFV67V8e22ttBKR12lhW8nAZbiQ3OB9Qf0e6qcv7CtVA9/0c7gyCX7a/SARafUTifbaJ6zNzup0sllC3hP0NqztCHo9TKO+2zlPa0KuRwxeWLBeA2eig98RxTtTD52XJcZVi4pMUmmMMyIHOPn3MHyMWFytrzKbJ+yoYP7Yt88wvZxh/0BFLnwb6Oxdv3rYQr5UuqxmRG5tkgTiJWulwxtmaZwfALAi8haF3GN55LoApKX0QyhFKdYw67DPzbi07Cod9Z76Gjz8x3D80+W3nTvNWbFHVXXe/SHVH+fhP7H/vNFxb3rykdftYpgFljzWYOr43tJBZqMkdTsCWbI8WkEL+MosZ2dXePcDPyz1D69HrelAtbDekxuESoEj1EdvyMe8rgbeewMre17OOzxfJppX1pArGCdqve79LRYDQUnI27nZCarOIN7gsxnyuZm0IvK8v7lCI42OyC/MW0Jew1oBagt57z5AqsBAf6a0kA8dU2eshSyM3souq51tlUfuc5PK5llMZfnUoxe475rd9hDndtKlQq7ndjoj8sVqIb/0LrjvT2HPDV1nrUT87vKCoHVYK/r6ujCnpYgcHEKuNnKEECz5rYPjoiXkJ/5O/RwvHzghZ09xqjCiTuGjI7D3BjtdCzYu5DlHXv0g8yy4tZCPKiujxmCAdK7Aj/3Rt+x5pWuSdPSVadJemU1meOi5GbUnoAONlRk++4MxvvTkBM9O1RiIUrbIJXXQ860RtVl9PK6WKoeZUB+9YTWQRPuwE1e/i0GxxMEX/lpdJxCz0/3WY61sRtYKwHtfcxkffvP19R/X57atlUKL1sqgLeSruERFG4u1rBUt7gtnS2d5Wsi9ARhUdgqX3Mqw1c62KmvF7yGVLfBX3z3Haq7AO+842NL6m6U7hbyWR66niDvx+OD6nwGXy47I6xUddBqhyqyVDVgr81aTpJY8cqiKyAFWgyMUESoiz66UOsRNOIQ8NY9IzfJsfoT9/SF12fCVqlmQZVG0zVohQ5wkc8JKQ9NftBopf7PJDE9PJDg53mR07RipVjWpvQ4f+/YZ/v3HH2VqymHvpOb4luWL6onrddENs9ZKDfSFmXUPcjRvCXmwj96QFymxN/Zm+m/mh8VLiS5a1wnE7ci3U7JWQLWCvWJ3fYEO+txMSHWgLqxlOVWgzzwmE2lCPk95yqU+s/eGSjasE2dRkBbymKNERtsro7fUj8itvaCPfusF7rhskCMjmzMbuDuF3I7ILSHPZyC3Ui3kzpt0mUdeududWYe14q20VlqNyPtVG057TBUQCoZYcvepiPy5r0Iupc58Fs+XxM6ejrKLay+x3pPhY+q6VjrXRodL2EKeUj72rLAeJ2590Wr45NrWaHpYs7NCtMmI/LlJFXH/4KRlebj9FJaneXJMWSbTy2sIeaOGWRVccO0lbI1w0x45lJqtpfNFPpy3iqxdXvAE7ErK9VgrdkS+xb2KQl43f1e4nZ/P/jL54NDaN3AQ9nvsdVedjfvCqq1DZQ65JrpLvW4L5yxrRZTaH4BqB3Dbe6BnlDuPDnPfNburDpD6c55I5/mPt29ONA5dK+QVm51N7PR3m7US9nlI54r2aXI2X6zZi7wRVVkrrXrkx14Lb/0iDB2xL4oFPUy5hmDpvNroiQzDrb+g/qijcitj5ZzYU6o2tVqL6gk+ETsiX1+OrfbIPSuqF8a0rIjIawi5ru5L55p8zOQ0dr1bkymIp2dUFeezp62N3cHLKSxPo7POphJNRuRNcA6HqIT66LFawi5Y7/dqrsA3i9eR7juiPHchHBF565ud/k1KP1wLj9tFxh3hK8Wb7TW0gj5oVQVxQqigsJatAmoiU89oyVqJ7ipveHXJrWr/B7h2tIc//qnr7Fm4Gv05v2pPnNsO9be89mbpUiG3xEFbKzpa0lVetW7ShXnkgJ2CuKH0w2QWn7u6qdaauL1w4OVlF8UCXibkAMw8B6e+rqap7Lb8Te2Tz50ij4fIyKWl1giDR1T0M3Wy7Pmtt5VtrqBeD2HNppy0shrsU98GQr7mhqMmOVU6vW7CWknnCpyfT+H3uJiatB5/6Ao82UWiPsFAxM9UIrPGnSytvdFp8by0hNztB2+IPi3kVubKaraAxMX8a/4E7v0DoHQw30geebutlWYIOCqzW0VveNa0VQ/cDodeVf/GPftK1kq8qvPImuiD6ztvP9hyJW0rdKeQu73K18pUCHkja8WOyLsnawVKHvL6PHL1wZlLZogGPG35IMUCXs4X+yE5qQqyjr1OHUB79tkRuZx5jvNymKtGHRGIN6g26LSQ+6obg7VCLl9Uz88S8vGCbpbmV0NFauSSr+bUa5nOtxCR9x8GRFPWyvMzSaSEN964l96idZY4dAQXkjv3edjTG1w7Im/BWjlVtCoeQ/0gRFUfe93xz7P7arjiPgD29gbpCXlbt9mA3T0BdsUDHN21OT5vI3R6YqvfAXAIea0g7if/pnRGWYve/cpacRYDtcBLD/XzwM/dwr1X15mP2ya6U8ihVKYPzQl5l3nk4QrrYT3phzoiX8kWWrdV6hALejiTtzaGortVA36A3dfaEXlu+jlOFXdxzWiFIA0fs60Vl0sQ9rk3tNnp9bhgeYKc8DJXcKR01UlBXM0qb7zpatLktMq4CfY0Za2cnla2yptuuoTd3mUyriCzHpXlc8dewXDUz/SaEXnz1srTOdUVUJ+J9obLrRVtITkbRb39ZQf48i++fF0H9Z6Qj+++/87q93UL0N/bls8qKY18W9d3v3efeu8Xz5VvdDaJx+3ipZcObGo0Dl0t5I7GWU1F5F1mrVjrtCPy9aQfOj70Lace1iEW8HI2b1lYx16rqilBNRJaPAcrs3gWz6iNztEKi2D4mPIbrfct7Pewkl6ftZItFNWBanmShGeATN5R+hzfW8dayRMiTbqZbnTFgkpjjAyXhheswenpJG6X4PBwhKOxDNPFGI/Pqdf95qECw7EAU402O6VsOiIvFiXncj1kXUFbyMM+Nz63q8xagXJLIeB1b0oe82ajo+kNReTrqSHRKYjFvNVIrjPpXiEPxEoe+ekHlU8Yrt9V0bZWuiT9sD3WSun6Lace1iEW9PJE8SC5PbfAjW8r/WH3ternU/+AS+Z50b2XgwMVneqGr1Q/rZmFEb+Hnzz73+Dz7255Hdm8VAe25QmWvQPlG5jxUWtIbnlfi/zqEo/638WxpX9Z+wFS82rIbmS4fJxYA05NJdnXH8LvcbPPn2S6GOOvnlRZJbs9KwzH/CymcvU3W7Mr6jGb8MiVbSJ4se9We49CWPaKc7PT6xZNzc7sdPT3tnLAeDPU3exshl5HodA6PPKtonvfYX9URXanv6GyJ17+qw2LKLSQd/qYN42d1ZFdv7XicfQub1dEHg96WSDG2Gs/V5Zfzi5LyJ/8LADuwcuqe2dUZK4c9MxwXfIhGPt+y+vI6QPb8iQr/sEKId+jUh0rxNe1PE5EpOlPN9GGV6ceRobKB/w24PRMkksH1cGrjwTzxHlqUYmISM0xZBWNzCzXsFekhO9/VP0/PESxKPnNfzzJU+OJ6utS2rj99g1/CK/+TfvyvrCvzCMPdEngshbticjX8VrovuSwLo98q+hiIY+pL9uX3qs20V72Kw2vrseN7eoJbMXqNkyolrXSavfDTYnI1QFBF53YhPpUGtf5hwHo3Xes+sbxUfW+WRueP57/prrcOU6rSXIFvdk5wap/kLQzN7xOCqJIqYrOQL62OJZhVXWO56OsuGNrRuTZfJGzsyscHlZC7k7N4I4OsUAUiYCVGbv6r2rDM7MMn/lZePCDcOReuOJ+XphN8onvnOWB79Ue4lFrBiWoGZh2HrmeDrQD2IhHriPydaUeh/pUR01QfeA7lO4W8oWzqrPevX+gshUacHAwwiPvv5PrL6nvo3cSzhJ2KSXZwnr6kTuEvJVe5A3QB4REpZCDHZXPyShHDtTIzRXC2vA8CcUCr1j9mro8k2htig5KyGOuNGSTpIPDFIrSLhKyN6Uqqjs9q6p4KFRoorLTqur80L/O8Z0XC5BqLOTn5lbIFyWHh6LKX0/NMbxrLz6vBxnst4RcfUbLUhAzy/DRu+DpL8Cr/4fKovCF+NEFtcbvnal9JpDK6f7a5eKkIvKSR94tdRNrsZGsFV2mvy5rRQjlk7v9tas/O4TuFXJdpn/1m1QuaBOMxLsjGodyj7zR4OVGuF3Cnr7SUi/yBujsl0StTUrLJ39B1shY0WghP/0gfYVZvuW+WV1upRE2S7YgGUKl+GWtaj+7YlO3L66Y3elNK1EMNRWRq9ueWg0zkQ1Cdrlh616dsXLpUMTy14tccfhSHnn/nbgiA5CaZThaIyI/+22YeQZe/zF46S/ZFYbHrUrQ09NJZpPVVkzKjsjLxakn5LM98lR250Tk2iLaiLWy7kSHgcPQd3DttgnbSPcK+eDlKv3tNb+13SvZFPQXcCVbKA1eXseHWEfl68kbrkUpIq+R+WFF5OPuUUZidQ6aw8dUBP4v/5Okp4dPy9eoy5dbGyqVyxcZRkXJejiv7ZOHLSFPlgu5P6OslXBxjcZVoKwVT5CpVQ9jGatfjG4xW4NT00mEgEODEfsAIiJDqiAkPAgrs/SEvPjcrvLMlYnjgIDDrym7vycuLNp54d+vEZXXGl0G0Bvysriao1iUO8oj34i10hv28Zv3HeP+a9e5WXnP76gzpQ6me4X8hp+FXzkBkQ3O/+xQnHnWWUenv1bRQt6+iFz3jqgVkV9HFi/Jvivq583qzJXxxzk58OOcylqpjIkGPvnYY/DPv12WhZIrFBlB+djFcIWQewOq13SFkAeySvijsgkbJzmNjAyRyOSZzFoHpQYpiKemk+ztDaoIWQ+S0FlUoX5YmUUIwVCsIpd88rja4/GXMnyy+SJPTyzzuuv2EvS6a9orpanw5Qfo3pCPQlGynM4bj9zBW1+yn9G+0PoePLYLBi5d+3rbSPcKOaheCDsYPbezZK20/nx1dWe7CoKCXjcel6jpka964tyZ+T0Wjvx0/TsYKjXgem7Pa7mQtyyYRhH5E5+Cf/1dOPcd+6JcocgrUl+HnkvI9hwAKgp9IoNV1kowp4Q8JpuLyAuhIaSEBayWEA0yV05PlzJW7IEU+swgPGiL+3AsUG6tTBwvddGzeGYyQbZQ5Mb9vVy/r4dHawq5OiOqtFZ6Q6XGWau5neORB33rTz+8GOhuId/hqHFv7bFW2pV+KKxJQbUi8qXVHBfkMP3xBr20/VEVgY7eQq73MCkCSF+0cUSetPzz7/yRfdH+zLNcnnkSbvkF/F4lXmUpiOGhqog8kldCHidZlWNexcoM2YBqMbAoredTJ3OlUJQ8P5Pk8HDUvq1ag7U5Fh60xsblGI75S0Kemoel8zy8sqcsC+iJC8rCuWa0h5v39/P0ZIKlVPnrbVsrNTY7wRLyHeSRhzbgkV8MmFelg1EDmPNt8sjbE5GDyiWv5ZEvW+K+ZlOlN30S3vAJ+3r5yEjjiFwL8qmv2amL969+nlVXGK57i91QKePsoRKpFvJoQQmkVxTIra6x4ZmcYtWvhHhRR+R1rJUL8ymy+aLa6AR1JuDyliqNw1bPmdQcQ9FAyVqxBm382bNhPvGdM/b9PTG2xEDEx+54gFsO9iElPHau/LFTdYTc2W8lnSvuGI/87itH+NVXX8ZQtPWujRcDRsg7mLBP9STPbMAj1+LfrvRDUBuntSLyZSvnfc3of/AyiO+xM3OywZE1IvIp1fPcG1Lj4pbGuD3/bb7b8xMQiNlilSmzVqqFPFZcImVNY88sN5gSVMhBao4VrxLgBWkJdB1rpSxjBZRIL9StAAAczElEQVS1Eh4sZTlor9zKJV/O5FV9wIQS8pPFfXzq0QvkLQvtiQuLXLO3ByEE14724HO7qnxy3RCr0jqxI/KVnGWt7Iyv+K54kF+88/Cm9yzpVnbGu7xDUWOiSh75ejZ6PFb+Ybs2O0H57VUFQcByukkht9CtbFeDQ/WLgqRUgjx4BK5/Kzz5Gfj6BwF4ZOANQCk1LV0ZkWeW1Mg1gHyWGElekKoLXW65QaWmNWtz2aMi6hUCFIS7rrVyqlLIV2bKc45DA/blOpd8ejkDk8eZdQ2Q9vYymUjzzWemSWbynJ5JcvXeHvu5XTvaUyXkqWwet0tUHdx7QjvTWjE0xgh5B6M2Owul+ZTrtFaEwB662w5iAW/Nzc6kJeQRf3MHDbsNgX9I5ZHXmlSfWVbl9pFhuO1dSthPfJZviltZCap+3NpaKdvs1BuN2q+2qjrPCpWClks2mGxvVXUuCCWmPrebFVe8rrUSPftVfj/4cWL6NV6ZLuWygyMinyur7ixOPMET+X28+ZZLGIkFeOB75znx4hJSwtWOhmM3H+jjxItLZdOUUtkCIa+7KkKNBTy4XYL5Fb3Z2R0tKQwbwwh5BxPxu0luoCAIwOtxEfF5qvuebIBY0EMiXe2R6yERzUbkEet6Se+AahalRbfsTnXPk2HVAuDK1wPwF/Je2/8PWJkMZZudkeHy21v3PelVHewKKw0icus2syghPzgYJiEidSPyq2f+kdfJB+HCo9btZ8obuIWrI/LZ+QXE3GlOFPdx68F+fvKmUR46NcMXj6u9gmv2lgqqbjnYR6Eo+eG50uPXq9oUQtAb8tqzQU1EfnFghLyDCfk8pDaYR+5zi7alHmrqReTaWok0a61Y0eKCxxK6WvaKnmSvI9y7PwRv/AseLxyyD2z+WhG5ri+wUhALVgQ+F9gPQLFRW1rrMaeLPbhdgoODYeWT1xHy0VVruPFjH1dnDCsVQh7oAeGG1KzdOKswcQIhi5ws7uOGfb286eZRBPDA984z2hcsm+Bz/SW9uAQ85hDyVLZQt1KxJ+RjfGkVgKDXfMUvBsy73MHo9MPMBq2VdqUeamJBL5l8saodqxbyZofzamtlwWVlddTa8NSphzrCjgzBsdeWmmZRJyK3qzuVKGcT6n4SEZVzLhs1wbLEf6IQIxbwMBwLMJMP1bZWEhP0FudZcUXg5OdU/59CptxacblUVL4yQ9QaBuydUR0gk33H6Av72BUP8qojw0hZHo2D+hwMxwKMLaTsy1LZ+rZJX8jH+KIVke+QPHJDY4yQdzARazNw0cohXo+Qv+zwAHcdHW7runS5/3KFvZLM5In4PVUDaOuhs1ZmsIS8VgqitkaiI/ZFxaIkX5Qla0VnreQrslbALs7JJ9T9FKO7SUk/slETrOQ0+GPMZVzEgl6GogFmChGKtbJWrPF2/zT0DiXgOte9sje+VaYvhGA45ie29BRLhNl34HL7Kj99q2o0VinkUF1ItJrLN4jIS9bKTkk/NDRmQ6GaEOKNwG8AR4GbpZSPtWNRBoUuv9ZtSddjrbzrFe0vLXY2zhp05PUup3MtDeb1eVz43C6miSnroWZEPqVysh3jz3JFJdhayHU2T1lE7vGrAQ1WRF5YniEr3QSj/SwSxpVuJORTEBkikc4RD3oZjvmZIVy7A+L4jyhIwamRe8H7XXjc6slRKeRWmT7AUCxA78QznCjs56YDpYHhdxwe5PdefzV3XzlCJSOxAKemSxWpqWyh7mvdF/bZ+yrGI7842GhEfgJ4HfBQG9ZiqMC2HqxuduvtM9FubCGv8MmTmXzT/rgmEvCQzEplndTyyJeVqNoj5YBcQVVl6gObyyXweVzVQ5Ujw7ZNIldmmSdGX8THkozgatAAi+Q0RIZZWtVCHmBRRnEV0pBNlV21OP44z8vdhKNxuOntULRek5oRuTo72BX1cKk8z0m5n5v2l4Tc5RL8u5tGidfY0xiJB8ra3zZKLdQpiGCslYuFDSmDlPJpKeWz7VqMoRxtPczriLxThNzKSa/MJV9O51v241X1akE1JkrUslamSv64hU7H9DomIAU8rvKCILDK9JV4itQMczJGb9jHgozgydYRcinVQIrwIEurOWIBFZEvoIuCKqLy8cd5Uh5UFZVX3K8ibyj3yMHyyFVEfos8jl/kGPNfyt7e5uZnjsQDJDN5OwWx0WZnb6h0IDAR+cVBZyiDoSZ6ALOOyDtFyHXEWEvIW7FWQG2Mji2kmJC9zE+e46HnKlIQrejYiR4g4XW8Hn6vu3oWZmTItlZcqTnmZIy+kI9FIngzdYR84gk1RPrAy0ms5pRHHguwWKu6MzGBa2WaJ4sH1Gvi8cMNb1OdF0MVQwjCA6qn+Vfez5tO/WfGZR/ZfXc0Xamo2wJr77vRZmevI+PFeOQXB2sqgxDiQSHEiRr/7m/lgYQQ7xRCPCaEeGxmpka+sKEKHZHriS/r8cg3Ax3xLaaqrZVWe7r0hX18/+wCXz3vwrMyyQe/cLL8CsnJqug2ky/3yEEVBdUUcsvO8KTnmENF5IsyjC9XZ0rQ438DngDyyteTWM0TD3qJ+j2k3NYgE2dEbm10Hi8eLNkZr/wAvOf74K4QWW21PPJnnN//eu7O/B5HLz3U4JUpp3JM3Gq2/mZnr7FWLjrWDJ+klHe144GklB8BPgJw4403rtF6zgBOIc/iEuDpECHXEXmlkLe62Qnw26+9iuemlrn23HFij36NxaUFpJQqUi3klR0RLd/80xG588AW8LjLs1ZAiWcmAblVfJk55uSVXBHysUQEf25J2SjOiDiXhif/Fo7+G9LuGNlCkVjQgxACd6QPVilPQRx/HClcPCX30aN9bZcbojWyhA6+Ai67B257N0RvoHf6UV55+VD19eqgp1tNLqWRUpLK1bdW+sLGWrnYMPW7HYzuRTK/ku0YWwXUASUa8NjZNJpkuvXNzv0DYfYPhCG3H4Ce/JyKhENeSM0Csioitzc7Pc6IvJa1Ygnq4nk8+RRzMk404GGJKG6Zh+xK2UAHnvkipJfgurfYtpE+aPmiA0rIndbK+I9IRA6SXvWXRcE16d0Pb/60es7AQ7/+yjVemXJsayWRJpMvImX9aLtss9MI+UXBhtRBCPFaIcQYcBvwJSHEV9uzLAOUIvLldL5jbBVNT6i8cVahKFnJFtZffBRTzaxGxDyTOl96uaIYyML2yKuslYqIXB8ArNa3c0QJ+dy1bRKAHz0A8Utg/+12d0ct5KH4YPltpITxx5mKqEEZ8VB7q2crCfrcxAIeJpfSpRa2dUS6z1grFx0bzVr5nJRyr5TSL6UcllLe3a6FGcorJNczHWgz6Qn6yiJynU3RqrViE1UNsIZYKAm53Wel3FrJFmpkrXjdNdIPLSGffgqAORkjWE/IFy/A8/8M174ZXC77IKU9//54zCoksiLy5QlYmWYscBmuNjclq8dIPMBkIm1PB6oc86aJBb0IoVyjTklZNWwu5l3uYNwuYXf267QvZE/IW+aRJ5vtRV4POyJfYGpJC3lFnxWLXI3eM35PjYhcl+lPKSFfEKq3d9pTPbrtma/+X0AqIQd7Io+OyIdifhYJk09afczH1Ubnac9lxIPetjYlq8dIPMhUIm1PB6oXbbtdgnjQS7BGd0TDzqSz1MFQhY5wO8kjB+XDLjojcrsX+TotBn8U6YuUWyt2n5XaHnll+mGm0iPXmSJTqq9JytOLEIK016oSdUTkwac+w+nw9dC7D6DKWtFFQbmFF+H8I3D80yBcPMO+Mk96MxmJ+cutlQa2SV/IZ/zxi4jOUgdDFdon7zSPvDfkZdHhkTc95q0BIrabUc9SubXij4O3vGimpkfuqbHZ6fGpcWuL5wBIWQKe81m9vi0hzy5NsU9M8oj7RvumlZudQ9EA8zJCaOwh+Pjd8NTn4cDtzKRdNSsxN4ORWIDZZMbucdPI/+4JeU0O+UWEyVrpcLQP2nERuTUlqFCUuF3CHvPWatZKGdFd7F2YKLdWaqTy1fbIXdXph6DsldUFssKP8KkhynlfuUeePv9DfMD30qO8xbqZFnJtFQ3H/Pxa/g30Xvlqjl33Ehg+BrE9LH34O2UtZzeT4XiAooTz86pNQD2PHGAg4rcjd8POxwh5h6M7IDpFqxPoCfmQUkXiPSGfba3ENiLku67m0jPfYXnRmt6zXF2eD3XyyGulH4KyZWafJeHusSshXb4QGfz4rY3L/PgTADy0PGK1x3WRWFVVqjp3fygW4Afycr41coRjl5UKeRZTOQ4OhNf/nFtApyCemVWj5RpZK79+zxH7LMmw8+msMM9QRbhjPfLyoqDlFse81eTofXjIc3niYfW71YWwkrrph7Uicuv2SyJuC5/f4yYhorCqyvRdk8c5XxxkSYYZX1QDGXTDLPtu/B4ifk9ZK1mAxVR2yzxyXd35wswK0DhH/NKhCNdd0rsl6zJsP52lDoYqwra10ll+Z69jyC+UxrxtyFrZcyNJ3yAvyz1MJl+w+qxUt3TVE5Ocm50Bj5tCUdoib2NF9AsiblsRAa+rbHSbf/YEJ6QaOHFhviTklRk4QzE/044OhPlCkUQ6v3UeeVxH5ErIG0XkhosLI+Qdjq7u7LTNTl0Aozc8l9N5hCg1+loXLhfju+7iDtcTzE5cgNxKzYg8q7NWHHZTadxb7cyVeWL25mDQ61ZNsFYXIJ0guHyOk8X9QMl/1r3InQxHA6WNWLDnlvZscjGQpi/kw+sWTXnkhouLzlIHQxXaWum0PHIdkesURN35cKN5yyuHfoKAyCH1gIZaHrkVkfvdpYOGztCoru5Ut5+VMTuCDXjdLMqwEvLJJwE4KVXaoS3kq9VCvrc3yIX5Uj9y/dzXLM9vEy6XYDgWIF+UCIFdY2AwmE9ChxPu4KwVKHnkyUy+LdWNgUMvY1bG6HvaEvIaWSulNrbOfuRKpGeTGT70pae48bce5IWZpB3RTxditqcc8LqYK0ZUQdDkcQBOFg8wEPHZQr1ktbB1sn8gzPRyxq6s1Gcjm12e70RveJpiH4OTzlIHQxWdmkeuy8AX7M3O3PqLgRyM9IT5euEGQqvWtKAGWSvOzU5trbz+zx/m/33rDLPJDE++uGTffqoQta2VgNfNXDGkBjBPPEHS28+s6OHorhgXFupH5Pv6QwCcm7PE3nruPVvkkYNKQQTjjxvK6Sx1MFSh0w87LSJ3uwSxgJcle7Oz9c6HtegJefmGuKV0QQ0h1x65x1EWPxRVAndsd4xPvuNWwOrdPXwl8p7f5YvZ6yqslQiikIXz32UieBkRv4d9/SHOz6fIFYqsZAtVQr6/X6UZnptTm42Lq1lrzVtjrYAjIjdCbnBgdks6nE4tCAIlujoiT6bzbRE0IQRnojeQSocJkYFgX9V1coUiPrerzFq49WAf33jvHXZOd8jnZnIpAy4XmRvewfLnv+LIWnFzXo9uWzjL2YGXEwt4Ge0NsZjK8eKCylypzIm/pCIiX9yGiFwLechrvrqGEp2nDoYyOjWPHKx+K46slXU3zKqgPx7lYf/t0HeobOiyJpcvVhVICSE4NBhBCIEQgpFYgKllPU3HajLl8Mjt0W3AaddBogEPl/QpoT4xrqYHVXrfsYCX/rCPsxVCXumlbybaWjERucFJ56mDoYxIh3rkYJXp66yVTPuEfCQW4Hd4G7y9dnv7XKFYlkNei6GY3y71T+XKm0wFPO4yIX9K7lcRuRbyFxMANfPD9/WHbGtFDWf24N6CzocaOyI3Qm5w0HnqYCgj1KEeOajGWU5rZSMNs5yMxAOcXy4iAz01/54tyLKNzpr3USsi13nkPjeLWGX1/jjP5waIBT0OIVcRea35o/v6w7a1srCFVZ0aI+SGWnSeOhjKiHRoHjmUWtnmCkVWc4W2ZK2AKkXP5otVM0E12XxxzTOU4XiAqUQGKWVja2XX1SQyeaIBL/Gg+mdbK3Ui8vGlVdK5Aoup3JYVA2mGYn4Au2+MwQBGyDuezvbIvSTSebtTYNsicsd8ylqoxlaN7YzhqDoYLKRyVRN1Ah43i0SQCNh1DcvpvL2xeUlfyD6A1BLy/f1hpISxhRSLNVIUN5uA181Q1L+lG6yGzqfz1MFQxu54gF+7+3LuPlbdc2S70WKiszzakX4IMBJXUefkUiMhX8NasTYFpxJp2yPX1orf6yaDj5Mv+xPkbe8py4Ef7Sv1Pq+1ialzyc/OpljaBmsF4OM/exPvedWlW/64hs7FnJ91OEII3v3KzvzS9lp9uHURzYZa2DoYbiIiX+sMxXkfqxUTdXRp+9jIXez3D1KUEAuqtWuf3Odx1RzMoHPJz86tsLiao3eLrRWAK/fEt/wxDZ2NEXLDutG2wpiOyDfSwtbBUDSAEPUj8mY2O4ctL3lqKW33FA85mmaB6suSsAdIqLXrFMR6lklPyEss4OHs3ApLqzljcRg6AmOtGNaNbhal+5O0y1rxeVz0h/1Vvb81uSY2O3Wl51Qiw2q2fDRaqcFWwe6jrjNURntD1u+1n4sQgv0DYZ58MYGUEN8Ga8VgqMQIuWHd6IyNC1ZE3q48clA+ecPNTk/jzU6fx8VAxKesFTuPvFTZCUrI9ZDlqGOzE+pH5KBSEJ8eV7nmJiI3dAJGyA3rRm/0jVkeeTu6H2pGYoENbXaCisqnE6Wp8870Q4DVXNEeh6Y3Nnf3BHGJNYS8L2TPDd3q9EODoRZGyA3rJur34BIlj7xdeeQAe3pU7+9iUVb9rRmPHFTmit7s9HlcdgWmbnmbzhVIrOattZfSPA8MhO2sl1rozBUwQm7oDIyQG9aNyyWIB71k80XcLtHWQQfHdsdZyRY4Y5XDO9FNs9ZiOKZ89lS2UFYJ6XIJfB4X6XyhFJE7DkJ/9fZbeN89R+ve737HsOV40Hjkhu3HCLlhQ+gNz3ZMB3KiU+x0ubyTZgqCQKUgziazJNI5QhWphAGPi0yuaI9rc/r7e3qCDYdFmIjc0GlsSMiFEP9LCPGMEOK4EOJzQojazTEMOxYteO3c6AQ4PBzB73FxfKxayLP55jxyXSF6bi5V1S0w4HWzmlWbnfVyxusxGPHbEf5WV3YaDLXYaET+deBKKeXVwHPA+ze+JEM34YzI24nX7eLorpia8lNBM90PoVQUdGZ2pWpQcdDnJp1XHnmrhUxCCPb1h4n4PU0dUAyGzWZDn0Ip5deklHnr10eAvRtfkqGb0Ol37Y7IAa7aE+ep8UTVhmczTbOgJORLq7nqiNzjtvLIczW7HK7FwcEwAxHjjxs6g3aGE/8B+Kd6fxRCvFMI8ZgQ4rGZmZk2PqxhO9EpiO3MWNFctSdOMpOv2vDMFWRTHrkz86Sy7WvA61KVnesciPGBHz/Kn775+pZvZzBsBmsKuRDiQSHEiRr/7ndc578CeeCBevcjpfyIlPJGKeWNg4OD7Vm9YdvRm33ttlag/oZnM71WQPVL15F7sMID93vdrOqIfB0+956eoOl5YugY1vz2SSnvavR3IcRbgXuBO6WU1Um/hh2NbhrVrvJ8J3rD88mxJe6/dg8AxaIkX2wuj1wIwVDMz9jCapW1EvS6WUxlSWby7GqQM24wdAMbzVq5B/gvwH1SylR7lmToJuK2tdJ+IdcbnscdEXmuWLT/1gz1Jupoa0X1IjeZJ4buZqMe+Z8CUeDrQogfCSH+TxvWZOgidETezvJ8J5UbnrmC+tnsDNNhW8jL1xfwWlkr6dymHIQMhq1kQ59gKWVnNso2bBk9wc1JP9RctSfOXz9yjjNzKxwajJDL64i8ueIjLeSVHnnA42Y5nSedK5qI3ND1mCRYw4bY1RPA53FxiaPasZ1UbnjmrGZVzeSRQ6kveS1rZX4lC2yOLWQwbCVGyA0bYiDi59EP3MkrLx/alPt3bngCdtfBpj3yeB2P3PH7erJWDIZOwoQihg2zmXMrKzc8s5a10qpHXlmCrzsgwubkwBsMW4mJyA0dz1V74px8cYl8oWhvdjYbkV82HGV3PMCRkVjZ5U5hb9esUYNhuzBCbuh4bjrQx0q2wMnxRMkjb3Kzsy/s4+H338lVe8uLd5wtd01Ebuh2jJAbOp7bDvYD8PDzcyWPvMnNzno4s1hiQRORG7obI+SGjmcw6ufwUITvvjBnpx/6N9h10GmtmIjc0O0YITd0BS851M/3z8zb8zc3GpFra0WIzStmMhi2CiPkhq7gtkP9rOYKPHZuHmh+s7Mefisij/g9uFztm2xkMGwHRsgNXcEtB/oRAv71OdUCudnNznpoj9xUdRp2AkbIDV1Bb9jH0ZEYJ15MAM3nkddDe+SmqtOwEzBCbugaXnKo3/7/Rq0V7ZGbiNywEzBCbugabnMK+UY3O63KTpN6aNgJGCE3dA03H+jDbW1Mbtgj92lrxUTkhu7HCLmha4gGvHY3xA175DoiNx65YQdghNzQVbz0UD8uAX6Pe+0rN8BveeQmIjfsBEw4YugqfuEVh3jJoYGqGZytEvC6ed+PHeGuo5vTftdg2EqMkBu6imjAy8sOD7Tlvn7+jkNtuR+DYbsx1orBYDB0OUbIDQaDocsxQm4wGAxdjhFyg8Fg6HKMkBsMBkOXY4TcYDAYuhwj5AaDwdDlGCE3GAyGLkdIKbf+QYWYAc6t8+YDwGwbl9MNmOd8cWCe88XBRp7zPinlYOWF2yLkG0EI8ZiU8sbtXsdWYp7zxYF5zhcHm/GcjbViMBgMXY4RcoPBYOhyulHIP7LdC9gGzHO+ODDP+eKg7c+56zxyg8FgMJTTjRG5wWAwGBwYITcYDIYup6uEXAhxjxDiWSHEaSHE+7Z7PZuNEGJUCPHPQoinhRAnhRC/tN1r2gqEEG4hxONCiC9u91q2AiFEjxDis0KIZ6z3+rbtXtNmI4T4FeszfUII8UkhRGC719RuhBAfF0JMCyFOOC7rE0J8XQhxyvrZ247H6hohF0K4gQ8DPwZcAfyUEOKK7V3VppMH3iulPArcCrz7InjOAL8EPL3di9hC/gj4ipTyCHANO/y5CyH2AL8I3CilvBJwA2/a3lVtCn8B3FNx2fuAb0gpDwPfsH7fMF0j5MDNwGkp5QtSyizwKeD+bV7TpiKlnJBS/tD6/zLqC75ne1e1uQgh9gI/AXx0u9eyFQghYsDtwMcApJRZKeXi9q5qS/AAQSGEBwgB49u8nrYjpXwImK+4+H7gL63//yXwb9vxWN0k5HuAC47fx9jhouZECLEfuA743vauZNP5Q+DXgeJ2L2SLOAjMAJ+w7KSPCiHC272ozURK+SLwv4HzwASwJKX82vauassYllJOgArUgLZM/+4mIRc1LrsocieFEBHg74BfllImtns9m4UQ4l5gWkr5g+1eyxbiAa4H/lxKeR2wQptOtzsVyxe+HzgA7AbCQoi3bO+quptuEvIxYNTx+1524OlYJUIIL0rEH5BS/v12r2eTeSlwnxDiLMo6e5UQ4m+2d0mbzhgwJqXUZ1qfRQn7TuYu4IyUckZKmQP+HnjJNq9pq5gSQuwCsH5Ot+NOu0nIvw8cFkIcEEL4UJsjX9jmNW0qQgiB8k6fllL+/navZ7ORUr5fSrlXSrkf9f5+U0q5oyM1KeUkcEEIcbl10Z3AU9u4pK3gPHCrECJkfcbvZIdv8Dr4AvBW6/9vBf6hHXfqacedbAVSyrwQ4j3AV1G73B+XUp7c5mVtNi8FfgZ4UgjxI+uyD0gpv7yNazK0n/8EPGAFKC8Ab9vm9WwqUsrvCSE+C/wQlZn1ODuwVF8I8UngFcCAEGIM+CDwO8DfCiHejjqgvbEtj2VK9A0Gg6G76SZrxWAwGAw1MEJuMBgMXY4RcoPBYOhyjJAbDAZDl2OE3GAwGLocI+QGg8HQ5RghNxgMhi7n/wPgGewIuC7bogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "data_length = 100\n",
    "n_sample = 100000\n",
    "anomaly_noise = np.random.randn(data_length)    #異常値は分散が大きい\n",
    "nomaly_noise  = np.random.randn(data_length)/2  #正常値は分散が小さい\n",
    "\n",
    "#時系列とラベルを生成\n",
    "t = np.linspace(0,10,data_length)\n",
    "x_anomaly = np.array([np.sin(t) + anomaly_noise for i in range(n_sample//2)])\n",
    "x_nomaly  = np.array([np.sin(t) + nomaly_noise  for i in range(n_sample//2)])\n",
    "X = np.concatenate([x_anomaly,x_nomaly])\n",
    "y = np.concatenate([np.ones(n_sample//2),np.zeros(n_sample//2)])\n",
    "\n",
    "#シャッフル\n",
    "rand_idx = np.arange(n_sample)\n",
    "np.random.shuffle(rand_idx)\n",
    "X = X[rand_idx,:]\n",
    "y = y[rand_idx]\n",
    "\n",
    "#描画\n",
    "plt.plot(t,x_anomaly[0,:])\n",
    "plt.plot(t,x_nomaly[0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75000, 100), (75000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2,X_test2,y_train2,y_test2 = train_test_split(X,y, random_state=0)\n",
    "X_train2.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train2 = scaler.fit_transform(X_train2)\n",
    "X_test2 = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "ここでは **パディング** は考えず、**ストライド** も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$\n",
    "\n",
    "$a_i$  : 出力される配列のi番目の値\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "$x_(i+s)$ : 入力の配列の(i+s)番目の値\n",
    "\n",
    "$w_s$ : 重みの配列のs番目の値\n",
    "\n",
    "$b$ : バイアス項\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "次に更新式です。ここがAdaGradなどに置き換えられる点は全結合層と同様です。\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_s}$ : $w_s$ に関する損失 $L$ の勾配\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b}$ : $b$ に関する損失 $L$ の勾配\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial w_s}$ や $\\frac{\\partial L}{\\partial b}$ を求めるためのバックプロパゲーションの数式が以下です。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_s} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}x_{(i+s)}\\\\\n",
    "\\frac{\\partial L}{\\partial b} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi番目の値\n",
    "\n",
    "$N_{out}$ : 出力のサイズ\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_j} = \\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}}w_s\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_j}$ : 前の層に流す誤差の配列のj番目の値\n",
    "\n",
    "ただし、 $j-s<0$ または $j-s>N_{out}-1$ のとき $\\frac{\\partial L}{\\partial a_{(j-s)}} =0$ です。\n",
    "\n",
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていることです。この場合は共有されている分の誤差を全て足すことで勾配を求めます。計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    チャンネル数を1に限定した1次元畳み込み層\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    input_channels : int\n",
    "      入力のチャンネル数\n",
    "    filter _sizes : int\n",
    "      フィルタのサイズ\n",
    "    stride_sizes : int\n",
    "      スライドのサイズ\n",
    "    output_channels : int\n",
    "      出力のチャンネル数\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, filter_sizes, stride_sizes, initializer, optimizer):\n",
    "        self.input_channels = input_channels\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.stride_sizes = stride_sizes\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        if initializer is None:\n",
    "            self.W = np.array([3, 5, 7])\n",
    "            self.B = np.array([1])\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (input_channels, n_features)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (output_channels, filter_sizes-1)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        if self.stride_sizes == 1:\n",
    "            A = np.convolve(X, self.W[::-1], mode='valid') + self.B\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA, X):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            一層前の活性化関数の出力結果\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        #　前の層に流す誤差の計算\n",
    "        dX = np.zeros(X.shape[0])\n",
    "        diff = X.shape[0] - dA.shape[0]\n",
    "        if diff > 0:\n",
    "            dA_trans = np.concatenate([np.array([0]*diff), dA, np.array([0]*diff)], axis=0)\n",
    "            # 重みの数\n",
    "            w_num = self.W.shape[0]\n",
    "            for i in range(X.shape[0]):\n",
    "                dX[i] = np.dot(dA_trans[i: w_num+i], self.W[::-1])\n",
    "            print(dX.shape, dX)\n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self, dA, X)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optimizer_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD_simple:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.1):\n",
    "        self.lr = lr\n",
    "    def update(self, layer, dA, X):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        dA : 後ろから流れてきた勾配\n",
    "        \"\"\"\n",
    "        if len(dA.shape) == 1:\n",
    "            # 各勾配の計算\n",
    "            dB = np.convolve(dA, np.array([1]*dA.shape[0]), mode='valid')\n",
    "            print(dB.shape, dB)\n",
    "            \n",
    "            dW = np.convolve(X, dA[::-1], mode='valid')\n",
    "            print(dW.shape, dW)\n",
    "            \n",
    "            # バイアス、重みの更新\n",
    "            layer.B = layer.B - dB * self.lr\n",
    "            layer.W = layer.W - dW * self.lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。\n",
    "$$\n",
    "N_{out} =  \\frac{N_{in}+2P-F}{S} + 1\\\\\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "$S$ : ストライドのサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_output_nums(input_nums, pad_nums, filter_sizes, stride_sizes):\n",
    "    output_nums = (input_nums + 2*pad_nums - filter_sizes) // stride_sizes + 1\n",
    "    return output_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "入力x、重みw、バイアスbを次のようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([1,2,3,4])\n",
    "# w = np.array([3, 5, 7])\n",
    "# b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer=None\n",
    "optimizer=SGD_simple()\n",
    "input_channels =1\n",
    "filter_sizes=3\n",
    "stride_sizes = 1\n",
    "simple_conv1d = SimpleConv1d(input_channels, filter_sizes, stride_sizes, initializer, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 5, 7]), array([1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_conv1d.W, simple_conv1d.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォワードプロパゲーションをすると出力は次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([35, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# フォワードプロぱゲーション\n",
    "X = np.array([1, 2, 3, 4])\n",
    "simple_conv1d.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にバックプロパゲーションを考えます。誤差は次のようであったとします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バックプロパゲーションをすると次のような値になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_b = np.array([30])\n",
    "# delta_w = np.array([50, 80, 110])\n",
    "# delta_x = np.array([30, 110, 170, 140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) [ 30. 110. 170. 140.]\n",
      "(1,) [30]\n",
      "(3,) [ 50  80 110]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 30., 110., 170., 140.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# バックプロパゲーション \n",
    "dA = np.array([10, 20])\n",
    "simple_conv1d.backward(dA, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装上の工夫\n",
    "畳み込みを実装する場合は、まずはfor文を重ねていく形で構いません。しかし、できるだけ計算は効率化させたいため、以下の式を一度に計算する方法を考えることにします。\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$\n",
    "バイアス項は単純な足し算のため、重みの部分を見ます。\n",
    "$$\n",
    "\\sum_{s=0}^{F-1}x_{(i+s)}w_s\n",
    "$$\n",
    "これは、xの一部を取り出した配列とwの配列の内積です。具体的な状況を考えると、以下のようなコードで計算できます。この例では流れを分かりやすくするために、各要素同士でアダマール積を計算してから合計を計算しています。これは結果的に内積と同様です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([1, 2, 3, 4])\n",
    "# w = np.array([3, 5, 7])\n",
    "# a = np.empty((2, 3))\n",
    "# indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
    "# indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
    "# a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
    "# a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
    "# a = a.sum(axis=1) # array([34., 49.,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndarrayは配列を使ったインデックス指定ができることを利用した方法です。\n",
    "\n",
    "また、二次元配列を使えば一次元配列から二次元配列が取り出せます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([1, 2, 3, 4])\n",
    "# indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
    "# print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このこととブロードキャストなどをうまく組み合わせることで、一度にまとめて計算することも可能です。\n",
    "\n",
    "畳み込みの計算方法に正解はないので、自分なりに効率化していってください。\n",
    "\n",
    "**《参考》**\n",
    "\n",
    "以下のページのInteger array indexingの部分がこの方法についての記述です。\n",
    "\n",
    "[Indexing — NumPy v1.17 Manual](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば以下のようなx, w, bがあった場合は、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "# w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "# b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力は次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力が2チャンネル、出力が3チャンネルの例です。計算グラフを書いた上で、バックプロパゲーションも手計算で考えてみましょう。計算グラフの中には和と積しか登場しないので、微分を新たに考える必要はありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**《補足》**\n",
    "\n",
    "チャンネル数を加える場合、配列をどういう順番にするかという問題があります。`(バッチサイズ、チャンネル数、特徴量数)`または`(バッチサイズ、特徴量数、チャンネル数)`が一般的で、ライブラリによって順番は異なっています。（切り替えて使用できるものもあります）\n",
    "\n",
    "今回のスクラッチでは自身の実装上どちらが効率的かを考えて選んでください。上記の例ではバッチサイズは考えておらず、`(チャンネル数、特徴量数)`です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以下作成ではバッチサイズを考慮して(バッチサイズ、チャンネル数、特徴量数)で実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    チャンネル数を限定しない1次元畳み込み層\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    input_channels : int\n",
    "      入力のチャンネル数\n",
    "    output_channels : int\n",
    "      出力のチャンネル数\n",
    "    filter _sizes : int\n",
    "      フィルタのサイズ\n",
    "    stride_sizes : int\n",
    "      スライドのサイズ\n",
    "    padding : int　or 'SAME' or 'VALID'\n",
    "      ある方向へのパディングする数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels, output_channels, filter_sizes, stride_sizes, padding, initializer, optimizer):\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.stride_sizes = stride_sizes\n",
    "        self.padding = padding\n",
    "        self.optimizer = optimizer\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        if initializer is None:\n",
    "            self.W = np.ones((self.output_channels, self.input_channels, self.filter_sizes))\n",
    "            self.B = np.arange(1, self.output_channels+1)\n",
    "        \n",
    "        # self.W = initializer.W(input_channels, output_channels, strides)\n",
    "        # self.B = initializer.B(output_channels)\n",
    "    \n",
    "    def zero_padding_1d(self, X):\n",
    "        if self.padding == 'SAME':\n",
    "            input_nums = X.shape[-1]\n",
    "            self.pad_nums = int(np.ceil((self.stride_sizes * (input_nums-1) - input_nums + self.filter_sizes) / 2))\n",
    "        elif self.padding == 'VALID':\n",
    "            self.pad_nums = 0\n",
    "        else:\n",
    "            self.pad_nums = self.padding\n",
    "        pad_width = [(0, 0) for _ in range(X.ndim-1)] + [(self.pad_nums, self.pad_nums)]\n",
    "        return np.pad(X, pad_width, 'constant')\n",
    "    \n",
    "#     def calc_output_nums(input_nums, pad_nums, filter_sizes, stride_sizes):\n",
    "#         output_nums = (input_nums + 2*pad_nums - filter_sizes) // stride_sizes + 1\n",
    "#         return output_nums\n",
    "    def calc_output_nums(self, input_nums):\n",
    "        output_nums = (input_nums + 2*self.pad_nums - self.filter_sizes) // self.stride_sizes + 1\n",
    "        return output_nums\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, input_channels, input_nums)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, output_channels, output_nums)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        # print('フォワードプロパゲーション')\n",
    "        self.input_nums = X.shape[-1]\n",
    "        \n",
    "        # パディングの処理\n",
    "        X = self.zero_padding_1d(X)\n",
    "        \n",
    "        # 出力する特徴量数を計算\n",
    "        output_nums = self.calc_output_nums(input_nums)\n",
    "        # output_nums = self.calc_output_nums(input_nums, self.pad_nums, self.filter_sizes, self.stride_sizes)\n",
    "\n",
    "        # 畳み込みで計算するインデックスを計算\n",
    "        indexes = np.array([[i for i in range(j * self.stride_sizes , self.filter_sizes + j * self.stride_sizes)] for j in range(output_nums)])\n",
    "        \n",
    "        # 畳み込みを実施\n",
    "        calc = X[...,indexes][:, np.newaxis] * self.W[:, :, np.newaxis]\n",
    "        A = calc.sum(axis=calc.ndim-1).sum(axis=calc.ndim-3) + self.B[:, np.newaxis]\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA, X):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (self.output_channels, output_nums)\n",
    "            後ろから流れてきた勾配\n",
    "        X : 次の形のndarray, shape (self.batch_size, self.input_channles, input_nums)\n",
    "            入力データ\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # print('バックプロパゲーション ')\n",
    "        # dZを計算\n",
    "        # 2はinput_channels, 4はfilter_sizes + N_out - 1    \n",
    "        batch_size = X.shape[0]\n",
    "        N_out = dA.shape[-1]\n",
    "        # N_in = self.stride_sizes * (N_out-1) - 2*self.pad_nums + self.filter_sizes\n",
    "        dX = np.zeros((batch_size, self.input_channels, max(self.filter_sizes+N_out-1, self.input_nums)))\n",
    "        # 重みを転置して、dAとの行列積をとり、再度転置\n",
    "        calc = np.dot(self.W.T, dA).T\n",
    "        # 2はN_out\n",
    "        for i in range(N_out):\n",
    "            dX[..., i:i+self.filter_sizes] += calc[i]\n",
    "        dX = dX[..., 0:self.input_nums]\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self, dA, X)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.001):\n",
    "        self.lr = lr\n",
    "    def update(self, layer, dA, X):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        dA : 次の形のndarray, shape (self.batch_size, self.output_channels, output_nums)\n",
    "            後ろから流れてきた勾配\n",
    "        X : 次の形のndarray, shape (self.batch_size, self.input_channles, input_nums)\n",
    "            入力データ\n",
    "        \"\"\"\n",
    "        # 各勾配の計算\n",
    "        # dAのbatch_size, N_outの軸に沿って合計する\n",
    "        axis = dA.ndim-1\n",
    "        dB = dA.sum(axis=axis).sum(axis=0)\n",
    "        print('dB', dB.shape, dB)\n",
    "        \n",
    "        # 3　はfilter_size, 2は出力のサイズ(N_out)\n",
    "        output_nums = dA.shape[-1]\n",
    "        \n",
    "        # パディングの処理\n",
    "        X = layer.zero_padding_1d(X)\n",
    "        \n",
    "        indexes = np.array([[i for i in range(j, layer.stride_sizes * output_nums + j, layer.stride_sizes)] for j in range(layer.filter_sizes)])        \n",
    "        \n",
    "        dW = np.dot(dA, X[..., indexes.T]).sum(axis=2).sum(axis=0)\n",
    "        print('dW', dW.shape, dW)\n",
    "\n",
    "        # バイアス、重みの更新\n",
    "        layer.B = layer.B - dB * self.lr\n",
    "        layer.W = layer.W - dW * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 2\n",
    "output_channels = 3\n",
    "filter_sizes = 3\n",
    "stride_sizes = 1\n",
    "padding = 0\n",
    "initializer = None \n",
    "optimizer = SGD()\n",
    "conv1d = Conv1d(input_channels, output_channels, filter_sizes, stride_sizes, padding, initializer, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 初期化した重みの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       " \n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       " \n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.]]]),\n",
       " array([1, 2, 3]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インスタンス変数を呼び出す\n",
    "conv1d.W, conv1d.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### フォワードプロパゲーション\n",
    "\n",
    "$a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]]])\n",
    "# X = np.arange(32).reshape(batch_size, input_channels, 4)\n",
    "local_X = deepcopy(X)\n",
    "X.shape #　batch_size, input_channels, n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 出力数の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nums = X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 問題２で作成した関数を呼び出す\n",
    "N_out = calc_output_nums(input_nums=input_nums, pad_nums=padding, filter_sizes=filter_sizes, stride_sizes=stride_sizes)\n",
    "N_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 畳み込み計算するインデックスの取得し、最後の軸に沿ってXにインデックスを代入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = np.array([[i for i in range(j, filter_sizes+j)] for j in range(N_out)])\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1 2 3]\n",
      "   [2 3 4]]\n",
      "\n",
      "  [[2 3 4]\n",
      "   [3 4 5]]]]\n",
      "(1, 2, 2, 3)\n",
      "(batch_size, input_channels, N_out, filter_sizes)\n"
     ]
    }
   ],
   "source": [
    "print(local_X[...,indexes])\n",
    "print(local_X[...,indexes].shape)\n",
    "print('(batch_size, input_channels, N_out, filter_sizes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 畳み込み計算の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n",
      "(output_channels, input_channels, filter_sizes)\n"
     ]
    }
   ],
   "source": [
    "print(conv1d.W.shape)\n",
    "print('(output_channels, input_channels, filter_sizes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[1. 2. 3.]\n",
      "    [2. 3. 4.]]\n",
      "\n",
      "   [[2. 3. 4.]\n",
      "    [3. 4. 5.]]]\n",
      "\n",
      "\n",
      "  [[[1. 2. 3.]\n",
      "    [2. 3. 4.]]\n",
      "\n",
      "   [[2. 3. 4.]\n",
      "    [3. 4. 5.]]]\n",
      "\n",
      "\n",
      "  [[[1. 2. 3.]\n",
      "    [2. 3. 4.]]\n",
      "\n",
      "   [[2. 3. 4.]\n",
      "    [3. 4. 5.]]]]]\n",
      "(1, 3, 2, 2, 3)\n",
      "(batch_size, output_channels, input_channels, N_out, filter_sizes)\n"
     ]
    }
   ],
   "source": [
    "# 軸があるように、Xはbatchsizeの後に、Wのinput_channelsとfilter_sizesの間にaxisを追加してアダマール積をとる\n",
    "print(local_X[...,indexes][:, np.newaxis] * conv1d.W[:, :, np.newaxis])\n",
    "print((local_X[...,indexes][:, np.newaxis] * conv1d.W[:, :, np.newaxis]).shape)\n",
    "print('(batch_size, output_channels, input_channels, N_out, filter_sizes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 畳み込み計算で残したい軸以外を合計し、バイアスを足す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[16. 22.]\n",
      "  [17. 23.]\n",
      "  [18. 24.]]]\n",
      "(1, 3, 2)\n",
      "(batch_size, output_channels, N_out)\n"
     ]
    }
   ],
   "source": [
    "calc = local_X[...,indexes][:, np.newaxis] * conv1d.W[:, :, np.newaxis]\n",
    "A = calc.sum(axis=calc.ndim-1).sum(axis=calc.ndim-3) + conv1d.B[:, np.newaxis]\n",
    "print(A)\n",
    "print(A.shape)\n",
    "print('(batch_size, output_channels, N_out)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上記処理をクラスへ追加し、クラスオブジェクトで実行確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16., 22.],\n",
       "        [17., 23.],\n",
       "        [18., 24.]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# クラスオブジェクトで実行確認\n",
    "A = conv1d.forward(X)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### バックプロパゲーション "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dAはとりあえず上記で計算したAを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[16. 22.]\n",
      "  [17. 23.]\n",
      "  [18. 24.]]]\n",
      "(1, 3, 2)\n",
      "(batch_size, output_channels, N_out)\n"
     ]
    }
   ],
   "source": [
    "dA = A\n",
    "print(dA)\n",
    "print(dA.shape)\n",
    "print('(batch_size, output_channels, N_out)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dBを計算\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38. 40. 42.]\n",
      "(3,)\n",
      "(output_channels, )\n"
     ]
    }
   ],
   "source": [
    "# dAのbatch_size, N_outの軸に沿って合計する\n",
    "axis = dA.ndim-1\n",
    "dB = dA.sum(axis=axis).sum(axis=0)\n",
    "print(dB)\n",
    "print(dB.shape)\n",
    "print('(output_channels, )')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dWを計算\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_s} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}x_{(i+s)}\\$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1, 2, 3, 4],\n",
       "         [2, 3, 4, 5]]]),\n",
       " (1, 2, 4))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_X, local_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [1 2]\n",
      " [2 3]]\n",
      "(3, 2)\n",
      "(filter_sizes, N_out)\n"
     ]
    }
   ],
   "source": [
    "# 計算するためのインデックスを取得\n",
    "indexes = np.array([[i for i in range(j, N_out+j)] for j in range(filter_sizes)])\n",
    "print(indexes)\n",
    "print(indexes.shape)\n",
    "print('(filter_sizes, N_out)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1 2 3]\n",
      "   [2 3 4]]\n",
      "\n",
      "  [[2 3 4]\n",
      "   [3 4 5]]]]\n",
      "(1, 2, 2, 3)\n",
      "(batch_size, input_channels, N_out, filter_sizes)\n"
     ]
    }
   ],
   "source": [
    "# dAとdot計算させるために、indexを転置してXの最後の軸に代入\n",
    "print(local_X[..., indexes.T])\n",
    "print((local_X[..., indexes.T]).shape)\n",
    "print('(batch_size, input_channels, N_out, filter_sizes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[ 60.  98. 136.]\n",
      "    [ 98. 136. 174.]]]\n",
      "\n",
      "\n",
      "  [[[ 63. 103. 143.]\n",
      "    [103. 143. 183.]]]\n",
      "\n",
      "\n",
      "  [[[ 66. 108. 150.]\n",
      "    [108. 150. 192.]]]]]\n",
      "(1, 3, 1, 2, 3)\n",
      "(batch_size, output_channels, batch_size, input_channels, filter_sizes)\n"
     ]
    }
   ],
   "source": [
    "# dW　の計算\n",
    "dW = np.dot(dA, local_X[..., indexes.T])\n",
    "print(dW)\n",
    "print(dW.shape)\n",
    "print('(batch_size, output_channels, batch_size, input_channels, filter_sizes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 60.,  98., 136.],\n",
       "         [ 98., 136., 174.]],\n",
       " \n",
       "        [[ 63., 103., 143.],\n",
       "         [103., 143., 183.]],\n",
       " \n",
       "        [[ 66., 108., 150.],\n",
       "         [108., 150., 192.]]]),\n",
       " (3, 2, 3))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW.sum(axis=2).sum(axis=0), dW.sum(axis=2).sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dXを計算\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_j} = \\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}}w_s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]\n",
      "\n",
      " [[12 13 14]\n",
      "  [15 16 17]]]\n",
      "(3, 2, 3)\n",
      "output_channels, input_channels, filter_sizes\n"
     ]
    }
   ],
   "source": [
    "# filtersは適当なW\n",
    "filters = np.arange(output_channels*input_channels*filter_sizes).reshape(output_channels, input_channels, filter_sizes)\n",
    "print(filters)\n",
    "print(filters.shape)\n",
    "print('output_channels, input_channels, filter_sizes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[16. 22.]\n",
      "  [17. 23.]\n",
      "  [18. 24.]]]\n",
      "(1, 3, 2)\n",
      "(batch_size, output_channels, N_out)\n"
     ]
    }
   ],
   "source": [
    "print(dA)\n",
    "print(dA.shape)\n",
    "print('(batch_size, output_channels, N_out)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  6, 12],\n",
       "         [ 3,  9, 15]],\n",
       " \n",
       "        [[ 1,  7, 13],\n",
       "         [ 4, 10, 16]],\n",
       " \n",
       "        [[ 2,  8, 14],\n",
       "         [ 5, 11, 17]]]),\n",
       " (3, 2, 3))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters.T, filters.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[318., 426.]],\n",
       " \n",
       "         [[471., 633.]]],\n",
       " \n",
       " \n",
       "        [[[369., 495.]],\n",
       " \n",
       "         [[522., 702.]]],\n",
       " \n",
       " \n",
       "        [[[420., 564.]],\n",
       " \n",
       "         [[573., 771.]]]]),\n",
       " (3, 2, 1, 2))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc = np.dot(filters.T, dA)\n",
    "calc, calc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[318., 369., 420.],\n",
       "          [471., 522., 573.]]],\n",
       " \n",
       " \n",
       "        [[[426., 495., 564.],\n",
       "          [633., 702., 771.]]]]),\n",
       " (2, 1, 2, 3))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc = np.dot(filters.T, dA).T\n",
    "calc, calc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_in = stride_sizes * (N_out-1) - 2*padding + filter_sizes\n",
    "N_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 318.,  795.,  915.,  564.],\n",
       "         [ 471., 1155., 1275.,  771.]]]),\n",
       " (1, 2, 4))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2はinput_channels, 4はfilter_sizes + N_out - 1\n",
    "batch_size = local_X.shape[0]\n",
    "dX = np.zeros((batch_size, input_channels, filter_sizes+N_out-1))\n",
    "# 重みを転置して、dAとの行列積をとり、再度転置\n",
    "calc = np.dot(filters.T, dA).T\n",
    "# 2はN_out\n",
    "for i in range(N_out):\n",
    "    dX[..., i:i+filter_sizes] += calc[i]\n",
    "dX = dX[..., 0:N_in]\n",
    "dX, dX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 51., 120., 120.,  69.],\n",
       "         [ 51., 120., 120.,  69.]]]),\n",
       " (1, 2, 4))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# すべて１のWで再度dXを計算\n",
    "# 2はinput_channels, 4はfilter_sizes + N_out - 1\n",
    "batch_size = local_X.shape[0]\n",
    "dX = np.zeros((batch_size, input_channels, filter_sizes+N_out-1))\n",
    "# 重みを転置して、dAとの行列積をとり、再度転置\n",
    "calc = np.dot(conv1d.W.T, dA).T\n",
    "# 2はN_out\n",
    "for i in range(N_out):\n",
    "    dX[..., i:i+filter_sizes] += calc[i]\n",
    "dX = dX[..., 0:N_in]\n",
    "dX, dX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上記処理をクラスへ追加し、クラスオブジェクトで実行確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dB (3,) [38. 40. 42.]\n",
      "dW (3, 2, 3) [[[ 60.  98. 136.]\n",
      "  [ 98. 136. 174.]]\n",
      "\n",
      " [[ 63. 103. 143.]\n",
      "  [103. 143. 183.]]\n",
      "\n",
      " [[ 66. 108. 150.]\n",
      "  [108. 150. 192.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 51., 120., 120.,  69.],\n",
       "        [ 51., 120., 120.,  69.]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d.backward(dA, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】（アドバンス課題）パディングの実装\n",
    "\n",
    "畳み込み層にパディングの機能を加えてください。1次元配列の場合、前後にn個特徴量を増やせるようにしてください。\n",
    "\n",
    "最も単純なパディングは全て0で埋める **ゼロパディング** であり、CNNでは一般的です。他に端の値を繰り返す方法などもあります。\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができます。この機能も持たせておくと便利です。なお、NumPyにはパディングの関数が存在します。\n",
    "\n",
    "[numpy.pad — NumPy v1.17 Manual](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- パディングの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding_1d(X, padding):\n",
    "    if padding == 'SAME':\n",
    "        input_nums = X.shape[-1]\n",
    "        pad_nums = int(np.ceil((stride_sizes * (input_nums-1) - input_nums + filter_sizes) / 2))\n",
    "    elif padding == 'VALID':\n",
    "        pad_nums = 0\n",
    "    else:\n",
    "        pad_nums = padding\n",
    "    pad_width = [(0, 0) for _ in range(X.ndim-1)] + [(pad_nums, pad_nums)]\n",
    "    return np.pad(X, pad_width, 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 2, 3, 4, 0],\n",
       "        [0, 2, 3, 4, 5, 0]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_padding_1d(X, padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 4],\n",
       "        [2, 3, 4, 5]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_padding_1d(X, padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 1, 2, 3, 4, 0, 0],\n",
       "        [0, 0, 2, 3, 4, 5, 0, 0]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_padding_1d(X, padding=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上のクラスにパディング処理を追加して、フォワードプロパゲーション、バックプロパゲーションを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 2\n",
    "output_channels = 3\n",
    "filter_sizes = 3\n",
    "stride_sizes = 1\n",
    "padding = 'SAME'\n",
    "initializer = None \n",
    "optimizer = SGD()\n",
    "conv1d = Conv1d(input_channels, output_channels, filter_sizes, stride_sizes, padding, initializer, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 9., 16., 22., 17.],\n",
       "        [10., 17., 23., 18.],\n",
       "        [11., 18., 24., 19.]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = conv1d.forward(X)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_output_nums(input_nums=4, pad_nums=1, filter_sizes=3, stride_sizes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dB (3,) [64. 68. 72.]\n",
      "dW (3, 2, 3) [[[111. 175. 154.]\n",
      "  [166. 239. 201.]]\n",
      "\n",
      " [[117. 185. 163.]\n",
      "  [175. 253. 213.]]\n",
      "\n",
      " [[123. 195. 172.]\n",
      "  [184. 267. 225.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 30.,  81., 150., 174.],\n",
       "        [ 30.,  81., 150., 174.]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA = A\n",
    "conv1d.backward(dA, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】（アドバンス課題）ミニバッチへの対応\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。Conv1dクラスを複数のデータが同時に計算できるように変更してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上のクラスにバッチ数を変更できる処理を追加して、フォワードプロパゲーション、バックプロパゲーションを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 5\n",
    "input_channels = 2\n",
    "output_channels = 3\n",
    "filter_sizes = 3\n",
    "stride_sizes = 1\n",
    "padding = 0\n",
    "initializer = None \n",
    "optimizer = SGD()\n",
    "conv1d = Conv1d(input_channels, output_channels, filter_sizes, stride_sizes, padding, initializer, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch5_X = np.arange(5*2*4).reshape(5, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 19.,  25.],\n",
       "         [ 20.,  26.],\n",
       "         [ 21.,  27.]],\n",
       " \n",
       "        [[ 67.,  73.],\n",
       "         [ 68.,  74.],\n",
       "         [ 69.,  75.]],\n",
       " \n",
       "        [[115., 121.],\n",
       "         [116., 122.],\n",
       "         [117., 123.]],\n",
       " \n",
       "        [[163., 169.],\n",
       "         [164., 170.],\n",
       "         [165., 171.]],\n",
       " \n",
       "        [[211., 217.],\n",
       "         [212., 218.],\n",
       "         [213., 219.]]]),\n",
       " (5, 3, 2))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = conv1d.forward(batch5_X)\n",
    "A, A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dB (3,) [1180. 1190. 1200.]\n",
      "dW (3, 2, 3) [[[ 97425. 103325. 109225.]\n",
      "  [121025. 126925. 132825.]]\n",
      "\n",
      " [[ 98250. 104200. 110150.]\n",
      "  [122050. 128000. 133950.]]\n",
      "\n",
      " [[ 99075. 105075. 111075.]\n",
      "  [123075. 129075. 135075.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[  60.,  138.,  138.,   78.],\n",
       "        [  60.,  138.,  138.,   78.]],\n",
       "\n",
       "       [[ 204.,  426.,  426.,  222.],\n",
       "        [ 204.,  426.,  426.,  222.]],\n",
       "\n",
       "       [[ 348.,  714.,  714.,  366.],\n",
       "        [ 348.,  714.,  714.,  366.]],\n",
       "\n",
       "       [[ 492., 1002., 1002.,  510.],\n",
       "        [ 492., 1002., 1002.,  510.]],\n",
       "\n",
       "       [[ 636., 1290., 1290.,  654.],\n",
       "        [ 636., 1290., 1290.,  654.]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA = A\n",
    "conv1d.backward(dA, batch5_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】（アドバンス課題）任意のストライド数\n",
    "ストライドは1限定の実装をしてきましたが、任意のストライド数に対応できるようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上記実装にて、フォワードプロパゲーション、バックプロパゲーションを行う際にインデックスを参照してきたが、そのインデックスの取得の仕方に任意のストライド数を加味してインデックスを取得できるように実装を変更"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### フォワードプロパゲーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 変更前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes = np.array([[i for i in range(j, filter_sizes+j)] for j in range(N_out)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 変更後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes = np.array([[i for i in range(j * stride_sizes, filter_sizes+(j * stride_sizes))] for j in range(N_out)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### バックプロパゲーション"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 変更前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes = np.array([[i for i in range(j, N_out+j)] for j in range(filter_sizes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 変更後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes = np.array([[i for i in range(j, stride_sizes　*　N_out　+　j, stride_sizes)] for j in range(filter_sizes)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上のクラスにストライド数を変更に対応する処理を追加して、フォワードプロパゲーション、バックプロパゲーションを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 2\n",
    "output_channels = 3\n",
    "filter_sizes = 3\n",
    "stride_sizes = 2\n",
    "padding = 0\n",
    "initializer = None \n",
    "optimizer = SGD()\n",
    "conv1d = Conv1d(input_channels, output_channels, filter_sizes, stride_sizes, padding, initializer, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16.],\n",
       "        [17.],\n",
       "        [18.]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = conv1d.forward(X)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dB (3,) [16. 17. 18.]\n",
      "dW (3, 2, 3) [[[16. 32. 48.]\n",
      "  [32. 48. 64.]]\n",
      "\n",
      " [[17. 34. 51.]\n",
      "  [34. 51. 68.]]\n",
      "\n",
      " [[18. 36. 54.]\n",
      "  [36. 54. 72.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[51., 51., 51.,  0.],\n",
       "        [51., 51., 51.,  0.]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA = A\n",
    "conv1d.backward(dA, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.検証\n",
    "### 【問題8】学習と推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、 **平滑化** を行なってください。\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ミニバッチを取得するイテレータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = 1.0 / (1.0 + np.exp(-self.A))\n",
    "        return Z\n",
    "    def backward(self, dZ):\n",
    "        # dZとアダマール計算する値\n",
    "        tmp =  (1.0 - self.forward(self.A)) * self.forward(self.A)\n",
    "        dA = dZ * tmp\n",
    "        return dA\n",
    "\n",
    "class Tanh():\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        # dZとアダマール計算する値\n",
    "        tmp = 1.0 - np.power(self.forward(self.A), 2)\n",
    "        dA = dZ * tmp\n",
    "        return dA\n",
    "\n",
    "class ReLU():\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.maximum(self.A, 0)\n",
    "        return Z\n",
    "    def backward(self, dZ):\n",
    "        # dZとアダマール計算する値\n",
    "        tmp = np.where(self.A > 0, 1, 0)\n",
    "        dA = dZ * tmp\n",
    "        return dA\n",
    "    \n",
    "class Softmax():\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        # オーバーフローを防ぐ\n",
    "        self.A -= np.max(self.A)\n",
    "        Z = np.exp(self.A) / np.exp(self.A).sum(axis=1)[:, np.newaxis]\n",
    "        return Z\n",
    "\n",
    "    def _cross_entropy_error(self, A, y_label_one_hot):\n",
    "        error = -(np.log(self.forward(A)) * y_label_one_hot).sum(axis=1).mean()\n",
    "        return error\n",
    "\n",
    "    def backward(self, A, y_label_one_hot):\n",
    "        # 交差エントロピー誤差の計算\n",
    "        loss = self._cross_entropy_error(A, y_label_one_hot)\n",
    "        # dA　の計算\n",
    "        dA = self.forward(A) - y_label_one_hot\n",
    "        # dA, loss\n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 畳み込み層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    チャンネル数を限定しない1次元畳み込み層\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    input_channels : int\n",
    "      入力のチャンネル数\n",
    "    output_channels : int\n",
    "      出力のチャンネル数\n",
    "    filter _sizes : int\n",
    "      フィルタのサイズ\n",
    "    stride_sizes : int\n",
    "      スライドのサイズ\n",
    "    padding : int　or 'SAME' or 'VALID'\n",
    "      ある方向へのパディングする数\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels, output_channels, filter_sizes, stride_sizes, padding, initializer, optimizer, act_instance):\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.stride_sizes = stride_sizes\n",
    "        self.padding = padding\n",
    "        self.optimizer = optimizer\n",
    "        # 活性化関数のインスタンス\n",
    "        self.act_instance = act_instance\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(self.output_channels, self.input_channels, self.filter_sizes)\n",
    "        self.B = initializer.B(output_channels)\n",
    "        # optimizerがAdagradの時に使う\n",
    "        # self.H_W = np.ones((input_channels, output_channels, stride_sizes))\n",
    "        self.H_W = np.ones((self.output_channels, self.input_channels, self.filter_sizes))\n",
    "        self.H_B = np.ones(output_channels)\n",
    "    \n",
    "    def padding_nums(self, input_nums):\n",
    "        if self.padding == 'SAME':\n",
    "            pad_nums = int(np.ceil((self.stride_sizes * (input_nums-1) - input_nums + self.filter_sizes) / 2))\n",
    "        elif self.padding == 'VALID':\n",
    "            pad_nums = 0\n",
    "        else:\n",
    "            pad_nums = self.padding\n",
    "        return pad_nums\n",
    "    \n",
    "    def zero_padding_1d(self, X):\n",
    "        input_nums = X.shape[-1]\n",
    "        self.pad_nums = self.padding_nums(input_nums)\n",
    "\n",
    "        pad_width = [(0, 0) for _ in range(X.ndim-1)] + [(self.pad_nums, self.pad_nums)]\n",
    "        return np.pad(X, pad_width, 'constant')\n",
    "    \n",
    "    def calc_output_nums(self, input_nums, pad_nums, filter_sizes, stride_sizes):\n",
    "        output_nums = (input_nums + 2*pad_nums - filter_sizes) // stride_sizes + 1\n",
    "        return output_nums\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, input_channels, input_nums)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, output_channels, output_nums)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        # print('フォワードプロパゲーション')\n",
    "        self.batch_size, _, self.input_nums = X.shape\n",
    "        # パディングの処理\n",
    "        self.X = self.zero_padding_1d(X)\n",
    "        \n",
    "        # 出力する特徴量数を計算\n",
    "        output_nums = self.calc_output_nums(self.input_nums, self.pad_nums, self.filter_sizes, self.stride_sizes)\n",
    "\n",
    "        # 畳み込みで計算するインデックスを計算\n",
    "        indexes = np.array([[i for i in range(j * self.stride_sizes , self.filter_sizes + j * self.stride_sizes)] for j in range(output_nums)])\n",
    "        \n",
    "        # 畳み込みを実施\n",
    "        calc = self.X[...,indexes][:, np.newaxis] * self.W[:, :, np.newaxis]\n",
    "        A = calc.sum(axis=calc.ndim-1).sum(axis=calc.ndim-3) + self.B[:, np.newaxis]\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (self.output_channels, output_nums)\n",
    "            後ろから流れてきた勾配\n",
    "        X : 次の形のndarray, shape (self.batch_size, self.input_channles, input_nums)\n",
    "            入力データ\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # print('バックプロパゲーション ')\n",
    "        # dZを計算   \n",
    "        # batch_size = X.shape[0]\n",
    "        N_out = dA.shape[-1]\n",
    "        # dX = np.zeros((self.batch_size, self.input_channels, self.filter_sizes+N_out-1))\n",
    "        dX = np.zeros((self.batch_size, self.input_channels, max(self.filter_sizes+N_out-1, self.input_nums)))\n",
    "        # 重みを転置して、dAとの行列積をとり、再度転置\n",
    "        calc = np.dot(self.W.T, dA).T\n",
    "        # 2はN_out\n",
    "        for i in range(N_out):\n",
    "            dX[..., i:i+self.filter_sizes] += calc[i]\n",
    "            \n",
    "        # 重みを転置して、dAとの行列積をとり、再度転置\n",
    "        calc = np.dot(self.W.T, dA).T\n",
    "        # 2はN_out\n",
    "        for i in range(N_out):\n",
    "            dX[..., i:i+self.filter_sizes] += calc[i]\n",
    "        dX = dX[..., 0:self.input_nums]\n",
    "            \n",
    "        # 更新\n",
    "        self = self.optimizer.update_Conv1d(self, dA)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "    def W(self, *parameters):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        Conv1d\n",
    "            output_channels : int 出力チャネル数\n",
    "            input_channels : int 入力チャネル数\n",
    "            filter_sizes : int フィルター数\n",
    "        Affine\n",
    "            n_nodes1 : int 前の層のノード数\n",
    "            n_nodes2 : int 後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        W : shape(*parameters)\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(*parameters)\n",
    "        return W\n",
    "    def B(self, output_channels):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        Conv1d\n",
    "            output_channels : int 出力チャネル数\n",
    "        Affine\n",
    "            n_node2 : int 後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(output_channels)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    Xavierによる初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    前の層のノード数の逆数の平方根を標準偏差とする分布\n",
    "    \"\"\"\n",
    "    def W(self, *parameters):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        Conv1d\n",
    "            output_channels : int 出力チャネル数\n",
    "            input_channels : int 入力チャネル数\n",
    "            filter_sizes : int フィルター数\n",
    "        Affine\n",
    "            n_nodes1 : int 前の層のノード数\n",
    "            n_nodes2 : int 後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        W : shape(*parameters)\n",
    "        \"\"\"\n",
    "        if len(parameters) == 3:\n",
    "            sigma = np.sqrt(1 / parameters[1])\n",
    "        else:\n",
    "            sigma = np.sqrt(1 / parameters[0])\n",
    "        W = sigma * np.random.randn(*parameters)\n",
    "        return W\n",
    "        \n",
    "    def B(self, output_channels):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        Conv1d\n",
    "            output_channels : int 出力チャネル数\n",
    "        Affine\n",
    "            n_node2 : int 後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.zeros(output_channels)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heによる初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    前の層のノード数の逆数を２倍した平方根を標準偏差とする分布\n",
    "    \"\"\"\n",
    "    def W(self, *parameters):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        Conv1d\n",
    "            output_channels : int 出力チャネル数\n",
    "            input_channels : int 入力チャネル数\n",
    "            filter_sizes : int フィルター数\n",
    "        Affine\n",
    "            n_nodes1 : int 前の層のノード数\n",
    "            n_nodes2 : int 後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        W : shape(*parameters)\n",
    "        \"\"\"\n",
    "        if len(parameters) == 3:\n",
    "            sigma = np.sqrt(2 / parameters[1])\n",
    "        else:\n",
    "            sigma = np.sqrt(2 / parameters[0])\n",
    "        W = sigma * np.random.randn(*parameters)\n",
    "        return W\n",
    "        \n",
    "    def B(self, output_channels):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        Conv1d\n",
    "            output_channels : int 出力チャネル数\n",
    "        Affine\n",
    "            n_node2 : int 後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.zeros(output_channels)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.001):\n",
    "        self.lr = lr\n",
    "    def update_Conv1d(self, layer, dA):\n",
    "        \"\"\"\n",
    "        Conv1d層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        dA : 次の形のndarray, shape (self.batch_size, self.output_channels, output_nums)\n",
    "            後ろから流れてきた勾配\n",
    "        \"\"\"\n",
    "        # 各勾配の計算\n",
    "        # dAのbatch_size, N_outの軸に沿って合計する\n",
    "        axis = dA.ndim-1\n",
    "        dB = dA.sum(axis=axis).sum(axis=0)\n",
    "        \n",
    "        output_nums = dA.shape[-1]\n",
    "                \n",
    "        indexes = np.array([[i for i in range(j, layer.stride_sizes * output_nums + j, layer.stride_sizes)] for j in range(layer.filter_sizes)])\n",
    "        \n",
    "        dW = np.dot(dA, layer.X[..., indexes.T]).sum(axis=2).sum(axis=0)\n",
    "\n",
    "        # バイアス、重みの更新\n",
    "        layer.B = layer.B - dB * self.lr\n",
    "        layer.W = layer.W - dW * self.lr\n",
    "\n",
    "    def update_FC(self, layer, dA):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        dA : 後ろから流れてきた勾配\n",
    "        \"\"\"\n",
    "        # バイアスの更新\n",
    "        dB = dA.sum(axis=0)\n",
    "        layer.B -= dB * self.lr\n",
    "        # 重みの更新\n",
    "        dW = np.dot(layer.X.T, dA)\n",
    "        layer.W -= dW * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    更新された分だけ、その重みに対する学習率を下げていく\n",
    "    Parameters\n",
    "    --------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.001):\n",
    "        self.lr = lr\n",
    "    def update_Conv1d(self, layer, dA):\n",
    "        \"\"\"\n",
    "        Conv1d層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        dA : 次の形のndarray, shape (self.batch_size, self.output_channels, output_nums)\n",
    "            後ろから流れてきた勾配\n",
    "        X : 次の形のndarray, shape (self.batch_size, self.input_channles, input_nums)\n",
    "            入力データ\n",
    "        H_B, H_W : class_Conv1dで初期値1で作成\n",
    "        \"\"\"\n",
    "        # 各勾配の計算\n",
    "        # dAのbatch_size, N_outの軸に沿って合計する\n",
    "        axis = dA.ndim-1\n",
    "        dB = dA.sum(axis=axis).sum(axis=0)\n",
    "        layer.H_B += np.power(dB, 2)\n",
    "        \n",
    "        # 3　はfilter_size, 2は出力のサイズ(N_out)\n",
    "        output_nums = dA.shape[-1]\n",
    "        \n",
    "        indexes = np.array([[i for i in range(j, layer.stride_sizes * output_nums + j, layer.stride_sizes)] for j in range(layer.filter_sizes)])        \n",
    "\n",
    "        dW = np.dot(dA, layer.X[..., indexes.T]).sum(axis=2).sum(axis=0)\n",
    "        layer.H_W += np.power(dW, 2)\n",
    "        \n",
    "        # バイアス、重みの更新\n",
    "        layer.B = layer.B - dB * self.lr / np.sqrt(layer.H_B)\n",
    "        layer.W = layer.W - dW * self.lr / np.sqrt(layer.H_W)\n",
    "\n",
    "    def update_FC(self, layer, dA):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        dA : 後ろから流れてきた勾配\n",
    "        H_B, H_W : class_FCで初期値1で作成\n",
    "        \"\"\"\n",
    "        # バイアスの更新\n",
    "        dB = dA.sum(axis=0)\n",
    "        layer.H_B += np.power(dB, 2)\n",
    "        layer.B -= dB * self.lr / np.sqrt(layer.H_B)\n",
    "        \n",
    "        # 重みの更新\n",
    "        dW = np.dot(layer.X.T, dA)\n",
    "        layer.H_W += np.power(dW, 2)\n",
    "        layer.W -= dW * self.lr / np.sqrt(layer.H_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 平滑化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \"\"\"\n",
    "    平滑化する処理\n",
    "    forwardのshape\n",
    "        self.forward(X) X: (batch_size, input_channels, output_nums)\n",
    "        return flat_X : (batch_size, input_channels * output_nums)\n",
    "    backwardのshape\n",
    "        self.backward(dX) dX: (batch_size, input_channels * output_nums)\n",
    "        return original_dX : (batch_size, input_channels, output_nums)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.shape = None\n",
    "    def forward(self, X):\n",
    "        self.shape = X.shape\n",
    "        flat_X = X.reshape(self.shape[0], np.prod(self.shape[1:]))\n",
    "        return flat_X\n",
    "    def backward(self, dX):\n",
    "        original_dX = dX.reshape(self.shape)\n",
    "        return original_dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 全結合層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, act_instance):\n",
    "        self.optimizer = optimizer\n",
    "        # 活性化関数のインスタンス\n",
    "        self.act_instance = act_instance\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        # optimazer がadagradの際に使用する\n",
    "        self.H_W = np.ones((n_nodes1, n_nodes2))\n",
    "        self.H_B = np.ones(n_nodes2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        A = np.dot(self.X, self.W) + self.B\n",
    "        return A\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            一層前の活性化関数の出力結果\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # dZを計算\n",
    "        dZ = np.dot(dA, self.W.T)\n",
    "        # 更新\n",
    "        self = self.optimizer.update_FC(self, dA)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1次元の畳み込みニューラルネットワーク分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import time\n",
    "class ScratchCNN1dNeuralNetworkClassifier():\n",
    "    \"\"\"\n",
    "    多層な1次元の畳み込みニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    -----\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_layer_sizes=[400, 200], verbose=False, random_state=None, activation='relu', epoch=10, batch_size=20, lr=10e-3, initialize=None, sigma=None, optimize='adagrad',filter_sizes=[3, 3], stride_sizes=[1, 1], padding=['SAME', 'VALID']):\n",
    "        self.verbose = verbose\n",
    "        # 乱数の設定\n",
    "        self.random_state = random_state\n",
    "        # 活性化関数の名前　'sigmoid', 'tanh', 'relu'\n",
    "        self.activation = activation\n",
    "        # epochの回数\n",
    "        self.epoch = epoch\n",
    "        # バッチサイズ\n",
    "        self.batch_size = batch_size\n",
    "        # 学習率\n",
    "        self.lr = lr\n",
    "        # 全結合層のノード数のタプル\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        # 乱数の設定\n",
    "        self.random_state = random_state\n",
    "        # 初期値の設定方法 'gauss', 'xavier', 'he'\n",
    "        self.initialize = initialize\n",
    "        # 初期値をガウス分布で定める際の標準偏差\n",
    "        self.sigma = sigma\n",
    "        # 最適化手法 'sgd', 'adagrad'\n",
    "        self.optimize = optimize\n",
    "        \n",
    "        # 一次元の畳み込み層　以下変数のサイズで畳み込みを行う層が決まる\n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.stride_sizes = stride_sizes\n",
    "        self.padding = padding\n",
    "        \n",
    "        # 出力クラス数\n",
    "        self.n_output = None\n",
    "        # 出力カテゴリの配列\n",
    "        self.categories_ = None\n",
    "        # 重みの情報リスト\n",
    "        # self.coefs_ = None\n",
    "        # self.intercepts_ = None\n",
    "        # epoch毎に損失を記録\n",
    "        self.losses = np.zeros(self.epoch)\n",
    "        self.val_losses = None\n",
    "        # fitの時にvalデータがあるフラグ\n",
    "        self.val_flag = None\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : 次の形のndarray, shape (n_samples, input_channels, n_features)\n",
    "            訓練データの特徴量\n",
    "        y_train : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, input_channels, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # random_stateが設定されている場合はseed設定\n",
    "        if type(self.random_state) == int:\n",
    "            np.random.seed(self.random_state)\n",
    "        # 特徴量データがinput_channels１で, ndimが２の時、input_channelsの次元を追加\n",
    "        if X_train.ndim == 2:\n",
    "            X_train = X_train[:, np.newaxis]\n",
    "        if X_val.ndim == 2:\n",
    "            X_val = X_val[:, np.newaxis]\n",
    "        \n",
    "        # 変数情報\n",
    "        self.n_samples, input_channels, self.n_features = X_train.shape\n",
    "        # valデータの確認\n",
    "        if type(X_val) == np.ndarray and type(y_val) == np.ndarray:\n",
    "            if X_val.shape == (y_val.shape[0], input_channels, self.n_features):\n",
    "                self.val_flag = True\n",
    "                self.val_losses = np.zeros(self.epoch)\n",
    "        \n",
    "        # 目的変数をone_hot_encoding\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "        if self.val_flag:\n",
    "            y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "        \n",
    "        # 出力カテゴリの配列\n",
    "        self.categories_ = enc.categories_[0]\n",
    "        # 出力クラス数を特定\n",
    "        self.n_output = len(self.categories_)\n",
    "        \n",
    "        \n",
    "        # 畳み込み層のインスタンス作成\n",
    "        input_nums = self.n_features\n",
    "        self.conv1d_lst = []\n",
    "        for filter_sizes, stride_sizes, padding in zip(self.filter_sizes, self.stride_sizes, self.padding):\n",
    "            # 活性化関数のインスタンス\n",
    "            if self.activation == 'relu':\n",
    "                act_instance = ReLU()\n",
    "            elif self.activation == 'sigmoid':\n",
    "                act_instance = Sigmoid()\n",
    "            elif self.activation == 'tanh':\n",
    "                act_instance = Tanh()\n",
    "            else:\n",
    "                print('not proper activation name')\n",
    "                \n",
    "            # 初期化のインスタンス作成\n",
    "            # initializeで指定がない時、sigmoid, tanhではxavier, reluではhe\n",
    "            if self.initialize is None:\n",
    "                if self.activation == 'relu':\n",
    "                    self.initialize = 'he'\n",
    "                elif self.activation == 'sigmoid' or self.activation == 'tanh':\n",
    "                    self.initialize = 'xavier'\n",
    "            # self.initializeに応じてinitializerのインスタンスを作成\n",
    "            if self.initialize == 'he':\n",
    "                initializer = HeInitializer()\n",
    "            elif self.initialize == 'xavier':\n",
    "                initializer = XavierInitializer()\n",
    "            elif self.initialize == 'gauss':\n",
    "                if self.sigma is None:\n",
    "                    self.sigma = 0.01\n",
    "                    initializer = SimpleInitializer(self.sigma)\n",
    "            # 最適化のインスタンス作成\n",
    "            if self.optimize == 'adagrad':\n",
    "                optimizer = AdaGrad(self.lr)\n",
    "            elif self.optimize == 'sgd':\n",
    "                optimizer = SGD(self.lr) \n",
    "            \n",
    "            conv1d = Conv1d(input_channels=input_channels, output_channels=input_channels,\n",
    "                            filter_sizes=filter_sizes, stride_sizes=stride_sizes, padding=padding,\n",
    "                            initializer=initializer, optimizer=optimizer, act_instance=act_instance)\n",
    "            \n",
    "            self.conv1d_lst.append(conv1d)\n",
    "            \n",
    "            # 畳み込み層後の出力サイズを計算\n",
    "            pad_nums = conv1d.padding_nums(input_nums)\n",
    "            output_nums = conv1d.calc_output_nums(input_nums, pad_nums, filter_sizes, stride_sizes)\n",
    "            input_nums = output_nums\n",
    "        fc_input_features = input_nums * conv1d.output_channels\n",
    "                \n",
    "        # 全結合層のインスタンス作成\n",
    "        self.fc_lst = []\n",
    "        for n_nodes in self.hidden_layer_sizes:\n",
    "            # 活性化関数のインスタンス\n",
    "            if self.activation == 'relu':\n",
    "                act_instance = ReLU()\n",
    "            elif self.activation == 'sigmoid':\n",
    "                act_instance = Sigmoid()\n",
    "            elif self.activation == 'tanh':\n",
    "                act_instance = Tanh()\n",
    "            else:\n",
    "                print('not proper activation name')\n",
    "                \n",
    "            # 初期化のインスタンス作成\n",
    "            # initializeで指定がない時、sigmoid, tanhではxavier, reluではhe\n",
    "            if self.initialize is None:\n",
    "                if self.activation == 'relu':\n",
    "                    self.initialize = 'he'\n",
    "                elif self.activation == 'sigmoid' or self.activation == 'tanh':\n",
    "                    self.initialize = 'xavier'\n",
    "            # self.initializeに応じてinitializerのインスタンスを作成\n",
    "            if self.initialize == 'he':\n",
    "                initializer = HeInitializer()\n",
    "            elif self.initialize == 'xavier':\n",
    "                initializer = XavierInitializer()\n",
    "            elif self.initialize == 'gauss':\n",
    "                if self.sigma is None:\n",
    "                    self.sigma = 0.01\n",
    "                    initializer = SimpleInitializer(self.sigma)\n",
    "            # 最適化のインスタンス作成\n",
    "            if self.optimize == 'adagrad':\n",
    "                optimizer = AdaGrad(self.lr)\n",
    "            elif self.optimize == 'sgd':\n",
    "                optimizer = SGD(self.lr) \n",
    "            \n",
    "            fc = FC(n_nodes1=fc_input_features, n_nodes2=n_nodes,\n",
    "                    initializer=initializer, optimizer=optimizer, act_instance=act_instance)\n",
    "            self.fc_lst.append(fc)\n",
    "            fc_input_features = n_nodes\n",
    "            \n",
    "            # 最終出力層のインスタンス\n",
    "            self.last_layer = FC(n_nodes1=fc_input_features, n_nodes2=self.n_output,\n",
    "                            initializer=HeInitializer(), optimizer=SGD(),\n",
    "                            act_instance=Softmax())\n",
    "\n",
    "            \n",
    "        # 各層のインスタンス内で変数が書き換えられるので、valから計算する\n",
    "        # epoch　でループ\n",
    "        for n_epoch in range(self.epoch):\n",
    "            start = time.time()\n",
    "            # 各々のバッチの損失の記録\n",
    "            if self.val_flag:\n",
    "                batches_val_losses = np.zeros(int(np.ceil(self.n_samples / self.batch_size)), dtype=np.float64)\n",
    "            batches_losses = np.zeros(int(np.ceil(self.n_samples / self.batch_size)), dtype=np.float64)\n",
    "                        \n",
    "            # バッチを取り出し、バッチでループ\n",
    "            get_mini_batch = GetMiniBatch(X_train, y_train_one_hot, batch_size=self.batch_size)\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                \n",
    "                # forward propagation\n",
    "                if self.val_flag:\n",
    "                    Z_val = X_val\n",
    "                    for i in range(len(self.conv1d_lst)):\n",
    "                        A_val = self.conv1d_lst[i].forward(Z_val)\n",
    "                        Z_val = self.conv1d_lst[i].act_instance.forward(A_val)\n",
    "                    \n",
    "                    # 畳み込み層が終わったら平滑化\n",
    "                    flat_val = Flatten()\n",
    "                    Z_val = flat_val.forward(Z_val)\n",
    "                \n",
    "                    # 全結合層をループ\n",
    "                    for i in range(len(self.fc_lst)):\n",
    "                        A_val = self.fc_lst[i].forward(Z_val)\n",
    "                        Z_val = self.fc_lst[i].act_instance.forward(A_val)\n",
    "                \n",
    "                    # 最後の出力層\n",
    "                    A_val = self.last_layer.forward(Z_val)\n",
    "                    \n",
    "                    # SoftMaxback_propagation, 損失記録\n",
    "                    _, batches_val_losses[get_mini_batch._counter - 1] = self.last_layer.act_instance.backward(A_val, y_val_one_hot)\n",
    "                \n",
    "                # train_data\n",
    "                Z = mini_X_train\n",
    "                for i in range(len(self.conv1d_lst)):\n",
    "                    A = self.conv1d_lst[i].forward(Z)\n",
    "                    Z = self.conv1d_lst[i].act_instance.forward(A)\n",
    "                    \n",
    "                # 畳み込み層が終わったら平滑化\n",
    "                flat = Flatten()\n",
    "                Z = flat.forward(Z)\n",
    "                \n",
    "                # 全結合層をループ\n",
    "                for i in range(len(self.fc_lst)):\n",
    "                    A = self.fc_lst[i].forward(Z)\n",
    "                    Z = self.fc_lst[i].act_instance.forward(A)\n",
    "                \n",
    "                # 最後の出力層\n",
    "                A = self.last_layer.forward(Z)\n",
    "                    \n",
    "                # SoftMaxback_propagation, 損失記録\n",
    "                dA, batches_losses[get_mini_batch._counter - 1] = self.last_layer.act_instance.backward(A, mini_y_train)\n",
    "                \n",
    "                # back propagation\n",
    "                dZ = self.last_layer.backward(dA)\n",
    "                \n",
    "                # fcを逆順で取り出す\n",
    "                for i in range(len(self.fc_lst)):\n",
    "                    dA = self.fc_lst[-(i+1)].act_instance.backward(dZ)\n",
    "                    dZ = self.fc_lst[-(i+1)].backward(dA)\n",
    "                \n",
    "                # flattenのback\n",
    "                dZ = flat.backward(dZ)\n",
    "                \n",
    "                # conv1dを逆順で取り出す\n",
    "                for i in range(len(self.conv1d_lst)):\n",
    "                    dA = self.conv1d_lst[-(i+1)].act_instance.backward(dZ)\n",
    "                    dZ = self.conv1d_lst[-(i+1)].backward(dA)\n",
    "  \n",
    "            #　バッチのループが終わったら損失を合計し、記録\n",
    "            self.losses[n_epoch] = batches_losses.sum()\n",
    "            if self.val_flag:\n",
    "                self.val_losses[n_epoch] = batches_val_losses.sum()\n",
    "        \n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            if self.verbose is True:\n",
    "                print('epoch : {} finished'.format(n_epoch))\n",
    "                print(\"time : {:,.1f}[s]\".format(time.time() - start))\n",
    "                print('train_loss : {}'.format(self.losses[n_epoch]))\n",
    "                if self.val_flag:\n",
    "                    print('val_loss : {}'.format(self.val_losses[n_epoch]))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        # 特徴量データがinput_channels１で, ndimが２の時、input_channelsの次元を追加\n",
    "        if X.ndim == 2:\n",
    "            X = X[:, np.newaxis]\n",
    "        \n",
    "        # 活性化関数の出力結果をpredで管理\n",
    "        pred = X\n",
    "\n",
    "        # 各層をループ\n",
    "        for conv1d in self.conv1d_lst:\n",
    "            A = conv1d.forward(pred)\n",
    "            pred = conv1d.act_instance.forward(A)\n",
    "        \n",
    "        # 平滑化\n",
    "        pred = Flatten().forward(pred)\n",
    "        \n",
    "        # 全結合層\n",
    "        for fc in self.fc_lst:\n",
    "            A = fc.forward(pred)\n",
    "            pred = fc.act_instance.forward(A)\n",
    "        \n",
    "        # 最終出力層\n",
    "        A = self.last_layer.forward(pred)\n",
    "        pred = self.last_layer.act_instance.forward(A)\n",
    "        \n",
    "        # 列、横方向に最大のインデックスを取得し、出力カテゴリのself.categories_の値を返す\n",
    "        return self.categories_[np.argmax(pred, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 検証結果をアウトプットする関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定しているパラメーターの表示\n",
    "def display_params(clf):\n",
    "    parameters = deepcopy(vars(clf))\n",
    "    delete_params = ['verbose', 'n_output', 'categories_', 'coefs_', 'intercepts_', 'losses', 'val_losses', 'val_flag', 'n_samples', 'n_features', 'act', 'last_act']\n",
    "    for params in delete_params:\n",
    "        del parameters[params]\n",
    "    print('Paremeters : ')\n",
    "    print(parameters)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy_scoreの計算\n",
    "from sklearn.metrics import accuracy_score\n",
    "def acc_score(X_test, y_test, clf):\n",
    "    score = accuracy_score(y_test, clf.predict(X_test))\n",
    "    print('Accuracy_score : {}'.format(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# 損失関数のプロット\n",
    "def loss_plot(clf):\n",
    "    plt.plot(range(clf.epoch), clf.losses, label='train_loss')\n",
    "    if clf.val_flag:\n",
    "        plt.plot(range(clf.epoch), clf.val_losses, label='val_loss')\n",
    "    plt.xlabel('n_epoch')\n",
    "    plt.title('model_loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTデータの誤分類結果を表示する\n",
    "def miss_class_imshow(y_pred, y_val, X_val, num, n_columns = 6):\n",
    "    \"\"\"\n",
    "    誤分類結果を並べて表示する。画像の上の表示は「推定結果/正解」である。\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y_pred : 推定値のndarray (n_samples,)\n",
    "    y_val : 検証データの正解ラベル(n_samples,)\n",
    "    X_val : 検証データの特徴量（n_samples, n_features)\n",
    "    num : 表示する数\n",
    "    n_columns : 表示する列数\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    true_false = y_pred==y_val\n",
    "    false_list = np.where(true_false==False)[0].astype(np.int)\n",
    "    if false_list.shape[0] < num:\n",
    "        num = false_list.shape[0]\n",
    "    fig = plt.figure(figsize=(16, (num-1//n_columns + 1)*(16 / n_columns)))\n",
    "    fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
    "    for i in range(num):\n",
    "        ax = fig.add_subplot(num-1//n_columns + 1, n_columns, i + 1, xticks=[], yticks=[])\n",
    "        ax.set_title(\"pred:{} / ans:{}\".format(y_pred[false_list[i]],y_val[false_list[i]]))\n",
    "        ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_classification(n_samples=1000, random_state=1)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train3 = scaler.fit_transform(X_train3)\n",
    "X_test3 = scaler.transform(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 1.8[s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cnn1d = ScratchCNN1dNeuralNetworkClassifier(hidden_layer_sizes=[400, 200], verbose=False, random_state=None, activation='relu', epoch=10, batch_size=20, lr=10e-3, initialize=None, sigma=None, optimize='adagrad',filter_sizes=[3, 3], stride_sizes=[1, 2], padding=['SAME', 0])\n",
    "cnn1d.fit(X_train3, y_train3, X_test3, y_test3)\n",
    "print(\"time : {:,.1f}[s]\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score : 0.656\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEXCAYAAAC06B/dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXRc5Znn8e8jVUmlfbHlTbYky8YLtsGO5QXMYkLCvmSAAAmEZbrDkIUAAxmSTPdMkhPmpCc0SbqHhpCGrO6wk0CHAIFgzGawZAxYtsHYSLZsvGu1tdc7f9zSZkuWZEu6qqrf55w6Vbp1b9Wjwvx067nvfa855xARkeiT4HcBIiJybBTgIiJRSgEuIhKlFOAiIlFKAS4iEqUU4CIiUUoBLiISpRTgEtPM7Ndm9qMBrlthZp/rZ53vm9nvh6Y6keOjABcRiVIKcBGRKKUAl1Eh0r74tpm9b2YHzewhMxtvZn8xs3oze8nMciLrXmJm5WZWY2YrzWx2t9dZYGZrI9s8CoQOe5+LzGxdZNs3zeyk46z7aLXcZWY7IrV8aGZnR5YvNrNSM6szs91mdu/x1CDxSwEuo8nlwOeBGcDFwF+A7wFj8f6tfsvMZgB/AG4D8oDngGfNLMnMkoA/Ar8DcoHHI68JgJl9BngY+G/AGOAXwDNmlnwsxfZTy0zgm8Ai51wGcC5QEdn058DPnXOZwDTgsWN5fxEFuIwm/+qc2+2c2wG8BrztnHvXOdcMPA0sAK4C/uyc+6tzrhW4B0gBTgWWAkHgZ865VufcE8Cabq//VeAXzrm3nXPtzrnfAM2R7Y7F0WppB5KBE80s6JyrcM5tiWzXCkw3s7HOuQbn3OpjfH+JcwpwGU12d3vc2MvP6cAkoLJjoXMuDGwH8iPP7XA9p9is7Pa4ELgj0u6oMbMaYEpku2PRZy3OuY/x9sy/D+wxs0fMrON9/g7vW8YmM1tjZhcd4/tLnFOAS7TZiRfEAJiZ4YXwDuBTID+yrENBt8fbgbudc9ndbqnOuT8MQy045/7DOXdaZB0H/FNk+Wbn3JeAcZFlT5hZ2jHWIHFMAS7R5jHgQjM728yCwB14bZA3gbeANrxeecDMLgMWd9v2l8DNZrbEPGlmdqGZZQx1LWY208w+G+mvN+F9g2gHMLNrzSwvssdeE3mt9mOsQeKYAlyiinPuQ+Ba4F+BfXgHOy92zrU451qAy4AbgGq8HvVT3bYtxeuD/7/I8x9H1h3yWvD63z+OLN+Ft7f9vcim5wHlZtaAd0Dzaudc07HWIfHLdEUeEZHopD1wEZEopQAXOUzk5KGGXm7f639rkZGjFoqISJQKjOSbjR071hUVFY3kW4qIRL2ysrJ9zrm8w5ePaIAXFRVRWlo6km8pIhL1zKyyt+XqgYuIRCkFuIhIlFKAi4hEqRHtgYtI7GltbaWqqoqmJp1MerxCoRCTJ08mGAwOaH0FuIgcl6qqKjIyMigqKqLnPGIyGM459u/fT1VVFVOnTh3QNmqhiMhxaWpqYsyYMQrv42RmjBkzZlDfZBTgInLcFN5DY7CfY3QE+PY1UPYbv6sQERlVoiPA1z8Bf7kL2pr9rkREZNSIjgAvXg5tjbD9Hb8rEZFRpqamhn/7t38b9HYXXHABNTU1/a94mBtuuIEnnnhi0NsNh+gI8MJlYImwdaXflYjIKNNXgLe3H/0iR8899xzZ2dnDVdaIiI5hhKFMmFziBfjZ/+h3NSLShx88W86GnXVD+ponTsrkf188p8/nv/Od77Blyxbmz59PMBgkPT2diRMnsm7dOjZs2MAXvvAFtm/fTlNTE7feeis33XQT0DU3U0NDA+effz6nnXYab775Jvn5+fzpT38iJSWl39pefvll7rzzTtra2li0aBH3338/ycnJfOc73+GZZ54hEAhwzjnncM899/D444/zgx/8gMTERLKysli1atVxfzZREeC/e6uCsYdmcf6B30FjNaTk+F2SiIwSP/7xj1m/fj3r1q1j5cqVXHjhhaxfv75zLPXDDz9Mbm4ujY2NLFq0iMsvv5wxY8b0eI3Nmzfzhz/8gV/+8pdceeWVPPnkk1x77bVHfd+mpiZuuOEGXn75ZWbMmMF1113H/fffz3XXXcfTTz/Npk2bMLPONs0Pf/hDXnjhBfLz84+pddObqAjw/QdbePbTQs5PCkPF6zD7Yr9LEpFeHG1PeaQsXry4x4kw//Iv/8LTTz8NwPbt29m8efMRAT516lTmz58PwMKFC6moqOj3fT788EOmTp3KjBkzALj++uu57777+OY3v0koFOLv//7vufDCC7nooosAWLZsGTfccANXXnkll1122VD8qtHRAy8pzOXd8HTaA6nqg4vIUaWlpXU+XrlyJS+99BJvvfUW7733HgsWLOj1RJnk5OTOx4mJibS1tfX7Pn1dDCcQCPDOO+9w+eWX88c//pHzzjsPgAceeIAf/ehHbN++nfnz57N///7B/mpHvtdxv8IImF+QTTghSGX6AooV4CLSTUZGBvX19b0+V1tbS05ODqmpqWzatInVq1cP2fvOmjWLiooKPv74Y6ZPn87vfvc7zjzzTBoaGjh06BAXXHABS5cuZfr06QBs2bKFJUuWsGTJEp599lm2b99+xDeBwYqKAE9PDjB7Ygavt86luOYNqNkO2VP8LktERoExY8awbNky5s6dS0pKCuPHj+987rzzzuOBBx7gpJNOYubMmSxdunTI3jcUCvGrX/2KL37xi50HMW+++WYOHDjApZdeSlNTE845fvrTnwLw7W9/m82bN+Oc4+yzz+bkk08+7hpG9JqYJSUl7livyPP9Z8pZu+YNnkn8Nlx6Hyw4+gEGERkZGzduZPbs2X6XETN6+zzNrMw5V3L4ulHRAwcoKcrh/dZJtKbkqQ8uIkKUtFDAO5AJRmXWIqZvXQnOgSbQEZFh8o1vfIM33nijx7Jbb72VG2+80aeKjhQ1AT4hK8TknBTeCM9l+sHnYM8GGO//kCURiU333Xef3yX0K2paKAAlhTk8fmCa94PaKCIS56IrwItyWd+QQWv2NAW4iMS9KAtw7xT6bdmLoeINaGvxuSIREf9EVYDPGJdBRijAm24etB6EqjV+lyQi4puoCvCEBGNhYQ5PHigCS1AbRUQGLT09vc/nKioqmDt37ghWc3yiKsABFhXlsm4vtE1YoAAXkbgWNcMIOyws9Prg23MWM3Xjg9BUC6Esn6sSEQD+8h3Y9cHQvuaEeXD+j/t8+q677qKwsJCvf/3rAHz/+9/HzFi1ahXV1dW0trbyox/9iEsvvXRQb9vU1MTXvvY1SktLCQQC3HvvvZx11lmUl5dz44030tLSQjgc5sknn2TSpElceeWVVFVV0d7ezj/+4z9y1VVXHdevPRBRF+AnT84mkGC8xUlMde3ewcxZF/hdloj45Oqrr+a2227rDPDHHnuM559/nttvv53MzEz27dvH0qVLueSSSwZ11feOceAffPABmzZt4pxzzuGjjz7igQce4NZbb+Waa66hpaWF9vZ2nnvuOSZNmsSf//xnwJtEayREXYCnJCUyNz+LZ/en8uVgZHpZBbjI6HCUPeXhsmDBAvbs2cPOnTvZu3cvOTk5TJw4kdtvv51Vq1aRkJDAjh072L17NxMmTBjw677++uvccsstgDfzYGFhIR999BGnnHIKd999N1VVVVx22WWccMIJzJs3jzvvvJO77rqLiy66iNNPP324ft0e+u2Bm1nIzN4xs/fMrNzMfhBZPtXM3jazzWb2qJklDX+5npLCHMp2NBIuOEV9cBHhiiuu4IknnuDRRx/l6quvZsWKFezdu5eysjLWrVvH+PHje50H/Gj6mujvy1/+Ms888wwpKSmce+65/O1vf2PGjBmUlZUxb948vvvd7/LDH/5wKH6tfg3kIGYz8Fnn3MnAfOA8M1sK/BPwU+fcCUA18HfDV2ZPJUW5tLSF2ZG7BPZ9CHU7R+qtRWQUuvrqq3nkkUd44oknuOKKK6itrWXcuHEEg0FeeeUVKisrB/2aZ5xxBitWrADgo48+Ytu2bcycOZOtW7dSXFzMt771LS655BLef/99du7cSWpqKtdeey133nkna9euHepfsVf9BrjzNER+DEZuDvgs8ERk+W+ALwxLhb3oOJC5mpO8BVtfHam3FpFRaM6cOdTX15Ofn8/EiRO55pprKC0tpaSkhBUrVjBr1qxBv+bXv/512tvbmTdvHldddRW//vWvSU5O5tFHH2Xu3LnMnz+fTZs2cd111/HBBx+wePFi5s+fz913380//MM/DMNveaQBzQduZolAGTAduA/4CbDaOTc98vwU4C/OuSMGUJrZTcBNAAUFBQuP5S9hb866ZyUn5KXy4O4vwfTPwWW/GJLXFZHB0XzgQ2vI5wN3zrU75+YDk4HFQG//tXr9S+Cce9A5V+KcK8nLyxvI2w3IwsIcSrfV4orP9PrgI3hhChGR0WBQJ/I452qAlcBSINvMOkaxTAZGtBG9qCiHAwdb2Jt3CjTsgr2bRvLtRSSKffDBB8yfP7/HbcmSJX6XNWj9DiM0szyg1TlXY2YpwOfwDmC+AlwBPAJcD/xpOAs93MLCXADeZh4Xg7cXPk5f40T84Jwb1Bhrv82bN49169b5XcYRBnuJy4HsgU8EXjGz94E1wF+dc/8J3AX8dzP7GBgDPDTIWo/LtLw0clKDrNqTArnFGk4o4pNQKMT+/fsHHT7Sk3OO/fv3EwqFBrxNv3vgzrn3gQW9LN+K1w/3hZmxsDCX0spqmLUc3n8M2lshMehXSSJxafLkyVRVVbF3716/S4l6oVCIyZMnD3j9qDsTs7uSohxe2ribukmnkVn6MOwog4KlfpclEleCwSBTp071u4y4FHWzEXa3KHKBh3eYC5jaKCISV6I6wOfmZ5EUSODtT9thkqaXFZH4EtUBnhxI5OTJWV4fvHi5d4We5nq/yxIRGRFRHeDgDSdcv6OWlsIzINwGlW/6XZKIyIiI+gAvKcyhtd2xjpkQCKmNIiJxI+oDvGNiqzVVh6DgFNjyis8ViYiMjKgP8Jy0JKaPS6e04oDXB9+7Eep3+V2WiMiwi/oAB284YVllNeGpZ3oLNL2siMSBmAjwhYW51DW1sTmhGFJy1AcXkbgQEwHecUJP6bYamKrpZUUkPsREgBfkpjI2PZnSish48PqdsG+z32WJiAyrmAhwM2NRUQ6llQdg2lneQrVRRCTGxUSAgzeccPuBRnYnToCcIgW4iMS8mAnwkiLvAg+dbZSK16C9zdeaRESGU8wE+JxJmYSCCazpGA/eXAc73/W7LBGRYRMzAR5MTGD+lGzKKquh6Aw0vayIxLqYCXCARUW5bPi0joOBLJh4EmzVafUiErtiKsAXFubQHnas217jtVG2vwPNDX6XJSIyLGIqwD9TmINZtwOZ4VbY9pbfZYmIDIuYCvDMUJCZ4zO88eAFp0BisvrgIhKzYirAweuDr62spi0hGQqWKMBFJGbFXICXFOVwsKWdTbvqvTbK7vXQsMfvskREhlzMBXjHBR7KKquhOHJa/SerfKxIRGR4xFyA52enMDEr5J3QM/FkCGVrOKGIxKSYC3AzY2FhDqUV1ThLgKlnwJaVml5WRGJOzAU4eAcyd9U1saOm0euD11XBga1+lyUiMqRiMsB79sGXewvVRhGRGBOTAT5rQgbpyQHvhJ7cYsgq0NXqRSTmxGSABxITWFCQ7R3INIPiM+GT1yDc7ndpIiJDpt8AN7MpZvaKmW00s3IzuzWyfL6ZrTazdWZWamaLh7/cgSspzOXD3fXUNbVGppethZ3r/C5LRGTIDGQPvA24wzk3G1gKfMPMTgT+L/AD59x84H9Ffh41SopycA7WVlZ7FzoG9cFFJKb0G+DOuU+dc2sjj+uBjUA+4IDMyGpZwM7hKvJYzJ+STWKCeQcy0/Ng/DydVi8iMSUwmJXNrAhYALwN3Aa8YGb34P0hOLWPbW4CbgIoKCg4jlIHJy05wIkTM70+OHh98HcehJZDkJQ6YnWIiAyXAR/ENLN04EngNudcHfA14Hbn3BTgduCh3rZzzj3onCtxzpXk5eUNRc0DtrAwh3Xba2htD3tXq29v0fSyIhIzBhTgZhbEC+8VzrmnIouvBzoePw6MqoOY4J3Q09QapnxnXWR62SS1UUQkZgxkFIrh7V1vdM7d2+2pnUDk6CCfBTYPfXnHp6TIO6GntOIAJKXBFE0vKyKxYyB74MuArwCfjQwZXGdmFwBfBf7ZzN4D/g+RPvdoMj4zxJTcFO9AJnh98F3vw8H9/hYmIjIE+j2I6Zx7HbA+nl44tOUMvZLCXF7bvA/nHFZ8FvztR/DJqzD3Mr9LExE5LjF5JmZ3Cwtz2NfQzLYDh2DifEjO0nhwEYkJMR/gi4pyAVhTUQ2JAZh6uqaXFZGYEPMBfsK4dDJDAcoqO8aDL4fabVD9iZ9liYgct5gP8IQE7wIPayo6DmQu9+41GkVEolzMBzhASVEuH+9poPpgC4yZDpn5CnARiXrxEeDdL/Bg5u2Ff7JK08uKSFSLiwA/eUo2wUSjtLJbG6Wx2hsTLiISpeIiwEPBRObmZ/U8kAlqo4hIVIuLAAevjfJeVS3Nbe2QPg7GzVGAi0hUi5sAX1iYS0tbmPU7ar0Fxcuh8i1obfSzLBGRYxY3Ad4xsVWP4YTtzbD9bd9qEhE5HnET4GPTk5k6Ns27Uj1A4amQENDV6kUkasVNgIPXBy+rPIBzDpLTYfJi9cFFJGrFV4AX5VB9qJUtew96C4qXw6fvwaEDfpYlInJM4izAvYmtSiu6Dyd03kk9IiJRJq4CvHhsGrlpSV0n9OR/BpIy1EYRkagUVwFu5k1s1XmFnsQgFJ2mABeRqBRXAQ7egcxP9h1kb32zt6B4uTe1bHWFj1WJiAxe/AV4UbeJrQCmneXdb33Vp4pERI5N3AX43PwskgIJXQcyx86AjIlqo4hI1Im7AE8OJHLy5KyuA5md08u+CuGwn6WJiAxK3AU4eMMJ1++opbElMh948XI4tB92r/ezLBGRQYnPAC/MoS3seK+qxlsw9UzvXlerF5EoEpcBvrDwsAOZmRMhb5b64CISVeIywLNTkzhhXDprKrqdQl+8PDK9bJNfZYmIDEpcBjh4ffCyymrCYectKF4ObY1Q9Y6fZYmIDFj8BnhhDvVNbXy0p95bULgMLFFtFBGJGvEb4JETejrnBw9lwuQSBbiIRI24DfCC3FTyMpK7TugBr42y813vivUiIqNc3Aa4mVFSmNN1Qg94Ae7CUPG6X2WJiAxYvwFuZlPM7BUz22hm5WZ2a7fnbjGzDyPL/+/wljr0SopyqapuZFdtZOTJ5EWQlK42iohEhcAA1mkD7nDOrTWzDKDMzP4KjAcuBU5yzjWb2bjhLHQ4lETGg5dWHuCikyZ508sWLlOAi0hU6HcP3Dn3qXNubeRxPbARyAe+BvzYOdcceW7PcBY6HE6clElKMLHrQCZ4bZT9H0PNdr/KEhEZkEH1wM2sCFgAvA3MAE43s7fN7FUzW9THNjeZWamZle7du/d46x1SwcQE5k/JprTysAOZoL1wERn1BhzgZpYOPAnc5pyrw2u/5ABLgW8Dj5mZHb6dc+5B51yJc64kLy9viMoeOiVFOWzYWUdDc5u3YNxsSBunABeRUW9AAW5mQbzwXuGceyqyuAp4ynneAcLA2OEpc/iUFOUSdrBuW2Riq47pZbeu1PSyIjKqDWQUigEPARudc/d2e+qPwGcj68wAkoB9w1HkcFpQkI0ZR7ZRDu2DPRv8KktEpF8D2QNfBnwF+KyZrYvcLgAeBorNbD3wCHC9c84NY63DIjMUZNaEzMMOZHZML7vSl5pERAai32GEzrnXgSN62xHXDm05/igpzOGptVW0tYcJJCZA1mQYc4IX4Kd+0+/yRER6FbdnYnZXUpTDwZZ2Nu2q71pYvBwq34C2Fr/KEhE5KgU43oFM4Mh5UVoPQdUaX2oSEemPAhzIz05hUlao57woU08HS1AfXERGLQV4xMKiXEorquk8DhvKgvyFCnARGbUU4BElhTnsqmtiR01j18Li5bCjDJpq/SpLRKRPCvCIIy7wAJHpZds1vayIjEoK8IhZEzJJTw70PKFn8iIIpqqNIiKjkgI8IjHBWFCQ3XMPPJAMhacqwEVkVFKAd1NSmMuHu+upbWztWli8HPZ9BLU7/CpLRKRXCvBuFhXl4Bys3XZYHxzgk1f9KElEpE8K8G7mF2STmGCUdW+jjJsDqWPVRhGRUUcB3k1qUoA5kzJ7HshMSPAmt9q6EqJvri4RiWEK8MMsLMxh3fYaWtu7zQVevBwadsPeTX6VJSJyBAX4YUoKc2lqDVO+s65rYfFZ3r3aKCIyiijAD9N1Qk+3Nkr2FMidpgAXkVFFAX6Y8ZkhpuSm9BwPDl4bpeJ1aG/tbTMRkRGnAO/FosJcSisP0OMCQ8XLoaUBqkr9KktEpAcFeC8WFuWwr6GFyv2HuhZOPR0w2PKyb3WJiHSnAO/FosgFHtZ074On5EDBKbDqJ/DgWfDmv0JtlU8ViogowHs1PS+dzFCAssrD+uBX/Q4+9wNvhsIX/wF+OgceOgdWPwD1u/wpVkTiVr8XNY5HCQlGSVFuzyv0AKSNhdNu8277t0D5U7D+aXj+Lnj+O1C4DOb+F5h9KaTn+VO8iMQN7YH3YWFhDh/vaaD6YB8XNR4zDc74Nnz9TfjGO3DmXXBwD/z5DvjnmfDbL8Da38KhA71vLyJynBTgfSgp9MaDH9FG6U3eTDjru16Q3/w6LLsVqj+BZ26Be06AFV+EdX/QlX1EZEiphdKHk6dkE0w01lQe4HMnjh/YRmYwYZ53O/t/wc53vTZL+R9h882QmATTPw9zL4MZ50Fy+vD+EiIS0xTgfQgFE5mbn9VzZsLBMIP8z3i3z/0QdpTC+qdgwx/hwz9DIAVmnANzLoMZ50IwZWh/ARGJeQrwo1hUlMuv36igqbWdUDDx2F8oIQGmLPZu5/4f2PZW1575hj9BUjrMPN8L8+lne1cCEhHph3rgR7GwMIeW9jDrdwxh7zohAYqWwYX/DHd8CF/5o9dS+fgleORL8JMT4Omvwea/6rR9ETkq7YEfRceBzNLKakoiJ/cMqcQATDvLu114rzdZ1vqnYNN/wnv/4Z08NPtib8+86HRvfRGRCCXCUYxJT6Z4bJo3M+GZ04b3zRKDcMLnvVvbz+DjlyPjzJ/yhiOm5cHsS7y99YJTvT15EYlr/Qa4mU0BfgtMAMLAg865n3d7/k7gJ0Cec27fcBXql4WFOby0cTfhsCMhwUbmTQPJMOsC79baCJtf9IJ83X9A6UOQPgGmfw4Klnq3MdO9g6YiElcGsgfeBtzhnFtrZhlAmZn91Tm3IRLunwe2DWuVPlpUlMvjZVVs3dfA9HEZI19AMAVOvNS7NTfAR89D+dPw4XOw7vfeOqljYMpSKFji3U+arwOhInGg3wB3zn0KfBp5XG9mG4F8YAPwU+B/AH8aziL9tLDzAg/V/gR4d8npMO8K7+Yc7NvsjWjZ/jZsW+0NTwRITPaGL05Z4u2hT1kCqcPQwxcRXw2qB25mRcAC4G0zuwTY4Zx7z2L463vx2DRy05JYU1HN1YsL/C6nixnkzfBuC6/3ljXs6QrzbavhrfvgjZ95z42d6e2hF5ziBXpusdouIlFuwAFuZunAk8BteG2V/wmcM4DtbgJuAigoGEUBOEBmxsLCHMoqo2BOk/Rx3qiV2Rd7P7c2wo61XXvpG/7kHRAFSBvX1XIpWAoTToJAkn+1i8igDSjAzSyIF94rnHNPmdk8YCrQsfc9GVhrZoudcz3mVXXOPQg8CFBSUuKIQouKcvjrht3srW8mLyOKesvBFG/MedEy7+dwGPZugu2rYdvbXrBvfNZ7LpAC+Qu79tInL4KUbP9qF5F+DWQUigEPARudc/cCOOc+AMZ1W6cCKInFUSgACwu9/nFZ5QHOmzvR52qOQ0ICjD/Ru5X8V29Z/a6ulsv21fD6z8D9M2Awbnakhx45QJpdqLaLyCgykD3wZcBXgA/MbF1k2fecc88NX1mjy9z8TJIDCZRWVEd3gPcmYwLM+YJ3A2g56F33s6OX/v7jUPqw91z6hK6hi1OWeG0XnVwk4puBjEJ5HTjqbpdzrmioChqNkgOJnDw5mzUDmVo22iWlQfGZ3g0g3A57NnTbS3/bm5ALIJgKY0/wxqF33qZB7jS1X0RGgHafBmhhUQ6/XLWVxpZ2UpKOY2KraJOQ2DVF7uKvestqq7wwryqFfR959+ufArod4kgd2zPUx0zzHucWa+ZFkSGiAB+gRUU53L/SsW57DadMG+N3Of7Kmtw1Hr1DWzNUV8D+j7vdtniTdHWccNS5/RQvyA/fc88uVEtGZBD0f8sAfaag4wo9BxTgvQkke1cmypt55HPN9V6Y7/8YDmztCvj1T/S8SlFCAHKKjmzHjJkOmZN0AFXkMArwAcpOTWLm+Ax+9UYFyYFEvrSkgPRkfXwDkpzhnd4/aX7P5c7Bof1d4d59z33rq9DW2LVuMDUS5t3aMR03nWUqccqcG7mh2SUlJa60tHTE3m+ord9Ry91/3shbW/eTGQrwlVMKueHUqdE1NjxahMNQv7NnqHcEfXUFuPaudZOzIG2MN/3uQG+hbLVrJGqYWZlzruSI5QrwwXtvew0PvLqF58t3EUxM4IsLJ3PTGcUUjknzu7T40N4K1ZVwoKMt8wk0Vh95a6qlx4HVwyVneqNlBhP8KTmaKExGnAJ8GGzd28AvX9vKk2U7aAuHOX/eRL525jTm5mf5XZqANwSyqTYS6DW9h3xft+57+IcLph4W6tlde/Up2UfedzwXyvJG9YgMkgJ8GO2pa+LhNypYsbqS+uY2Tps+lq8tn8ap08YQyxN9xSznvAOvRw35Pv4gtDcf/bWTsyAlq++w7/U+R+Ef5xTgI6CuqZUVq7fx8BufsLe+mXn5Wdx85jTOmzuBxJG6GIT4q7XRC/emmt7vG6v7fq7f8M+MBHo/fwBC2d6B4+R074LZyRneLTE4Mp+BDDkF+Ahqam3n6Xd38OCqrXyy7yBFY1L56hnFXP6Zycd3dWq8G70AAA8dSURBVHuJbf2F/9H+CPQX/gCBUCTQI6GelNF70CdndFsvs9tz6V3baObKEaUA90F72PFi+S4eeHUL71XVMjY9mRuXFXHt0kKyUrQ3JEOoe/g31UFLvdcGam7w7lsi9z0eNxy5Xvehm0eTmNQt6DMOe9wR9One8YKkNO/W32N9Q+iTAtxHzjne2rKf+1/dwmub95GeHOCaJQX819OmMj4z5Hd5Il3a27oCfqCh39d6rQcH996JSf2H/GD+IHQ8DqZG/UXAFeCjxPodtfxi1Vb+/P5OAgkJ/JcF+dx0ZjHT8tL9Lk1kaIXD3h59y0Hv1npo6B63twyulsQkb877YMhrJQVTBngf6rZdH/fB1CO3HeJvEwrwUWbb/kP88rWtPFa6nZb2MOecOJ6bz5zGgsgp+yJyFO2tfYT8Ie9bQPflbU1ei+nw+96WHX5/tPMIjsYSj/xjcPHPuy6uMtiXU4CPTvsamvnNmxX89q1KahtbWTI1l5uXT2P5jDwNQRTxk3Penv5Agr7HfZP3zePw+9Pv8Gb1PAYK8FGuobmNR97Zxr+/9gm76pqYPTGTm88s5sJ5EwkkRnf/TkSOjwI8SrS0hfnTuh38YtVWPt7TwOScFL56ejFXlkyJr3nIRaSTAjzKhMOOlzft4YFXt1BWWU1uWhLXn1LEdacUkpOmMbgi8UQBHsXWVBzggZVbeHnTHlKTErlq0RSuWVLI9HEauSISDxTgMeDDXfX8YtUWnlm3k7awozgvjXPnTODcORM4eXKWDnqKxCgFeAzZXdfEC+W7eKF8F6u3HqA97JiQGeKcOeM5d84EFk/NJagDnyIxQwEeo2oOtfDyxj28UL6LVZv30tQaJislyNmzx3HunAmccUKeDn6KRDkFeBxobGnn1Y/28mL5Ll7auJu6pjZSgomcMWMs586ZwNmzxpOVqvkmRKJNXwGua0rFkJSkRM6bO4Hz5k6gtT3M21sP8EL5Ll7csIsXyncTSDCWFo/h3DnjOWfOBM3DIhLltAceB8Jhx3tVNbxQvpsXy3exdZ83ydD8KdmRg6DjKdZcLCKjllooAngzI368pyFyEHQ3H+yoBeCEcemdI1rm5mdqRIvIKKIAl17tqGnkxciIlnc+OUDYQX52Cp8/0RvRsqgoR6fyi/hMAS79OnCwhZc2em2WVZv30dIWJjctibNneSNaTjthrK4oJOIDBbgMysHmNl79aC8vlO/ibxv3UN/cRmpSIstn5nHunAmcNWscmSGNaBEZCRqFIoOSlhzggnkTuWDeRFrawry5ZR8vlO/mrxt289wHuwgmGqdMG0tJYQ5zJmUyZ1IW4zOT1TsXGUH97oGb2RTgt8AEIAw86Jz7uZn9BLgYaAG2ADc652qO9lraA49+7WHHu9uqvT3zTXvYsrfrsllj0pI4MRLmXqhnUjQmjYQEhbrI8TjmFoqZTQQmOufWmlkGUAZ8AZgM/M0512Zm/wTgnLvraK+lAI89Dc1tbPy0jvIdtZTvrKN8Zx2b99TT2u79u0pLSmT2xMzOvfQTJ2UyY3wGSQEdGBUZqGNuoTjnPgU+jTyuN7ONQL5z7sVuq60GrhiqYiV6pCcHWFSUy6Ki3M5lzW3tbN7dwIaddZTv9IL98bIqfvNWJQDBROOEcRmde+lz8rOYPTGT9GR19EQGY1AHMc2sCFgFzHXO1XVb/izwqHPu971scxNwE0BBQcHCysrK4yxZolE47KjYf7BzL718Zy0bdtax/6B3cVozKBqTFmnBdLVhxqYn+1y5iP+OexSKmaUDrwJ3O+ee6rb8fwIlwGWunxdTC0W6c86xu665cy+9476qurFznfGZyT166nMmZTE5J0UHSyWuHNcoFDMLAk8CKw4L7+uBi4Cz+wtvkcOZGROyQkzICnH27PGdy2sPtVL+qbeHvj7SW1/54R7CkX9hmaFAj4OlJ07KpCA3ldQktWAkvvT7L968XZ2HgI3OuXu7LT8PuAs40zl3aPhKlHiTlRrk1GljOXXa2M5ljS3tbNpV19mC2bCzlt+vrqS5Ldy5zpi0JCbnpDA5JzVy3/U4PydFAS8xZyCjUE4DXgM+wBtGCPA94F+AZGB/ZNlq59zNR3sttVBkKLW1h9my9yCbdnltF+92iB2Rxy3t4R7rj01PIr+XcJ+Sk0J+dqrmTZdR63hGobwO9NZwfG4oChM5VoHEBGZOyGDmhIwjnguHHXsbmqmqPtQj3KuqG9mws46/lu/uN+CndD727jWNgIw2+k4pMSkhwRifGWJ8ZoiFhUc+f2wBn3zE3rsCXvykAJe4NJiA336gsUfQr99RywvluzpPVuowNj2p8zXHZ4aYkBlifGYy47NCjM/wDtbmpAY1gkaGjAJcpBcDCfg99d334A+xo6aR3XXN7Kpt4v2qGvY1tByxXVJiAuMykzsDflxmciToI6Gf5YW+DrjKQOhficgxSEjoGgJZUtT7Oi1tYfY2eIG+p66JXXVN7K5rZnddE7vrmti4q46VHzZxsKX9iG0zQoE+Q358ZjITskLkpSdrrvY4pwAXGSZJgQTys1PIz0456noNzW19hvyuuibe3nqQ3XVNtIV7tmzMvL58Z6smEvB5GclkpwTJTk0iJy1IdkoS2alB9ehjkAJcxGfpyQGmj0tn+ri+r0saDjsOHGrxgr6+iV21zeyq6wr9HTVNrN1Ww4GDR7ZtOqQEE8lJDZKVmkROapCc1CSyUoNdj1O8+5y0IFkp3jpZKUHt5Y9iCnCRKJCQYIxNT47MDZPV53rNbe0cONhC9cFWahpbqDnUSvUh777mUAvVh1o7H2/aVec9bmylPdz3+SAZoYAX7IeHf0ok/NO6hX/kj0JmKKCDtSNAAS4SQ5IDiUzMSmFi1tHbNt0556hvbqMmEvrVkYDvPfxbqNx/kOqDLdQ1tfX5mokJRmYoQFZKkMyUIJmhYORxoPPnzJTIslCg22NvneSA2j0DoQAXiXNm5gVnKEgBqQPerq09TF1TWyTkOwK/I+xbqGtso7axlbqmVuoaW/m0tpG6Jm9ZS1v4qK8dCiYcNeQ7/xh0Pu5anh4KkBgnFxFRgIvIMQkkJpCblkRuWtKgt21qbe8M9trGts7HdY2tnSFfFwn/2sZW9jW0sHXfwc7lR+n4AJCRHNnTj4R/Rqgr8Dv+GGSEvJ87nssIda0bLRccUYCLyIgLBRMJBRMZlxEa9LbOOQ62tHeGee1Rgr9j+Y6aRjZ+2kp9Uyv1zW30N3dqxzeAjM6wPzL4j/i52+PUpMQROQagABeRqGJmpCcHSE8O9DtEszfhsONgSxt1TW3UNbZS33Hf3EpdYxv1Ta09n4v8Mag6cKhz+eHTLBwuMcHICAW67eUHuOu8WSwoyDnWX7tXCnARiSsJCUZGpHVyLH8AwGsBdYR7/WFhX9/k/SE4/LmEYdgjV4CLiAxSRwsoL8PfS/5FR6deRESOoAAXEYlSCnARkSilABcRiVIKcBGRKKUAFxGJUgpwEZEopQAXEYlS5vqbFGAo38xsL1B5jJuPBfYNYTnRTp9HF30WPenz6CkWPo9C51ze4QtHNMCPh5mVOudK/K5jtNDn0UWfRU/6PHqK5c9DLRQRkSilABcRiVLRFOAP+l3AKKPPo4s+i570efQUs59H1PTARUSkp2jaAxcRkW4U4CIiUSoqAtzMzjOzD83sYzP7jt/1+MXMppjZK2a20czKzexWv2saDcws0czeNbP/9LsWv5lZtpk9YWabIv9OTvG7Jr+Y2e2R/0/Wm9kfzGzwF+Ac5UZ9gJtZInAfcD5wIvAlMzvR36p80wbc4ZybDSwFvhHHn0V3twIb/S5ilPg58LxzbhZwMnH6uZhZPvAtoMQ5NxdIBK72t6qhN+oDHFgMfOyc2+qcawEeAS71uSZfOOc+dc6tjTyux/ufM9/fqvxlZpOBC4F/97sWv5lZJnAG8BCAc67FOVfjb1W+CgApZhYAUoGdPtcz5KIhwPOB7d1+riLOQwvAzIqABcDb/lbiu58B/wM4+mXC40MxsBf4VaSl9O9mluZ3UX5wzu0A7gG2AZ8Ctc65F/2tauhFQ4D3dinnuB77aGbpwJPAbc65Or/r8YuZXQTscc6V+V3LKBEAPgPc75xbABwE4vKYkZnl4H1TnwpMAtLM7Fp/qxp60RDgVcCUbj9PJga/Cg2UmQXxwnuFc+4pv+vx2TLgEjOrwGutfdbMfu9vSb6qAqqccx3fyp7AC/R49DngE+fcXudcK/AUcKrPNQ25aAjwNcAJZjbVzJLwDkQ843NNvjAzw+tvbnTO3et3PX5zzn3XOTfZOVeE9+/ib865mNvLGijn3C5gu5nNjCw6G9jgY0l+2gYsNbPUyP83ZxODB3QDfhfQH+dcm5l9E3gB70jyw865cp/L8ssy4CvAB2a2LrLse86553ysSUaXW4AVkZ2drcCNPtfjC+fc22b2BLAWb/TWu8TgKfU6lV5EJEpFQwtFRER6oQAXEYlSCnARkSilABcRiVIKcBGRKKUAFxGJUgpwkeNkZhVmNtbvOiT+KMBFRKKUAlyikpkVRS5Y8MvIpP0vmllKH+tOM7PnzazMzF4zs1mR5b82swciyz6KTI6FmYXM7Fdm9kFkVr+zIssTzeyeyPL3zeyWbm9zi5mtjTw3a9g/ABEU4BLdTgDuc87NAWqAy/tY70HgFufcQuBO4N+6PVcEnIk3p/gDkau2fAPAOTcP+BLwm8jym/Bmt1vgnDsJWNHtdfY55z4D3B95D5FhN+rnQhE5ik+ccx1zwpThhXEPkal3TwUe9+Y0AiC52yqPOefCwGYz2wrMAk4D/hXAObfJzCqBGXgz3D3gnGuLPHeg2+t0zAxZBlx2/L+aSP8U4BLNmrs9bgd6a6EkADXOufl9vMbhkwE5ep+DnsjyviYP6qilHf1/JSNELRSJaZELXnxiZl8Eb0peMzu52ypfNLMEM5uGd0WbD4FVwDWR9WcABZHlLwI3Ry7RhZnljtxvInIkBbjEg2uAvzOz94Byel5T9UPgVeAvwM3OuSa8HnmimX0APArc4Jxrxrvu5jbg/chrfXkEfweRI2g6WYlbZvZr4D+dc0/4XYvIsdAeuIhIlNIeuMQMM7sP76pF3f3cOfcrP+oRGW4KcBGRKKUWiohIlFKAi4hEKQW4iEiUUoCLiESp/w+0AFUw6ZhQUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = acc_score(X_test3, y_test3, cnn1d)\n",
    "loss_plot(cnn1d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "144px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
