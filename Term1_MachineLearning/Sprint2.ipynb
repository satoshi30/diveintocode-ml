{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スクラッチの意義\n",
    "ここでのスクラッチとは、NumPyなどの基本的なライブラリを組み合わせることで、scikit-learnのような応用的なライブラリと同じ機能のクラス・関数を自作することを指します。\n",
    "\n",
    "スクラッチをすることでscikit-learnなどのライブラリを動かすだけでは掴みづらい、アルゴリズムの深い理解を目指します。コーディングのスキル向上も兼ねますが、それは主な目的ではありません。\n",
    "\n",
    "以下のような効果を狙っています。\n",
    "\n",
    "- 新たな手法に出会った時に理論・数式を理解しやすくする\n",
    "- ライブラリを使う上での曖昧さを減らす\n",
    "- 既存の実装を読みやすくする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_splitのスクラッチ\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil, floor\n",
    "import random\n",
    "def scratch_train_test_split(X, y, train_size=0.8,):\n",
    "    \"\"\"\n",
    "    検証データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      訓練データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    if type(X) != np.ndarray :\n",
    "        raise TypeError(\"Type of X input must be numpy.array\")\n",
    "    elif type(y) != np.ndarray:\n",
    "        raise TypeError(\"Type of y input must be numpy.array\")\n",
    "    elif len(X) == 0 or len(y) == 0:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    elif X.shape[0] != y.shape[0]:\n",
    "        raise SyntaxError('The number of rows in the array must be match')\n",
    "    elif type(train_size) != float:\n",
    "        raise TypeError(\"Type of train_size input must be float\")\n",
    "    elif train_size >= 1 or train_size <= 0:\n",
    "        raise ValueError('Value of train_size must be between 0 and 1')\n",
    "    n_samples = len(X)\n",
    "    n_train = int(floor(train_size * n_samples))\n",
    "    n_test = int(n_samples - n_train)\n",
    "    if n_train == 0:\n",
    "        raise ValueError(\n",
    "            'With n_samples={}, test_size={} and train_size={}, the '\n",
    "            'resulting train set will be empty. Adjust any of the '\n",
    "            'aforementioned parameters.'.format(n_samples, test_size,\n",
    "                                                train_size)\n",
    "        )\n",
    "    index_lst = [i for i in range(n_samples)]\n",
    "    test_index = random.sample(index_lst, n_test)\n",
    "    train_index = list(set(index_lst)-set(test_index))\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140 141 142 143 144 145 146 147 148 149]\n",
      " [110 111 112 113 114 115 116 117 118 119]\n",
      " [  0   1   2   3   4   5   6   7   8   9]] [14 11  0]\n",
      "12 3 12 3\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(150).reshape(15, -1)\n",
    "y = np.arange(15)\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8)\n",
    "print(X_test, y_test)\n",
    "print(len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20  21  22  23  24  25  26  27  28  29]\n",
      " [130 131 132 133 134 135 136 137 138 139]\n",
      " [  0   1   2   3   4   5   6   7   8   9]] [ 2 13  0]\n",
      "12 3 12 3\n"
     ]
    }
   ],
   "source": [
    "# sklearn で確認\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "print(X_test, y_test)\n",
    "print(len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類問題\n",
    "分類は3種類の手法をスクラッチします。\n",
    "\n",
    "- ロジスティック回帰\n",
    "- SVM\n",
    "- 決定木\n",
    "\n",
    "ロジスティック回帰はscikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数で`loss=\"log\"`とすることでロジスティック回帰の計算になります。\n",
    "\n",
    "- [sklearn.linear_model.SGDClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)\n",
    "- [sklearn.svm.SVC — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "- [sklearn.tree.DecisionTreeClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "\n",
    "データセットは3種類用意します。\n",
    "\n",
    "1つ目は事前学習期間同様にirisデータセットです。\n",
    "\n",
    "[sklearn.datasets.load_iris — scikit-learn 0.20.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "\n",
    "- virgicolorとvirginica\n",
    "\n",
    "残り2つは特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数`X`,目的変数`y`が作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "data = load_iris()\n",
    "names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "iris_df = pd.DataFrame(data.data, columns=names)\n",
    "iris_df['Species'] = data.target\n",
    "iris_df_choice = iris_df[(iris_df['Species'] == 1) | (iris_df['Species'] == 2)]\n",
    "X = iris_df_choice.iloc[:, 0:4].values\n",
    "y = iris_df_choice.iloc[:, -1].values\n",
    "iris_data = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット1作成コード\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data1 = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット2作成コード\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data2 = X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰（勾配降下法）\n",
    "def scratch_SGDClassifier(X, y, loss='log'):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "    from sklearn.linear_model import SGDClassifier \n",
    "    clf = SGDClassifier(loss=loss)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def scratch_SVC(X, y):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "    from sklearn.svm import SVC\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木\n",
    "def scratch_DecisionTreeClassifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰（勾配降下法）\n",
      "[2 2 2 2 2 2 2 2 1 2 1 1 2 2 2 1 1 1 2 2]\n",
      "SVM\n",
      "[2 2 1 2 2 1 1 2 1 1 1 2 1 2 2 1 1 1 1 1]\n",
      "決定木\n",
      "[2 2 1 1 2 1 2 2 1 2 1 2 2 1 1 2 1 1 1 2]\n",
      "ロジスティック回帰（勾配降下法）\n",
      "[-1  1  1  1  1 -1  1  1 -1  1 -1  1  1 -1  1  1 -1 -1  1  1  1 -1  1 -1\n",
      " -1 -1  1  1 -1  1  1  1  1  1 -1 -1 -1  1  1 -1  1 -1 -1  1  1  1  1 -1\n",
      " -1  1  1 -1 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1  1  1 -1  1 -1 -1 -1\n",
      "  1  1 -1 -1  1  1 -1  1 -1 -1  1  1 -1  1  1 -1  1  1 -1  1  1  1  1  1\n",
      "  1  1  1 -1]\n",
      "SVM\n",
      "[-1  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1 -1  1  1 -1 -1 -1  1 -1 -1\n",
      " -1  1 -1  1  1  1 -1  1 -1  1 -1  1 -1 -1  1  1 -1 -1  1 -1  1 -1  1  1\n",
      "  1 -1  1  1 -1 -1  1  1  1  1  1  1  1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1\n",
      "  1 -1  1 -1  1 -1 -1  1  1  1 -1 -1  1  1  1 -1  1 -1  1  1  1 -1  1 -1\n",
      "  1 -1 -1 -1]\n",
      "決定木\n",
      "[-1 -1 -1  1 -1  1 -1 -1 -1  1  1 -1 -1 -1  1 -1  1 -1  1 -1 -1  1 -1 -1\n",
      " -1 -1 -1  1 -1  1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1\n",
      "  1 -1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1 -1  1 -1 -1 -1 -1 -1  1 -1  1 -1\n",
      "  1 -1 -1  1 -1 -1 -1  1  1 -1 -1 -1  1  1  1 -1  1  1 -1 -1 -1 -1 -1 -1\n",
      " -1  1  1  1]\n",
      "ロジスティック回帰（勾配降下法）\n",
      "[0 0 0 0 0 0 0 0]\n",
      "SVM\n",
      "[1 0 1 0 1 1 1 1]\n",
      "決定木\n",
      "[0 1 0 0 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikeda/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/ikeda/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/ikeda/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data_lst = [iris_data, simple_data1, simple_data2]\n",
    "for data in data_lst:\n",
    "    print('ロジスティック回帰（勾配降下法）', scratch_SGDClassifier(*data), sep='\\n')\n",
    "    print('SVM', scratch_SVC(*data), sep='\\n')\n",
    "    print('決定木', scratch_DecisionTreeClassifier(*data), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回帰問題\n",
    "回帰は1種類をスクラッチします。\n",
    "\n",
    "- 線形回帰\n",
    "\n",
    "線形回帰は勾配降下法を用いて計算するSGDRegressorクラスを利用してください。\n",
    "\n",
    "[sklearn.linear_model.SGDRegressor — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "`train.csv`をダウンロードし、目的変数として`SalePrice`、説明変数として、`GrLivArea`と`YearBuilt`を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", 80)\n",
    "df = pd.read_csv('train.csv', index_col= 'Id')\n",
    "X = df.loc[:, ['GrLivArea', 'YearBuilt']].values\n",
    "y = df.loc[:, 'SalePrice'].values\n",
    "House_Prices_data = X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形回帰（勾配降下法）\n",
    "def scratch_SGDRegressor(X, y):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "    from sklearn.linear_model import SGDRegressor\n",
    "    clf = SGDRegressor()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰（勾配降下法）\n",
      "[1.87551482e+15 1.29493184e+15 2.44342771e+15 1.64746524e+15\n",
      " 2.13412575e+15 2.12189054e+15 2.75107286e+15 1.88992708e+15\n",
      " 1.79469332e+15 2.25207576e+15 2.02358864e+15 2.30191037e+15\n",
      " 1.83444175e+15 1.83049719e+15 1.95936845e+15 2.01094656e+15\n",
      " 2.47403708e+15 1.94584728e+15 1.75931631e+15 2.12190521e+15\n",
      " 2.41241547e+15 2.23024927e+15 1.68678280e+15 1.60510221e+15\n",
      " 1.72260401e+15 2.40239199e+15 1.60902543e+15 1.62518920e+15\n",
      " 2.10135534e+15 1.60946164e+15 2.18089889e+15 1.99783626e+15\n",
      " 2.17825762e+15 2.19227769e+15 2.40588833e+15 2.37179996e+15\n",
      " 2.59242997e+15 2.03060534e+15 2.41593716e+15 1.52733284e+15\n",
      " 2.87375582e+15 2.38794638e+15 1.59198791e+15 1.91178825e+15\n",
      " 1.95590545e+15 2.53607089e+15 1.81126795e+15 3.11059495e+15\n",
      " 1.91525658e+15 2.44823269e+15 2.24421065e+15 1.94455199e+15\n",
      " 2.37884066e+15 2.50852166e+15 2.33027601e+15 1.77938196e+15\n",
      " 2.32066739e+15 2.95064210e+15 2.47007785e+15 2.03018647e+15\n",
      " 1.98737256e+15 2.14770294e+15 1.99696384e+15 1.53128407e+15\n",
      " 2.20008945e+15 1.80345752e+15 2.34120392e+15 2.02446106e+15\n",
      " 1.83445642e+15 1.93053459e+15 1.98516351e+15 2.44517922e+15\n",
      " 1.60771680e+15 2.48099910e+15 1.63741641e+15 2.10356840e+15\n",
      " 3.73876880e+15 2.24509507e+15 1.78638266e+15 1.85717667e+15\n",
      " 3.87209819e+15 2.62911960e+15 1.82312030e+15 2.37747868e+15\n",
      " 2.34914639e+15 3.06467689e+15 1.53037964e+15 1.89780019e+15\n",
      " 1.85408052e+15 2.24470288e+15 1.96901174e+15 2.16426424e+15\n",
      " 2.29707605e+15 1.60289315e+15 2.04543914e+15 2.57231497e+15\n",
      " 2.15948327e+15 1.99869401e+15 2.20973941e+15 1.54874847e+15\n",
      " 1.73482188e+15 1.62520520e+15 1.78464315e+15 2.70163045e+15\n",
      " 2.20098188e+15 2.30540939e+15 1.72872695e+15 2.57192144e+15\n",
      " 2.30409809e+15 2.71738601e+15 2.55832959e+15 2.96113247e+15\n",
      " 2.44517522e+15 1.98077607e+15 3.20490561e+15 2.00005199e+15\n",
      " 1.56885946e+15 2.67411722e+15 1.90788103e+15 1.50112558e+15\n",
      " 2.15249057e+15 2.86894951e+15 3.06948854e+15 3.15162400e+15\n",
      " 2.66143113e+15 2.42595798e+15 1.63349319e+15 1.86369314e+15\n",
      " 1.58763782e+15 2.21630257e+15 1.76411595e+15 1.61952381e+15\n",
      " 1.79992917e+15 2.10092847e+15 2.17172115e+15 1.76324220e+15\n",
      " 1.76498704e+15 2.01141345e+15 2.30146216e+15 2.20447422e+15\n",
      " 1.69901001e+15 2.58672323e+15 2.18523431e+15 2.05111653e+15\n",
      " 2.29406393e+15 2.69288624e+15 1.63829150e+15 2.36435238e+15\n",
      " 2.69506996e+15 2.89260220e+15 2.94587980e+15 1.98388822e+15\n",
      " 2.05244650e+15 2.25167156e+15 1.75931631e+15 2.53170879e+15\n",
      " 1.83401488e+15 1.61469616e+15 1.78684688e+15 2.28837187e+15\n",
      " 1.61467482e+15 1.73482188e+15 1.72872695e+15 2.35520798e+15\n",
      " 2.57887146e+15 2.24639570e+15 2.07472921e+15 2.45353122e+15\n",
      " 1.53390667e+15 1.44129016e+15 2.35430622e+15 2.24203627e+15\n",
      " 2.10965533e+15 3.12582895e+15 1.76498571e+15 2.78682338e+15\n",
      " 1.92487720e+15 2.15727821e+15 1.68109873e+15 1.77285215e+15\n",
      " 3.12678672e+15 2.18701383e+15 1.89386630e+15 3.14507286e+15\n",
      " 1.93533824e+15 1.55487141e+15 1.71866879e+15 2.18261172e+15\n",
      " 2.11928929e+15 1.81217505e+15 1.76892360e+15 2.26256080e+15\n",
      " 1.62827201e+15 2.05942186e+15 1.89608203e+15 1.92310836e+15\n",
      " 2.27348205e+15 2.64133081e+15 1.74181858e+15 1.83402288e+15\n",
      " 1.60685905e+15 2.06993090e+15 3.01224637e+15 1.73658539e+15\n",
      " 1.54831092e+15 3.07690677e+15 2.29931712e+15 2.12538289e+15\n",
      " 2.26956016e+15 1.77067110e+15 1.63001685e+15 1.61774963e+15\n",
      " 1.79643282e+15 2.34601023e+15 2.07426632e+15 1.77153019e+15\n",
      " 2.57844725e+15 2.17525350e+15 2.18921222e+15 2.58585081e+15\n",
      " 2.59727229e+15 2.57537378e+15 2.10922179e+15 2.87684797e+15\n",
      " 2.62954381e+15 1.61207890e+15 1.78552224e+15 2.35563219e+15\n",
      " 1.92354990e+15 2.72827125e+15 2.12582176e+15 2.31323849e+15\n",
      " 2.10618833e+15 2.23771952e+15 2.28531306e+15 2.19486294e+15\n",
      " 1.92705692e+15 1.64615394e+15 2.14678917e+15 2.15553204e+15\n",
      " 2.40720096e+15 1.67895770e+15 1.52250653e+15 2.21848361e+15\n",
      " 1.73879845e+15 1.65752474e+15 1.81478430e+15 2.28878140e+15\n",
      " 1.73919198e+15 1.87155692e+15 2.03541698e+15 1.77504120e+15\n",
      " 2.61424846e+15 2.47837917e+15 1.71953320e+15 1.99478813e+15\n",
      " 2.01884502e+15 4.96114684e+15 2.24115318e+15 2.89171244e+15\n",
      " 2.84361067e+15 1.95808249e+15 2.02845897e+15 1.46662900e+15\n",
      " 1.61467482e+15 2.51423906e+15 2.22982373e+15 1.92488654e+15\n",
      " 2.40061381e+15 1.67191832e+15 1.91702810e+15 2.23853326e+15\n",
      " 1.91876493e+15 2.49061172e+15 4.78159789e+15 2.43080830e+15\n",
      " 1.81347567e+15 2.15815463e+15 2.03757803e+15 1.81126795e+15\n",
      " 1.89737198e+15 2.25212911e+15 1.81085842e+15 1.69202665e+15\n",
      " 2.82788978e+15 2.22372347e+15 2.30450096e+15 1.91571280e+15\n",
      " 1.69203332e+15 1.61511103e+15 2.42028192e+15 2.54965207e+15]\n"
     ]
    }
   ],
   "source": [
    "print('線形回帰（勾配降下法）', scratch_SGDRegressor(*House_Prices_data), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
