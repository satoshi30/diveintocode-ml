{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clean-workflow-in-keras",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd56mwFSfaHg"
      },
      "source": [
        "# Keras - Clean Project Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFMIDefpfgC3"
      },
      "source": [
        "## Aim:\n",
        "Aim of this notebook is to show an example of clean workflow Computer Vision project/competition in Keras.\n",
        "\n",
        "##  Workflow:\n",
        "Workflow can be interpreted as following steps:\n",
        "\n",
        "1. Dataset initialization (if needed): this step is usually required in case where training samples are separated from from their labels or there is additional information about the samples of a different format. This is the case here, depth is an additional feature that is separate from training images and is thus provided in DataFrame format. For easy integration between the depth and images, each sample has a unique ID. By those IDs images can be connected with their masks and depth added on top of that.\n",
        "2. Data loading/processing: set of operations preparing the data for model-ingestible format. Each sample is loaded as image and appended to a list, same happends with masks. Afterwards, dimensions are expanded (if needed), because 2D Convolutional CNN require input samples of dimensionality (HxWxC - height x width x channels) and OpenCV loads grayscale images as (HxW) 2D arrays.\n",
        "3. Data is normalized to 0-1 input range. When loaded in OpenCV, grayscale images come in range between 0 and 255. Networks usually converge quicker if data is in 0-1 range. It is also important to keep the values range the same for images and masks (feeding the model with 0-255 images and 0-1 masks is not recommended).\n",
        "4. Data is split into training and validation subsets. For this competition, salt coverage is the basis of the split. Then, a stratified split is performed in order to avoid significant discrepancy in distribution between training and validation sets. This could potentially harm model performance or at least skew the validation metric results.\n",
        "5. Model definition and training. A lot more about this can be read either in segmentation papers, solutions from past competition or discussions part itself :). One major principle to keep in mind - segmentation model output must be of the same shape as was the input!\n",
        "6. Prediction with trained model.\n",
        "7. Predictions processing. This can be done in different ways, depending on the final goal. For this competition, predictions and encoded with Run Length Encoding in order to compress their size (raw masks predictions would weight around a GB). Method of processing is very important, as it may require a specific approach to final predictions preparation. In case of RLE, one have to make sure that predictions are scaled (or unpadded) to original image size. Otherwise, RLE will encode wrong pixels and thus final submission score will be low."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpEBy8VTfZOg",
        "outputId": "c9f5335c-fc97-406b-8eb9-c4ca4bac2cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 自分のマイドライブにマウントする\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4UUxcj5pGb8",
        "outputId": "a57ed605-35b2-4b69-fa9f-654908943db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/unet/TGSSalt_data/clean_workflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/unet/TGSSalt_data/clean_workflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11FMufg00BnS",
        "outputId": "93531e7a-6177-4d25-9ef8-1be09c606b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls -a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv\t\t X_test.npy   y_train.npy\n",
            "Unet_grayscale0_pad0_size128.h5  X_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoaOcCblwwUk"
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.callbacks import *\n",
        "from keras.models import load_model\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "plt.style.use('ggplot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meR7i5DQxWbJ"
      },
      "source": [
        "# Define SaltParser\n",
        "The first question most probably would be - why create and use parser like this one?\n",
        "\n",
        "In Machine Learning, you usually can tune two things: models and data. Each parameter can influence the final score, so it's good to know what kind of parameters are used for each run and it's even better to design the pipeline in a way that will minimize potential errors.\n",
        "\n",
        "When a certain operation will be used many times but with different parameters, it is good to parameterize it and just call with chosen parameters. Besides, having functions for processing in one place makes it easier to spot mistakes. This is even more important when you perform an operation in different parts of the pipeline. Then, making sure that all functions are doing the same (for example using different types of padding for training and prediction certainly would not be a good idea!).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "036AdeSrwzEq"
      },
      "source": [
        "class SaltParser(object):\n",
        "\n",
        "    \"\"\"\n",
        "    Parser for Salt Competition.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_src='../input/',\n",
        "                 image_size=(128, 128),\n",
        "                 pad_images=False,\n",
        "                 grayscale=True,\n",
        "                 load_test_data=True):\n",
        "\n",
        "        self.data_src = data_src\n",
        "        self.image_size = image_size\n",
        "        self.pad_images = pad_images\n",
        "        self.grayscale = grayscale\n",
        "        self.load_test_data = load_test_data\n",
        "\n",
        "        self.train_df = None\n",
        "        self.test_df = None\n",
        "        self.padding_pixels = None\n",
        "\n",
        "        self.X_train = []\n",
        "        self.y_train = []\n",
        "        self.X_test = []\n",
        "\n",
        "        self.orig_image_size = (101, 101)\n",
        "        \n",
        "        \"\"\"\n",
        "        # Arguments:\n",
        "        \n",
        "            data_src: directory containing data\n",
        "            image_size: tuple specifying final image size\n",
        "            pad_images: whether images should be padded or resized\n",
        "            grayscale: whether to load images as grayscale\n",
        "            load_test_data: whether to load test data\n",
        "            \n",
        "        \"\"\"\n",
        "\n",
        "    def initialize_data(self):\n",
        "        \n",
        "        \"\"\"\n",
        "        Initialize processing by loading .csv files.\n",
        "        \"\"\"\n",
        "\n",
        "        train_df = pd.read_csv('{}train.csv'.format(self.data_src),\n",
        "                               usecols=[0], index_col='id')\n",
        "        depths_df = pd.read_csv('{}depths.csv'.format(self.data_src),\n",
        "                                index_col='id')\n",
        "\n",
        "        self.train_df = train_df.join(depths_df)\n",
        "        self.test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
        "\n",
        "        return\n",
        "\n",
        "    def load_data(self):\n",
        "        \n",
        "        \"\"\"\n",
        "        Load images and masks from training set.\n",
        "        \n",
        "        # Returns:\n",
        "            self.X_train: np.array of training images\n",
        "            self.y_train: np.array of training masks\n",
        "            self.X_test: np.array of test images\n",
        "        \"\"\"\n",
        "\n",
        "        print('Loading training set.')\n",
        "        # Loop over ids in train_df\n",
        "        for i in tqdm(self.train_df.index):\n",
        "            # Load image and mask according to ID\n",
        "            img_src = '{}unzip_train/images/{}.png'.format(self.data_src, i)\n",
        "            mask_src = '{}unzip_train/masks/{}.png'.format(self.data_src, i)\n",
        "            # Specify if image should be loaded in grayscale.\n",
        "            if self.grayscale:\n",
        "                img_temp = cv2.imread(img_src, 0)\n",
        "            else:\n",
        "                img_temp = cv2.imread(img_src)\n",
        "            # Load mask\n",
        "            mask_temp = cv2.imread(mask_src, 0)\n",
        "            # Resize or pad image and mask\n",
        "            if self.orig_image_size != self.image_size:\n",
        "                if self.pad_images:\n",
        "                    img_temp = self.__pad_image(img_temp)\n",
        "                    mask_temp = self.__pad_image(mask_temp)\n",
        "                else:\n",
        "                    img_temp = cv2.resize(img_temp, self.image_size)\n",
        "                    mask_temp = cv2.resize(mask_temp, self.image_size)\n",
        "            # Append processed image and mask\n",
        "            self.X_train.append(img_temp)\n",
        "            self.y_train.append(mask_temp)\n",
        "\n",
        "        # Transform into arrays\n",
        "        self.X_train = np.asarray(self.X_train)\n",
        "        self.y_train = np.asarray(self.y_train)\n",
        "        # If images were loaded as grayscale, they are loaded as (HxW) arrays\n",
        "        # Dimensions must be expanded for the model to be trained.\n",
        "        if self.grayscale:\n",
        "            self.X_train = np.expand_dims(self.X_train, -1)\n",
        "        # Mask must be expanded obligatorily, as they are 1-channel by default.\n",
        "        self.y_train = np.expand_dims(self.y_train, -1)\n",
        "\n",
        "        # Output information about training set.\n",
        "        print('Training set ready.')\n",
        "        print('X_train shape: {}'.format(self.X_train.shape))\n",
        "        print('y_train shape: {}'.format(self.y_train.shape))\n",
        "        print('X_train - min: {}, max: {}'.format(\n",
        "            np.min(self.X_train), np.max(self.X_train)))\n",
        "        print('y_train - min: {}, max: {}'.format(\n",
        "            np.min(self.y_train), np.max(self.y_train)))\n",
        "\n",
        "        # Load test data.\n",
        "        # Perform similar steps to the training processing part,\n",
        "        # but there are no masks to be loaded.\n",
        "        if self.load_test_data:\n",
        "            print('Loading test set.')\n",
        "            for i in tqdm(self.test_df.index):\n",
        "                img_src = '{}unzip_test/images/{}.png'.format(self.data_src, i)\n",
        "                if self.grayscale:\n",
        "                    img_temp = cv2.imread(img_src, 0)\n",
        "                else:\n",
        "                    img_temp = cv2.imread(img_src)\n",
        "                if self.orig_image_size != self.image_size:\n",
        "                    if self.pad_images:\n",
        "                        img_temp = self.__pad_image(img_temp)\n",
        "                    else:\n",
        "                        img_temp = cv2.resize(img_temp, self.image_size)\n",
        "                self.X_test.append(img_temp)\n",
        "\n",
        "            self.X_test = np.asarray(self.X_test)\n",
        "            if self.grayscale:\n",
        "                self.X_test = np.expand_dims(self.X_test, -1)\n",
        "\n",
        "            print('Test set ready.')\n",
        "            print('X_test shape: {}'.format(self.X_test.shape))\n",
        "            print('X_test - min: {}, max: {}'.format(\n",
        "                np.min(self.X_test), np.max(self.X_test)))\n",
        "\n",
        "            return self.X_train, self.y_train, self.X_test\n",
        "\n",
        "        return self.X_train, self.y_train\n",
        "\n",
        "    def compute_coverage(self):\n",
        "        \n",
        "        \"\"\"\n",
        "        Compute salt coverage of each mask. This will serve as a basis for \n",
        "        stratified split between training and validation sets.\n",
        "        \n",
        "        # Returns:\n",
        "            self.train_df: training DF containing coverage information.\n",
        "        \"\"\"\n",
        "\n",
        "        print('Compute mask coverage for each observation.')\n",
        "\n",
        "        def cov_to_class(val):\n",
        "            for i in range(0, 11):\n",
        "                if val * 10 <= i:\n",
        "                    return i\n",
        "\n",
        "        # Output percentage of area covered by class\n",
        "        self.train_df['coverage'] = np.mean(self.y_train / 255., axis=(1, 2))\n",
        "        # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "        # because each coverage will occur only once.\n",
        "        self.train_df['coverage_class'] = self.train_df.coverage.map(\n",
        "            cov_to_class)\n",
        "\n",
        "        return self.train_df\n",
        "\n",
        "    def predictions_rle_encode(self,\n",
        "                               y_pred_test,\n",
        "                               confidence_threshold_best):\n",
        "        \n",
        "        \"\"\"\n",
        "        Run Length Encoding of predictions.\n",
        "        This is needed for submission output.\n",
        "        \n",
        "        # Arguments:\n",
        "            y_pred_test: model predictions\n",
        "            confidence_threshold_best: confidence threshold, according to which\n",
        "                masks are set to 1/0.\n",
        "        # Returns:\n",
        "            y_test_pred_rle: RLEncoded predictions.\n",
        "        \"\"\"\n",
        "\n",
        "        # If images were padded, this padding must now be removed.\n",
        "        # Otherwise encoding method will fail to properly encode predictions and\n",
        "        # score will be bad.\n",
        "        if self.pad_images:\n",
        "            print('Remove padding from images.')\n",
        "            y_min_pad, y_max_pad, x_min_pad, x_max_pad = self.padding_pixels[\n",
        "                0], self.padding_pixels[1], self.padding_pixels[2], self.padding_pixels[3]\n",
        "            y_pred_test = y_pred_test[:, y_min_pad:-\n",
        "                                      y_max_pad, x_min_pad:-x_max_pad, 0]\n",
        "            \n",
        "        # Situation is similar for previously resized images.\n",
        "        # They must be resized again to their original size before encoding.\n",
        "        else:\n",
        "            y_pred_test = np.asarray([cv2.resize(x, self.orig_image_size)\n",
        "                                      for x in y_pred_test])\n",
        "\n",
        "        assert y_pred_test.shape == (18000, 101, 101), '\\\n",
        "        Test predictions shape must be equal to (18000, 101, 101).'\n",
        "\n",
        "        print('Test predictions shape: {}'.format(y_pred_test.shape))\n",
        "\n",
        "        # Perform mask predictions binarization and RLEncoding. \n",
        "        y_test_pred_rle = {idx:\n",
        "                           rle_encode(y_pred_test[i] > confidence_threshold_best)\n",
        "                           for i, idx in enumerate(\n",
        "                               tqdm(self.test_df.index.values))}\n",
        "\n",
        "        return y_test_pred_rle\n",
        "\n",
        "    def generate_submission(self, y_test_pred_rle):\n",
        "        \n",
        "        \"\"\"\n",
        "        Submission generation based on encoded model predictions.\n",
        "        \n",
        "        # Arguments:\n",
        "            y_test_pred_rle: RLEncoded predictions.\n",
        "        # Returns:\n",
        "            submission: generated submission.\n",
        "        \"\"\"\n",
        "\n",
        "        submission = pd.DataFrame.from_dict(y_test_pred_rle, orient='index')\n",
        "        submission.index.names = ['id']\n",
        "        submission.columns = ['rle_mask']\n",
        "\n",
        "        return submission\n",
        "\n",
        "    def return_padding_borders(self):\n",
        "        \"\"\"\n",
        "        Return padding borders in case intermediate operations on original images\n",
        "        are needed.\n",
        "        \n",
        "        # Returns:\n",
        "            self.padding_pixels: tuple of padding borders.\n",
        "        \"\"\"\n",
        "        return self.padding_pixels\n",
        "\n",
        "    def __pad_image(self, img):\n",
        "        \n",
        "        \"\"\"\n",
        "        Helper function for images padding.\n",
        "        \n",
        "        # Arguments:\n",
        "            img: image as np.array\n",
        "            \n",
        "        # Returns:\n",
        "            img: padded image as np.array\n",
        "        \"\"\"\n",
        "\n",
        "        pad_floor = np.floor(\n",
        "            (np.asarray(self.image_size) - np.asarray(self.orig_image_size)) / 2)\n",
        "        pad_ceil = np.ceil((np.asarray(self.image_size) -\n",
        "                            np.asarray(self.orig_image_size)) / 2)\n",
        "\n",
        "        self.padding_pixels = np.asarray(\n",
        "            (pad_floor[0], pad_ceil[0], pad_floor[1], pad_ceil[1])).astype(np.int32)\n",
        "\n",
        "        y_min_pad, y_max_pad, x_min_pad, x_max_pad = self.padding_pixels[\n",
        "            0], self.padding_pixels[1], self.padding_pixels[2], self.padding_pixels[3]\n",
        "\n",
        "        img = cv2.copyMakeBorder(img, y_min_pad, y_max_pad,\n",
        "                                 x_min_pad, x_max_pad,\n",
        "                                 cv2.BORDER_REFLECT_101)\n",
        "\n",
        "        assert img.shape[:2] == self.image_size, '\\\n",
        "        Image after padding must have the same shape as input image.'\n",
        "\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNfNIfUVxd-N"
      },
      "source": [
        "## Define helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sen5dvr9xOvP"
      },
      "source": [
        "# Quick RLEncoding needed for submission generation.\n",
        "# Source: another kernel, thanks!\n",
        "def rle_encode(im):\n",
        "    pixels = im.flatten(order='F')\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqZPFmg3xnfg"
      },
      "source": [
        "# 1. Initialize parameters:¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-clXuABxlRX",
        "outputId": "251af17d-6157-4218-d0e6-99476a09f706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Input dictionary for SaltParser\n",
        "salt_parameters = {\n",
        "    'data_src': '/content/drive/My Drive/unet/TGSSalt_data/',\n",
        "    'image_size': (128, 128),\n",
        "    'pad_images': False,\n",
        "    'grayscale': False,\n",
        "}\n",
        "\n",
        "salt_parser = SaltParser(**salt_parameters)\n",
        "\n",
        "normalize = True\n",
        "save = False\n",
        "\n",
        "\n",
        "# Automatic input_dim parameter specification\n",
        "# for model training.\n",
        "input_dim = salt_parameters['image_size']\n",
        "\n",
        "if salt_parameters['grayscale']:\n",
        "    input_dim = input_dim + (1,)\n",
        "else:\n",
        "    input_dim = input_dim + (3,)\n",
        "    \n",
        "# Run name\n",
        "run_name = '{}_grayscale{}_pad{}_size{}'.format(\n",
        "    'Unet',\n",
        "    int(salt_parameters['grayscale']),\n",
        "    int(salt_parameters['pad_images']),\n",
        "    input_dim[0])\n",
        "\n",
        "print('Run name: {}'.format(run_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run name: Unet_grayscale0_pad0_size128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZTJbMTjzx9R"
      },
      "source": [
        "# 2. Initialize and load data - call SaltParser functions:\n",
        "1. Initialize data.\n",
        "2. Load train and test set.\n",
        "3. Compute coverage for stratified split.\n",
        "4. Return padding pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEiwS37Tz4rN",
        "outputId": "70a76f47-7025-4fb6-e5d6-d06bc00a92a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "salt_parser.initialize_data()\n",
        "X_train, y_train, X_test = salt_parser.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading training set.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [18:11<00:00,  3.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training set ready.\n",
            "X_train shape: (4000, 128, 128, 3)\n",
            "y_train shape: (4000, 128, 128, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 40/18000 [00:00<00:45, 398.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X_train - min: 0, max: 255\n",
            "y_train - min: 0, max: 255\n",
            "Loading test set.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18000/18000 [00:48<00:00, 373.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set ready.\n",
            "X_test shape: (18000, 128, 128, 3)\n",
            "X_test - min: 0, max: 255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICeN3nK5uGMc",
        "outputId": "87755d6d-da56-4fdb-8cd7-80c9d6863b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/unet/TGSSalt_data/clean_workflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/unet/TGSSalt_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01fPxQ8sgmSj"
      },
      "source": [
        "import numpy as np\n",
        "np.save('X_train', X_train)\n",
        "np.save('y_train', y_train)\n",
        "np.save('X_test', X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I89CrNiIBozU",
        "outputId": "36fd7698-882d-468b-f8c3-9ac6948e8b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df = salt_parser.compute_coverage()\n",
        "padding_pixels = salt_parser.return_padding_borders()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compute mask coverage for each observation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1QfrIamut3C",
        "outputId": "d25c403c-373f-49a4-ce2a-93d1604ff1cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>z</th>\n",
              "      <th>coverage</th>\n",
              "      <th>coverage_class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>575d24d81d</th>\n",
              "      <td>843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a266a2a9df</th>\n",
              "      <td>794</td>\n",
              "      <td>0.504718</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75efad62c1</th>\n",
              "      <td>468</td>\n",
              "      <td>0.993332</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34e51dba6a</th>\n",
              "      <td>727</td>\n",
              "      <td>0.149254</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4875705fb0</th>\n",
              "      <td>797</td>\n",
              "      <td>0.042890</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              z  coverage  coverage_class\n",
              "id                                       \n",
              "575d24d81d  843  0.000000               0\n",
              "a266a2a9df  794  0.504718               6\n",
              "75efad62c1  468  0.993332              10\n",
              "34e51dba6a  727  0.149254               2\n",
              "4875705fb0  797  0.042890               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFIvtNsJvEVj"
      },
      "source": [
        "# 3. Normalize input data to 0-1 range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MyS2h3WlwqU",
        "outputId": "af64b9c6-64fc-4a7d-a64e-1ae61d34ff8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "if normalize:\n",
        "    # X_train, X_test = utils.normalize_along_channel(X_train, X_test)\n",
        "    X_train = X_train / 255.\n",
        "    y_train = y_train / 255.\n",
        "    X_test = X_test / 255.\n",
        "    print('X_train - min: {}, max: {}'.format(np.min(X_train), np.max(X_train)))\n",
        "    print('y_train - min: {}, max: {}'.format(np.min(y_train), np.max(y_train)))\n",
        "    print('Train set: {}, {}'.format(X_train.shape, y_train.shape))\n",
        "    print('X_test - min: {}, max: {}'.format(np.min(X_test), np.max(X_test)))\n",
        "    print('Test set: {}'.format(X_test.shape))\n",
        "    \n",
        "X_train = X_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train - min: 0.0, max: 1.0\n",
            "y_train - min: 0.0, max: 1.0\n",
            "Train set: (4000, 128, 128, 3), (4000, 128, 128, 1)\n",
            "X_test - min: 0.0, max: 1.0\n",
            "Test set: (18000, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYG6Y2cBvPsx"
      },
      "source": [
        "# 4. Perform stratified training/validation split based on coverage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGKkgmg2vKuv",
        "outputId": "94221108-7eea-481a-8533-3b4b5c7a2297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Perform 80/20 training/validation split based on stratified coverage.\n",
        "X_tr, X_val, y_tr, y_val, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    train_df.coverage.values,\n",
        "    train_df.z.values,\n",
        "    test_size=0.2, stratify=train_df.coverage_class, random_state=1234)\n",
        "\n",
        "\n",
        "del train_df\n",
        "gc.collect()\n",
        "\n",
        "del X_train, y_train\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAtZjex5vXSn"
      },
      "source": [
        "# 5. Define UNet model for training.\n",
        "Taken from another kernel, thanks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWTdc6NQvTNx"
      },
      "source": [
        "from keras import Model\n",
        "from keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,\n",
        "                          Conv2DTranspose, Dropout, Input, MaxPooling2D,\n",
        "                          UpSampling2D, concatenate)\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def conv_block(m, dim, acti, bn, res, do=0):\n",
        "    n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
        "    n = BatchNormalization()(n) if bn else n\n",
        "    n = Dropout(do)(n) if do else n\n",
        "    n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
        "    n = BatchNormalization()(n) if bn else n\n",
        "    return Concatenate()([m, n]) if res else n\n",
        "\n",
        "\n",
        "def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
        "    if depth > 0:\n",
        "        n = conv_block(m, dim, acti, bn, res)\n",
        "        m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
        "        m = level_block(m, int(inc * dim), depth - 1,\n",
        "                        inc, acti, do, bn, mp, up, res)\n",
        "        if up:\n",
        "            m = UpSampling2D()(m)\n",
        "            m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
        "        else:\n",
        "            m = Conv2DTranspose(dim, 3, strides=2,\n",
        "                                activation=acti, padding='same')(m)\n",
        "        n = Concatenate()([n, m])\n",
        "        m = conv_block(n, dim, acti, bn, res)\n",
        "    else:\n",
        "        m = conv_block(m, dim, acti, bn, res, do)\n",
        "    return m\n",
        "\n",
        "\n",
        "def UNet(params):\n",
        "\n",
        "    img_shape = params['input_dim']\n",
        "    out_ch = 1\n",
        "    start_ch = 8\n",
        "    depth = 3\n",
        "    inc_rate = 2.\n",
        "    activation = 'relu'\n",
        "    dropout = 0.5\n",
        "    batchnorm = False\n",
        "    maxpool = True\n",
        "    upconv = True\n",
        "    residual = False\n",
        "\n",
        "    i = Input(shape=img_shape)\n",
        "    o = level_block(i, start_ch, depth, inc_rate, activation,\n",
        "                    dropout, batchnorm, maxpool, upconv, residual)\n",
        "    o = Conv2D(out_ch, 1)(o)\n",
        "    # Sigmoid activation is used because model is trained with binary_crossentropy.\n",
        "    o =  Activation('sigmoid')(o)\n",
        "\n",
        "    model = Model(inputs=i, outputs=o)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQnGa5SIviIm"
      },
      "source": [
        "# 6. Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuUuabCZvdd6",
        "outputId": "f615f14d-3ec5-466b-ab8d-98646fdb7bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "model = UNet({'input_dim': input_dim})\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss' ,patience=12, verbose=1, mode='min')\n",
        "model_checkpoint = ModelCheckpoint(\"./{}.h5\".format(run_name),monitor='val_loss',\n",
        "                                   save_best_only=True, verbose=1, mode='min')\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',factor=0.33, patience=6, min_lr=1e-6, verbose=1, mode='min')\n",
        "\n",
        "epochs = 10  # change to more for better score!\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "history = model.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6401\n",
            "Epoch 00001: val_loss improved from inf to 0.00000, saving model to ./Unet_grayscale0_pad0_size128.h5\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.6401 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5409\n",
            "Epoch 00002: val_loss did not improve from 0.00000\n",
            "100/100 [==============================] - 33s 331ms/step - loss: 0.5409 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4610\n",
            "Epoch 00003: val_loss did not improve from 0.00000\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.4610 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3823\n",
            "Epoch 00004: val_loss did not improve from 0.00000\n",
            "100/100 [==============================] - 33s 327ms/step - loss: 0.3823 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3499\n",
            "Epoch 00005: val_loss did not improve from 0.00000\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.3499 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3386\n",
            "Epoch 00006: val_loss did not improve from 0.00000\n",
            "100/100 [==============================] - 33s 328ms/step - loss: 0.3386 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3208\n",
            "Epoch 00007: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00033000001567415896.\n",
            "100/100 [==============================] - 33s 325ms/step - loss: 0.3208 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2951\n",
            "Epoch 00008: val_loss did not improve from 0.00000\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.2951 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2823\n",
            "Epoch 00009: val_loss did not improve from 0.00000\n",
            "100/100 [==============================] - 32s 323ms/step - loss: 0.2823 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2725\n",
            "Epoch 00010: val_loss did not improve from 0.00000\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.2725 - val_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFK-10tGxBT5"
      },
      "source": [
        "# 7. Predict validation and test set masks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqNCAFB3xAcB",
        "outputId": "49d66fab-1069-4901-8e5a-84f99700ed2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_valid = model.predict(X_val)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "del X_tr, X_val, X_test\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2843"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enO-O1rwxE-l",
        "outputId": "1a1d0116-e908-422f-c686-b9763352e6ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "# Assume 0.5 threshold for mask binarization.\n",
        "# This can be optimized!\n",
        "y_pred_test_rle = salt_parser.predictions_rle_encode(\n",
        "    y_pred_test, confidence_threshold_best=0.5)\n",
        "\n",
        "submission = salt_parser.generate_submission(y_pred_test_rle)\n",
        "\n",
        "# Save submission with specified run_name.\n",
        "if save:\n",
        "    submission.to_csv('submission_{}.csv'.format(run_name))\n",
        "    \n",
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  6%|▋         | 1149/18000 [00:00<00:01, 11485.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test predictions shape: (18000, 101, 101)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 18000/18000 [00:01<00:00, 11441.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rle_mask</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>353e010b7b</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5439dbbddf</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71bab9f311</th>\n",
              "      <td>3301 4 3401 6 3502 7 3602 10 3703 11 3804 12 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52551f7a80</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512d8d9997</th>\n",
              "      <td>10 31 102 1 111 33 212 32 304 1 313 32 405 2 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>09f1675cfb</th>\n",
              "      <td>1213 1 1314 2 1415 17 1516 21 1617 24 1718 26 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6947dbc4f4</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68de95fb39</th>\n",
              "      <td>1 83 102 85 203 84 304 84 405 84 506 85 607 85...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fdad2f99d8</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d7c57f676e</th>\n",
              "      <td>8971 4 9069 8 9168 11 9269 10 9371 8 9473 6 95...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     rle_mask\n",
              "id                                                           \n",
              "353e010b7b                                                   \n",
              "5439dbbddf                                                   \n",
              "71bab9f311  3301 4 3401 6 3502 7 3602 10 3703 11 3804 12 3...\n",
              "52551f7a80                                                   \n",
              "512d8d9997  10 31 102 1 111 33 212 32 304 1 313 32 405 2 4...\n",
              "...                                                       ...\n",
              "09f1675cfb  1213 1 1314 2 1415 17 1516 21 1617 24 1718 26 ...\n",
              "6947dbc4f4                                                   \n",
              "68de95fb39  1 83 102 85 203 84 304 84 405 84 506 85 607 85...\n",
              "fdad2f99d8                                                   \n",
              "d7c57f676e  8971 4 9069 8 9168 11 9269 10 9371 8 9473 6 95...\n",
              "\n",
              "[18000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}