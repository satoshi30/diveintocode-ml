{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint ディープラーニングフレームワーク2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.このSprintについて\n",
    "\n",
    "### Sprintの目的\n",
    "- フレームワークのコードを読めるようにする\n",
    "- フレームワークを習得し続けられるようになる\n",
    "- 理論を知っている範囲をフレームワークで動かす\n",
    "\n",
    "### どのように学ぶか\n",
    "前半はTensorFlowのExampleを動かします。後半ではKerasのコードを書いていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.公式Example\n",
    "\n",
    "深層学習フレームワークには公式に様々なモデルのExampleコードが公開されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】公式チュートリアルモデルを分担して実行\n",
    "TensorFLowの公式チュートリアルモデルを分担して実行してください。\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。\n",
    "\n",
    "[models/tutorials at master · tensorflow/models](https://www.tensorflow.org/tutorials/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 実行したファイル\n",
    "[image segmentation](https://github.com/satoshi30/diveintocode-ml/blob/master/Sprint/Term2_DeepLearning/Sprint14/segmentation.ipynb)\n",
    "\n",
    "- ベースとなっているモデル　:  U-net [参考](https://qiita.com/hiro871_/items/871c76bf65b76ebe1dd0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】（アドバンス課題）様々な手法を実行\n",
    "TensorFLowやGoogle AI ResearchのGitHubリポジトリには、定番のモデルから最新のモデルまで多様なコードが公開されています。これらから興味あるものを選び実行してください。\n",
    "\n",
    "なお、これらのコードは初学者向けではないため、巨大なデータセットのダウンロードが必要な場合など、実行が簡単ではないこともあります。そういった場合は、コードリーディングを行ってください。\n",
    "\n",
    "[models/research at master · tensorflow/models](https://github.com/tensorflow/models/tree/master/research)\n",
    "\n",
    "[google-research/google-research: Google AI Research](https://github.com/google-research/google-research)\n",
    "\n",
    "更新日が古いものはPythonやTensorFlowのバージョンが古く、扱いずらい場合があります。新しいものから見ることを推奨します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.異なるフレームワークへの書き換え\n",
    "\n",
    "「ディープラーニングフレームワーク1」で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していきます。\n",
    "\n",
    "- Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "- Iris（3種類全ての目的変数を使用して多値分類）\n",
    "- House Prices\n",
    "- MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kerasへの書き換え\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用してください。\n",
    "\n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類がありますが、これは指定しません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】Iris（2値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# データセットの読み込み\n",
    "dataset_path =\"/Users/ikeda/Desktop/dive/diveintocode-ml/Downlowd_data/datasets_19_420_Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=n_hidden1, activation='relu', input_shape=(n_input, )))\n",
    "model.add(tf.keras.layers.Dense(units=n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=n_classes, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/10\n",
      "64/64 - 1s - loss: 0.8499 - accuracy: 0.5000 - val_loss: 0.6495 - val_accuracy: 0.6250\n",
      "Epoch 2/10\n",
      "64/64 - 0s - loss: 0.6270 - accuracy: 0.6250 - val_loss: 0.6629 - val_accuracy: 0.3750\n",
      "Epoch 3/10\n",
      "64/64 - 0s - loss: 0.5344 - accuracy: 0.8594 - val_loss: 0.4848 - val_accuracy: 0.9375\n",
      "Epoch 4/10\n",
      "64/64 - 0s - loss: 0.4704 - accuracy: 0.8438 - val_loss: 0.3865 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "64/64 - 0s - loss: 0.3624 - accuracy: 0.8438 - val_loss: 0.5847 - val_accuracy: 0.5625\n",
      "Epoch 6/10\n",
      "64/64 - 0s - loss: 0.3574 - accuracy: 0.8125 - val_loss: 0.4331 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "64/64 - 0s - loss: 0.3822 - accuracy: 0.7656 - val_loss: 0.2466 - val_accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "64/64 - 0s - loss: 0.2155 - accuracy: 0.9375 - val_loss: 0.1858 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "64/64 - 0s - loss: 0.1872 - accuracy: 0.9688 - val_loss: 0.1939 - val_accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "64/64 - 0s - loss: 0.1686 - accuracy: 0.9062 - val_loss: 0.1543 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"/Users/ikeda/Desktop/dive/diveintocode-ml/Downlowd_data/datasets_19_420_Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "# one_hotへ変換\n",
    "y = y.astype(np.int)\n",
    "y = np.identity(3)[y]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=n_hidden1, activation='relu', input_shape=(n_input, )))\n",
    "model.add(tf.keras.layers.Dense(units=n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/10\n",
      "96/96 - 1s - loss: 1.1383 - categorical_accuracy: 0.5104 - val_loss: 0.6494 - val_categorical_accuracy: 0.6250\n",
      "Epoch 2/10\n",
      "96/96 - 0s - loss: 0.4685 - categorical_accuracy: 0.7396 - val_loss: 0.5537 - val_categorical_accuracy: 0.7083\n",
      "Epoch 3/10\n",
      "96/96 - 0s - loss: 0.3417 - categorical_accuracy: 0.8646 - val_loss: 0.3111 - val_categorical_accuracy: 0.9167\n",
      "Epoch 4/10\n",
      "96/96 - 0s - loss: 0.2093 - categorical_accuracy: 0.9688 - val_loss: 0.2559 - val_categorical_accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "96/96 - 0s - loss: 0.1420 - categorical_accuracy: 0.9479 - val_loss: 0.4905 - val_categorical_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "96/96 - 0s - loss: 0.1708 - categorical_accuracy: 0.9271 - val_loss: 0.2164 - val_categorical_accuracy: 0.8333\n",
      "Epoch 7/10\n",
      "96/96 - 0s - loss: 0.1276 - categorical_accuracy: 0.9479 - val_loss: 0.4237 - val_categorical_accuracy: 0.7500\n",
      "Epoch 8/10\n",
      "96/96 - 0s - loss: 0.1744 - categorical_accuracy: 0.9271 - val_loss: 0.1863 - val_categorical_accuracy: 0.9583\n",
      "Epoch 9/10\n",
      "96/96 - 0s - loss: 0.1333 - categorical_accuracy: 0.9583 - val_loss: 0.2315 - val_categorical_accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "96/96 - 0s - loss: 0.0565 - categorical_accuracy: 0.9896 - val_loss: 0.3332 - val_categorical_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"/Users/ikeda/Desktop/dive/diveintocode-ml/Downlowd_data/train.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "objective_variable = 'SalePrice'\n",
    "features = ['GrLivArea', 'YearBuilt']\n",
    "\n",
    "y = df[objective_variable]\n",
    "X = df.loc[:, features]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# Xを標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_val = std.transform(X_val)\n",
    "X_test = std.transform(X_test)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定係数\n",
    "def det_coeff(y_true, y_pred):\n",
    "    u = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "    v = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
    "    return tf.ones_like(v) - (u / v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=n_hidden1, activation='relu', input_shape=(n_input, )))\n",
    "model.add(tf.keras.layers.Dense(units=n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=n_classes, activation=None))\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=[det_coeff])\n",
    "# metrics=['root_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 234 samples\n",
      "Epoch 1/10\n",
      "934/934 - 1s - loss: 38827281883.8201 - det_coeff: -9.4814e+00 - val_loss: 34994018198.9744 - val_det_coeff: -1.3406e+01\n",
      "Epoch 2/10\n",
      "934/934 - 0s - loss: 29377438700.2655 - det_coeff: -6.4400e+00 - val_loss: 15566800567.7949 - val_det_coeff: -5.3569e+00\n",
      "Epoch 3/10\n",
      "934/934 - 0s - loss: 7492828620.8822 - det_coeff: -9.9249e-01 - val_loss: 1812857825.9145 - val_det_coeff: -5.0133e-02\n",
      "Epoch 4/10\n",
      "934/934 - 0s - loss: 2201119140.7281 - det_coeff: 0.4967 - val_loss: 1524833123.2821 - val_det_coeff: 0.1043\n",
      "Epoch 5/10\n",
      "934/934 - 0s - loss: 2067460168.0857 - det_coeff: 0.5118 - val_loss: 1576759852.8547 - val_det_coeff: 0.0587\n",
      "Epoch 6/10\n",
      "934/934 - 0s - loss: 2068534473.5246 - det_coeff: 0.5608 - val_loss: 1553682203.8974 - val_det_coeff: 0.0868\n",
      "Epoch 7/10\n",
      "934/934 - 0s - loss: 2054300805.1392 - det_coeff: 0.4893 - val_loss: 1495899227.3504 - val_det_coeff: 0.1433\n",
      "Epoch 8/10\n",
      "934/934 - 0s - loss: 2035285872.9251 - det_coeff: 0.5601 - val_loss: 1509741257.0256 - val_det_coeff: 0.1273\n",
      "Epoch 9/10\n",
      "934/934 - 0s - loss: 2030335030.2013 - det_coeff: 0.5838 - val_loss: 1488253468.4444 - val_det_coeff: 0.1395\n",
      "Epoch 10/10\n",
      "934/934 - 0s - loss: 2030250580.8308 - det_coeff: 0.5240 - val_loss: 1479971859.4188 - val_det_coeff: 0.1459\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one_hotへ変換\n",
    "y_test = np.identity(10)[y_test]\n",
    "y_train = np.identity(10)[y_train]\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 400\n",
    "n_hidden2 = 200\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=n_hidden1, activation='relu', input_shape=(n_input, )))\n",
    "model.add(tf.keras.layers.Dense(units=n_hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 - 19s - loss: 0.3432 - categorical_accuracy: 0.9072 - val_loss: 0.3947 - val_categorical_accuracy: 0.9053\n",
      "Epoch 2/20\n",
      "48000/48000 - 17s - loss: 0.2369 - categorical_accuracy: 0.9395 - val_loss: 0.2170 - val_categorical_accuracy: 0.9412\n",
      "Epoch 3/20\n",
      "48000/48000 - 17s - loss: 0.1981 - categorical_accuracy: 0.9499 - val_loss: 0.2205 - val_categorical_accuracy: 0.9465\n",
      "Epoch 4/20\n",
      "48000/48000 - 17s - loss: 0.1917 - categorical_accuracy: 0.9536 - val_loss: 0.2210 - val_categorical_accuracy: 0.9473\n",
      "Epoch 5/20\n",
      "48000/48000 - 17s - loss: 0.1722 - categorical_accuracy: 0.9566 - val_loss: 0.2282 - val_categorical_accuracy: 0.9455\n",
      "Epoch 6/20\n",
      "48000/48000 - 17s - loss: 0.1557 - categorical_accuracy: 0.9621 - val_loss: 0.2195 - val_categorical_accuracy: 0.9535\n",
      "Epoch 7/20\n",
      "48000/48000 - 17s - loss: 0.1704 - categorical_accuracy: 0.9603 - val_loss: 0.2717 - val_categorical_accuracy: 0.9528\n",
      "Epoch 8/20\n",
      "48000/48000 - 17s - loss: 0.1444 - categorical_accuracy: 0.9667 - val_loss: 0.1763 - val_categorical_accuracy: 0.9622\n",
      "Epoch 9/20\n",
      "48000/48000 - 17s - loss: 0.1326 - categorical_accuracy: 0.9696 - val_loss: 0.1869 - val_categorical_accuracy: 0.9627\n",
      "Epoch 10/20\n",
      "48000/48000 - 18s - loss: 0.1375 - categorical_accuracy: 0.9685 - val_loss: 0.2135 - val_categorical_accuracy: 0.9567\n",
      "Epoch 11/20\n",
      "48000/48000 - 17s - loss: 0.1406 - categorical_accuracy: 0.9676 - val_loss: 0.2902 - val_categorical_accuracy: 0.9501\n",
      "Epoch 12/20\n",
      "48000/48000 - 18s - loss: 0.1401 - categorical_accuracy: 0.9693 - val_loss: 0.2025 - val_categorical_accuracy: 0.9593\n",
      "Epoch 13/20\n",
      "48000/48000 - 17s - loss: 0.1314 - categorical_accuracy: 0.9705 - val_loss: 0.1992 - val_categorical_accuracy: 0.9623\n",
      "Epoch 14/20\n",
      "48000/48000 - 17s - loss: 0.1267 - categorical_accuracy: 0.9718 - val_loss: 0.2879 - val_categorical_accuracy: 0.9565\n",
      "Epoch 15/20\n",
      "48000/48000 - 17s - loss: 0.1425 - categorical_accuracy: 0.9693 - val_loss: 0.2829 - val_categorical_accuracy: 0.9588\n",
      "Epoch 16/20\n",
      "48000/48000 - 17s - loss: 0.1303 - categorical_accuracy: 0.9718 - val_loss: 0.3010 - val_categorical_accuracy: 0.9557\n",
      "Epoch 17/20\n",
      "48000/48000 - 17s - loss: 0.1142 - categorical_accuracy: 0.9746 - val_loss: 0.2264 - val_categorical_accuracy: 0.9663\n",
      "Epoch 18/20\n",
      "48000/48000 - 17s - loss: 0.1328 - categorical_accuracy: 0.9731 - val_loss: 0.3041 - val_categorical_accuracy: 0.9645\n",
      "Epoch 19/20\n",
      "48000/48000 - 18s - loss: 0.1220 - categorical_accuracy: 0.9736 - val_loss: 0.2544 - val_categorical_accuracy: 0.9541\n",
      "Epoch 20/20\n",
      "48000/48000 - 775s - loss: 0.1288 - categorical_accuracy: 0.9705 - val_loss: 0.2909 - val_categorical_accuracy: 0.9627\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】（アドバンス課題）PyTorchへの書き換え\n",
    "4種類の問題をPyTorchに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iris（2値分類）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# データセットの読み込み\n",
    "dataset_path =\"/Users/ikeda/Desktop/dive/diveintocode-ml/Downlowd_data/datasets_19_420_Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "# y = y.astype(np.int)[:, np.newaxis]\n",
    "y = y.astype(np.int)\n",
    "# one_hotへ変換\n",
    "# y = y.astype(np.int)\n",
    "# y = np.identity(2)[y]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形を直してバッチ情報を取得\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "loader_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=4, out_features=50, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを構築\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(n_input, n_hidden1))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2', nn.Linear(n_hidden1, n_hidden2))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('fc3', nn.Linear(n_hidden2, n_classes))\n",
    "# model.add_module('softmax', nn.Softmax(dim=1))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法のパラメータ設定\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# loss関数の定義\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 95.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, total_loss : 0.5134, val_loss : 0.7451, total_acc : 0.328, val_acc : 0.375\n",
      "Epoch 2, total_loss : 0.5000, val_loss : 0.7484, total_acc : 0.391, val_acc : 0.375\n",
      "Epoch 3, total_loss : 0.4937, val_loss : 0.8357, total_acc : 0.562, val_acc : 0.375\n",
      "Epoch 4, total_loss : 0.4877, val_loss : 0.7096, total_acc : 0.531, val_acc : 0.375\n",
      "Epoch 5, total_loss : 0.4749, val_loss : 0.7153, total_acc : 0.562, val_acc : 0.375\n",
      "Epoch 6, total_loss : 0.4792, val_loss : 0.6879, total_acc : 0.562, val_acc : 0.375\n",
      "Epoch 7, total_loss : 0.4752, val_loss : 0.6758, total_acc : 0.547, val_acc : 0.438\n",
      "Epoch 8, total_loss : 0.4558, val_loss : 0.6781, total_acc : 0.547, val_acc : 0.375\n",
      "Epoch 9, total_loss : 0.4503, val_loss : 0.7378, total_acc : 0.578, val_acc : 0.375\n",
      "Epoch 10, total_loss : 0.4662, val_loss : 0.6315, total_acc : 0.562, val_acc : 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# バッチ正規化等、学習時と推論時で振る舞いの違うモジュールの振る舞いを学習時の振る舞いに\n",
    "# model.eval()で推論時の振る舞いに変更可能\n",
    "model.train()\n",
    "# 学習ループ\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "    total_acc = 0\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    # ミニバッチ毎ににループ\n",
    "    for mini_batch_x, mini_batch_y in loader_train:    \n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        # 順伝播\n",
    "        out = model(mini_batch_x)\n",
    "        # 推論する\n",
    "        pred = out.data.max(1)[1] # 出力ラベルを求める\n",
    "        correct = pred.eq(mini_batch_y.data).sum()  # 正解と一緒だったらカウントアップ\n",
    "        # print(pred, correct)\n",
    "        total_correct += correct\n",
    "        # print(total_correct)\n",
    "        # ロスの計算\n",
    "        loss = criterion(out, mini_batch_y)\n",
    "        total_loss += loss\n",
    "        # print(total_loss)\n",
    "        # 勾配の計算\n",
    "        loss.backward()\n",
    "        # パラメータの更新\n",
    "        optimizer.step()\n",
    "    total_loss /= batch_size\n",
    "    # print(total_loss)\n",
    "    total_acc = total_correct.numpy() / n_samples\n",
    "    # print(total_acc)\n",
    "    val_out = model(X_val)\n",
    "    val_pred = val_out.data.max(1, keepdim=True)[1] # 出力ラベルを求める\n",
    "    val_correct = val_pred.eq(y_val.data.view_as(val_pred)).sum()  # 正解と一緒だったらカウントアップ\n",
    "    val_acc = val_correct.numpy() / len(y_val.data)\n",
    "    \n",
    "    val_loss = criterion(val_out, y_val)\n",
    "    print(\"Epoch {}, total_loss : {:.4f}, val_loss : {:.4f}, total_acc : {:.3f}, val_acc : {:.3f}\".format(epoch, total_loss, val_loss, total_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iris（多値分類）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"/Users/ikeda/Desktop/dive/diveintocode-ml/Downlowd_data/datasets_19_420_Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "# one_hotへ変換\n",
    "y = y.astype(np.int)\n",
    "# y = np.identity(3)[y]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形を直してバッチ情報を取得\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "loader_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=4, out_features=50, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを構築\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(n_input, n_hidden1))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2', nn.Linear(n_hidden1, n_hidden2))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('fc3', nn.Linear(n_hidden2, n_classes))\n",
    "# model.add_module('softmax', nn.Softmax(dim=1))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法のパラメータ設定\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# loss関数の定義\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, total_loss : 1.0747, val_loss : 0.9629, total_acc : 0.323, val_acc : 0.708\n",
      "Epoch 2, total_loss : 0.9345, val_loss : 0.8792, total_acc : 0.667, val_acc : 0.708\n",
      "Epoch 3, total_loss : 0.8560, val_loss : 0.8118, total_acc : 0.688, val_acc : 0.708\n",
      "Epoch 4, total_loss : 0.7930, val_loss : 0.7471, total_acc : 0.688, val_acc : 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 85.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, total_loss : 0.7210, val_loss : 0.6952, total_acc : 0.771, val_acc : 0.708\n",
      "Epoch 6, total_loss : 0.6774, val_loss : 0.6443, total_acc : 0.688, val_acc : 0.708\n",
      "Epoch 7, total_loss : 0.6282, val_loss : 0.5983, total_acc : 0.740, val_acc : 0.708\n",
      "Epoch 8, total_loss : 0.5849, val_loss : 0.5635, total_acc : 0.844, val_acc : 0.708\n",
      "Epoch 9, total_loss : 0.5556, val_loss : 0.5533, total_acc : 0.760, val_acc : 0.875\n",
      "Epoch 10, total_loss : 0.5232, val_loss : 0.5175, total_acc : 0.844, val_acc : 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# バッチ正規化等、学習時と推論時で振る舞いの違うモジュールの振る舞いを学習時の振る舞いに\n",
    "# model.eval()で推論時の振る舞いに変更可能\n",
    "model.train()\n",
    "# 学習ループ\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "    total_acc = 0\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    # ミニバッチ毎ににループ\n",
    "    for mini_batch_x, mini_batch_y in loader_train:    \n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        # 順伝播\n",
    "        out = model(mini_batch_x)\n",
    "        # 推論する\n",
    "        pred = out.data.max(1)[1] # 出力ラベルを求める\n",
    "        correct = pred.eq(mini_batch_y.data).sum()  # 正解と一緒だったらカウントアップ\n",
    "        # print(pred, correct)\n",
    "        total_correct += correct\n",
    "        # print(total_correct)\n",
    "        # ロスの計算\n",
    "        loss = criterion(out, mini_batch_y)\n",
    "        total_loss += loss\n",
    "        # print(total_loss)\n",
    "        # 勾配の計算\n",
    "        loss.backward()\n",
    "        # パラメータの更新\n",
    "        optimizer.step()\n",
    "    total_loss /= batch_size\n",
    "    # print(total_loss)\n",
    "    total_acc = total_correct.numpy() / n_samples\n",
    "    # print(total_acc)\n",
    "    val_out = model(X_val)\n",
    "    val_pred = val_out.data.max(1, keepdim=True)[1] # 出力ラベルを求める\n",
    "    val_correct = val_pred.eq(y_val.data.view_as(val_pred)).sum()  # 正解と一緒だったらカウントアップ\n",
    "    val_acc = val_correct.numpy() / len(y_val.data)\n",
    "    \n",
    "    val_loss = criterion(val_out, y_val)\n",
    "    print(\"Epoch {}, total_loss : {:.4f}, val_loss : {:.4f}, total_acc : {:.3f}, val_acc : {:.3f}\".format(epoch, total_loss, val_loss, total_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"/Users/ikeda/Desktop/dive/diveintocode-ml/Downlowd_data/train.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "objective_variable = 'SalePrice'\n",
    "features = ['GrLivArea', 'YearBuilt']\n",
    "\n",
    "y = df[objective_variable]\n",
    "X = df.loc[:, features]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# yを対数変換\n",
    "y = np.log(y.astype(np.int))[:, np.newaxis]\n",
    "# y = y.astype(np.int)[:, np.newaxis]\n",
    "# y = y.astype(np.int)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# Xを標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_val = std.transform(X_val)\n",
    "X_test = std.transform(X_test)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形を直してバッチ情報を取得\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "# y_train = torch.from_numpy(y_train).long()\n",
    "# y_val = torch.from_numpy(y_val).long()\n",
    "# y_test = torch.from_numpy(y_test).long()\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "loader_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=2, out_features=50, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを構築\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(n_input, n_hidden1))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2', nn.Linear(n_hidden1, n_hidden2))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('fc3', nn.Linear(n_hidden2, n_classes))\n",
    "# model.add_module('softmax', nn.Softmax(dim=1))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法のパラメータ設定\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# loss関数の定義\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:00, 12.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, total_loss : 42.7535, val_loss : 0.5321\n",
      "Epoch 2, total_loss : 1.8718, val_loss : 0.1161\n",
      "Epoch 3, total_loss : 1.2452, val_loss : 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, total_loss : 1.2874, val_loss : 0.1148\n",
      "Epoch 5, total_loss : 1.1050, val_loss : 0.0480\n",
      "Epoch 6, total_loss : 1.0781, val_loss : 0.0542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:00<00:00, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, total_loss : 0.9775, val_loss : 0.1483\n",
      "Epoch 8, total_loss : 1.0708, val_loss : 0.1925\n",
      "Epoch 9, total_loss : 1.0640, val_loss : 0.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, total_loss : 1.4285, val_loss : 0.3231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# バッチ正規化等、学習時と推論時で振る舞いの違うモジュールの振る舞いを学習時の振る舞いに\n",
    "# model.eval()で推論時の振る舞いに変更可能\n",
    "model.train()\n",
    "# 学習ループ\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "    total_loss = 0\n",
    "    # ミニバッチ毎ににループ\n",
    "    for mini_batch_x, mini_batch_y in loader_train:    \n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        # 順伝播\n",
    "        out = model(mini_batch_x)\n",
    "        # print(out)\n",
    "        # ロスの計算\n",
    "        loss = criterion(out, mini_batch_y)\n",
    "        total_loss += loss\n",
    "        # print(total_loss)\n",
    "        # 勾配の計算\n",
    "        loss.backward()\n",
    "        # パラメータの更新\n",
    "        optimizer.step()\n",
    "    total_loss /= batch_size\n",
    "    # print(total_loss)\n",
    "    val_out = model(X_val)\n",
    "    val_loss = criterion(val_out, y_val)\n",
    "    print(\"Epoch {}, total_loss : {:.4f}, val_loss : {:.4f}\".format(epoch, total_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目的変数を対数変換しないと、lossがうまく計算できなかった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one_hotへ変換\n",
    "# y_test = np.identity(10)[y_test]\n",
    "# y_train = np.identity(10)[y_train]\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "n_hidden1 = 400\n",
    "n_hidden2 = 200\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形を直してバッチ情報を取得\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "loader_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc3): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを構築\n",
    "model = nn.Sequential()\n",
    "model.add_module('fc1', nn.Linear(n_input, n_hidden1))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('fc2', nn.Linear(n_hidden1, n_hidden2))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('fc3', nn.Linear(n_hidden2, n_classes))\n",
    "# model.add_module('softmax', nn.Softmax(dim=1))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法のパラメータ設定\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# loss関数の定義\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:04<01:31,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, total_loss : 111.0736, val_loss : 0.3660, total_acc : 0.768, val_acc : 0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:09<01:26,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, total_loss : 40.4212, val_loss : 0.2862, total_acc : 0.904, val_acc : 0.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:14<01:20,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, total_loss : 33.1764, val_loss : 0.2397, total_acc : 0.921, val_acc : 0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:18<01:14,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, total_loss : 28.2078, val_loss : 0.2081, total_acc : 0.932, val_acc : 0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:23<01:10,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, total_loss : 24.1683, val_loss : 0.1814, total_acc : 0.943, val_acc : 0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:28<01:05,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, total_loss : 20.9727, val_loss : 0.1599, total_acc : 0.950, val_acc : 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:32<01:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, total_loss : 18.4093, val_loss : 0.1501, total_acc : 0.956, val_acc : 0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:36<00:54,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, total_loss : 16.2708, val_loss : 0.1315, total_acc : 0.961, val_acc : 0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [00:41<00:50,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, total_loss : 14.4316, val_loss : 0.1218, total_acc : 0.966, val_acc : 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [00:45<00:44,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, total_loss : 12.9549, val_loss : 0.1151, total_acc : 0.969, val_acc : 0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [00:50<00:41,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, total_loss : 11.6627, val_loss : 0.1044, total_acc : 0.972, val_acc : 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [00:55<00:36,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, total_loss : 10.5718, val_loss : 0.1013, total_acc : 0.975, val_acc : 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [00:59<00:31,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, total_loss : 9.5997, val_loss : 0.0986, total_acc : 0.977, val_acc : 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [01:03<00:26,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, total_loss : 8.7394, val_loss : 0.0938, total_acc : 0.979, val_acc : 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [01:08<00:22,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, total_loss : 8.0232, val_loss : 0.0872, total_acc : 0.981, val_acc : 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [01:12<00:17,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, total_loss : 7.2745, val_loss : 0.0858, total_acc : 0.983, val_acc : 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [01:17<00:13,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, total_loss : 6.7424, val_loss : 0.0820, total_acc : 0.985, val_acc : 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [01:21<00:08,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, total_loss : 6.1616, val_loss : 0.0793, total_acc : 0.986, val_acc : 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [01:24<00:03,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, total_loss : 5.6674, val_loss : 0.0778, total_acc : 0.987, val_acc : 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:27<00:00,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, total_loss : 5.2431, val_loss : 0.0765, total_acc : 0.989, val_acc : 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# バッチ正規化等、学習時と推論時で振る舞いの違うモジュールの振る舞いを学習時の振る舞いに\n",
    "# model.eval()で推論時の振る舞いに変更可能\n",
    "model.train()\n",
    "# 学習ループ\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "    total_acc = 0\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    # ミニバッチ毎ににループ\n",
    "    for mini_batch_x, mini_batch_y in loader_train:    \n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        # 順伝播\n",
    "        out = model(mini_batch_x)\n",
    "        # 推論する\n",
    "        pred = out.data.max(1)[1] # 出力ラベルを求める\n",
    "        correct = pred.eq(mini_batch_y.data).sum()  # 正解と一緒だったらカウントアップ\n",
    "        # print(pred, correct)\n",
    "        total_correct += correct\n",
    "        # print(total_correct)\n",
    "        # ロスの計算\n",
    "        loss = criterion(out, mini_batch_y)\n",
    "        total_loss += loss\n",
    "        # print(total_loss)\n",
    "        # 勾配の計算\n",
    "        loss.backward()\n",
    "        # パラメータの更新\n",
    "        optimizer.step()\n",
    "    total_loss /= batch_size\n",
    "    # print(total_loss)\n",
    "    total_acc = total_correct.numpy() / n_samples\n",
    "    # print(total_acc)\n",
    "    val_out = model(X_val)\n",
    "    val_pred = val_out.data.max(1, keepdim=True)[1] # 出力ラベルを求める\n",
    "    val_correct = val_pred.eq(y_val.data.view_as(val_pred)).sum()  # 正解と一緒だったらカウントアップ\n",
    "    val_acc = val_correct.numpy() / len(y_val.data)\n",
    "    \n",
    "    val_loss = criterion(val_out, y_val)\n",
    "    print(\"Epoch {}, total_loss : {:.4f}, val_loss : {:.4f}, total_acc : {:.3f}, val_acc : {:.3f}\".format(epoch, total_loss, val_loss, total_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】（アドバンス課題）フレームワークの比較\n",
    "それぞれのフレームワークにはどのような違いがあるかをまとめてください。\n",
    "\n",
    "*《視点例》*\n",
    "\n",
    "- 計算速度\n",
    "- コードの行数・可読性\n",
    "- 用意されている機能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ThensorFlow\n",
    "    - ハイレベルな機能を実装可能で、計算をデータフローやグラフで表すことができまるため、実践で、複雑な問題に対処できる\n",
    "    - Googleの音声検索や言語翻訳、画像検索に使用\n",
    "-　Keras\n",
    "    - 比較的短いコードで実装可能、最新手法を素早く試すことができる\n",
    "    - CPUとGPU上でシームレスな動作\n",
    "- Chainer\n",
    "    - 記法がシンプルで国産のフレームワークのため、学習が容易\n",
    "    - 画像分類や物体検出などで利用されている\n",
    "    - 2019年12月に開発を終了し、PyTorchへ移行\n",
    "- PyTorch\n",
    "    - Chainer, Numpyと似たような構文で操作可能\n",
    "    - 計算速度も早く、ソースコードが扱いやすい\n",
    "    - 計算グラフを動的で構築可能\n",
    "- MXNet\n",
    "    - 命令的プラグラムと宣言的プログラムを併用することができ、柔軟なフレームワーク\n",
    "    - CNN、LSTM、RCNN、Deep Q Networkなど様々な深層学習モデルをサポートしており、画像認識、自然言語処理、レコメンデーションなど様々な場面で使われている\n",
    "- Deeplearning4j（DL4j）\n",
    "    - Javaで開発されているため、JVM上で動くという特徴があり、既存の情報システムと組み合わせ運用できます。そのため、商用に使われやすく、サポートが提供されているということが利点\n",
    "    - Javaでディープラーニングを行う際に利用されており、例えば、金融分野の不正検知や異常検知、電子商取引や広告のレコメンドシステム、 製造業の不良品検知や画像認識などで使用されている\n",
    "- Microsoft Cognitive Toolkit\n",
    "    - 巨大データセット処理時のパフォーマンス低下を最小化するためのアルゴリズムが組み込まれているため、複数マシンで巨大データセットを扱う場合において、他のツールキットに対する優位性があるとされている\n",
    "    - Skypeのリアルタイム翻訳、国内では三井住友銀行が自動応答システムで利用している\n",
    "- PaddlePaddle\n",
    "    - クラウドだけでなく、分散コンピューティングのクラスタで高速に稼働する\n",
    "    - 中国で強い\n",
    "- Caffe\n",
    "    - C++で実装され、GPUに対応しているため、高速な計算処理が可能\n",
    "    - 開発コミュニティーが活発にGitHubを更新していたり、サンプルコードも多く提供されているため、初心者にもおすすめ\n",
    "    - 大規模画像認識のコンテスト「ILSVRC」で2012年に首位を獲得した「畳み込みニューラルネットワークの画像分類モデル」があり、直ぐに利用できるというのも利点"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3-2020.02)",
   "language": "python",
   "name": "conda_anaconda3-2020.02"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
