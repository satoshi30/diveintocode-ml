{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprint17_Problem4-5.ipynb のコピー",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmWZ7zgwpo4Q",
        "outputId": "15d1f04f-fa74-4cd1-92a6-eb4e968724ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install tensorflow==1.5.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/79/a37d0b373757b4d283c674a64127bd8864d69f881c639b1ee5953e2d9301/tensorflow-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (44.4MB)\n",
            "\u001b[K     |████████████████████████████████| 44.4MB 94kB/s \n",
            "\u001b[?25hCollecting tensorflow-tensorboard<1.6.0,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/fa/91c06952517b4f1bc075545b062a4112e30cebe558a6b962816cb33efa27/tensorflow_tensorboard-1.5.1-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 61.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.5.0) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (1.0.1)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 64.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (3.2.2)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.5.0) (50.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5.0) (3.1.0)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=3066359236e0ff6fc1f5051e27bb3b6a2745251338d2aab062b8b5baf8f66a54\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "Installing collected packages: html5lib, bleach, tensorflow-tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.2.0\n",
            "    Uninstalling bleach-3.2.0:\n",
            "      Successfully uninstalled bleach-3.2.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorflow-1.5.0 tensorflow-tensorboard-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUu9m_KWmamn",
        "outputId": "12feeece-d065-4991-c1c4-20d0ccf975af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRZTehf2taXo",
        "outputId": "28577858-419c-4e87-e5a7-00f6e280c03d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!pip install keras==2.2.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl (300kB)\n",
            "\r\u001b[K     |█                               | 10kB 20.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 92kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 215kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 225kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 235kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 245kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 256kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 266kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 276kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 286kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 296kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.0) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.0) (2.10.0)\n",
            "Collecting keras-preprocessing==1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/33/275506afe1d96b221f66f95adba94d1b73f6b6087cfb6132a5655b6fe338/Keras_Preprocessing-1.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.0) (1.15.0)\n",
            "Collecting keras-applications==1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/60/c557075e586e968d7a9c314aa38c236b37cb3ee6b37e8d57152b1a5e0b47/Keras_Applications-1.0.2-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.0) (1.18.5)\n",
            "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.0 keras-applications-1.0.2 keras-preprocessing-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N8BGzsmtmZD",
        "outputId": "e6424506-ae28-48c4-f834-6288007404da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNBShcRWR-Dx",
        "outputId": "e028946b-f03f-42d2-a980-9cc13e93a800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 自分のマイドライブにマウントする\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bajxyWdd8Hs",
        "outputId": "8160a294-70bb-493e-df2b-3984d2df5059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# カレントディレクトリの変更\n",
        "%cd /content/drive/My Drive/keras-yolo3"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/keras-yolo3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ImkjD0nJmye",
        "outputId": "2009cc4c-cb59-4e30-9b58-9c5e48d1934c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# ディレクトリを作成\n",
        "%mkdir simpson_annotation"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘simpson_annotation’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgNUBTYRKjua",
        "outputId": "25bd18f2-dc0b-4a07-dc2e-2362f285cf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# カレントディレクトリの変更\n",
        "%cd simpson_annotation"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/keras-yolo3/simpson_annotation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFk2SHgWUM6Q",
        "outputId": "d8dd3d7a-743f-41ee-afa0-0bac6732baa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# simposonのannotationデータをコピーする\n",
        "%cp -i /content/drive/\"My Drive\"/ObjectDetection/annotation.txt simpson_annotation.txt"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: overwrite 'simpson_annotation.txt'? ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx1cDMlsaz15",
        "outputId": "deec37aa-6986-43a7-d896-f3b3f9343d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import pandas as pd\n",
        "annotation_df = pd.read_csv(\"simpson_annotation.txt\", header=None)\n",
        "annotation_df.head()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>57</td>\n",
              "      <td>72</td>\n",
              "      <td>52</td>\n",
              "      <td>72</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>80</td>\n",
              "      <td>31</td>\n",
              "      <td>337</td>\n",
              "      <td>354</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>128</td>\n",
              "      <td>48</td>\n",
              "      <td>285</td>\n",
              "      <td>407</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>72</td>\n",
              "      <td>126</td>\n",
              "      <td>158</td>\n",
              "      <td>275</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>123</td>\n",
              "      <td>61</td>\n",
              "      <td>294</td>\n",
              "      <td>416</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  ...                       5\n",
              "0  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  abraham_grampa_simpson\n",
              "1  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  abraham_grampa_simpson\n",
              "2  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  abraham_grampa_simpson\n",
              "3  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  abraham_grampa_simpson\n",
              "4  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  abraham_grampa_simpson\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5icz13PhLP_v",
        "outputId": "2b04da91-f4cd-4cde-fa67-6e6364c65052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import os\n",
        "# annotation_df['path'] = '/content/drive/\"My Drive\"/ObjectDetection/' + annotation_df[0]\n",
        "path_lst = [os.path.join('../ObjectDetection', old_path) for old_path in annotation_df[0]]\n",
        "annotation_df['path'] = path_lst\n",
        "annotation_df.head()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>57</td>\n",
              "      <td>72</td>\n",
              "      <td>52</td>\n",
              "      <td>72</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>80</td>\n",
              "      <td>31</td>\n",
              "      <td>337</td>\n",
              "      <td>354</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>128</td>\n",
              "      <td>48</td>\n",
              "      <td>285</td>\n",
              "      <td>407</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>72</td>\n",
              "      <td>126</td>\n",
              "      <td>158</td>\n",
              "      <td>275</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>simpsons_dataset/abraham_grampa_simpson/pic_00...</td>\n",
              "      <td>123</td>\n",
              "      <td>61</td>\n",
              "      <td>294</td>\n",
              "      <td>416</td>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  ...                                               path\n",
              "0  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  ../ObjectDetection/simpsons_dataset/abraham_gr...\n",
              "1  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  ../ObjectDetection/simpsons_dataset/abraham_gr...\n",
              "2  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  ../ObjectDetection/simpsons_dataset/abraham_gr...\n",
              "3  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  ../ObjectDetection/simpsons_dataset/abraham_gr...\n",
              "4  simpsons_dataset/abraham_grampa_simpson/pic_00...  ...  ../ObjectDetection/simpsons_dataset/abraham_gr...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSRTZrayMqhF",
        "outputId": "73c6d09c-27a4-4c02-ec88-076972fb0c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "#LabelEncoderのインスタンスを生成\n",
        "le = LabelEncoder()\n",
        "#ラベルを覚えさせる\n",
        "le = le.fit(annotation_df[5])\n",
        "#ラベルを整数に変換\n",
        "annotation_df['label'] = le.transform(annotation_df[5])\n",
        "annotation_df['label'].value_counts()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    756\n",
              "7     718\n",
              "0     687\n",
              "14    675\n",
              "3     650\n",
              "2     650\n",
              "11    629\n",
              "16    614\n",
              "9     429\n",
              "13    403\n",
              "15    219\n",
              "8     213\n",
              "6     212\n",
              "12    210\n",
              "4     209\n",
              "5     208\n",
              "1     206\n",
              "17    201\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sbY-YCVTEb-",
        "outputId": "45bdf1b1-4483-433f-d2a3-071078cfe295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "le.classes_"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['abraham_grampa_simpson', 'apu_nahasapeemapetilon', 'bart_simpson',\n",
              "       'charles_montgomery_burns', 'chief_wiggum', 'comic_book_guy',\n",
              "       'edna_krabappel', 'homer_simpson', 'kent_brockman',\n",
              "       'krusty_the_clown', 'lisa_simpson', 'marge_simpson',\n",
              "       'milhouse_van_houten', 'moe_szyslak', 'ned_flanders',\n",
              "       'nelson_muntz', 'principal_skinner', 'sideshow_bob'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI97uAOoRx1Z",
        "outputId": "40e71e1a-b4b2-4a0b-9cea-598a2f6ee77d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "simpson_classes_df = pd.DataFrame(le.classes_)\n",
        "simpson_classes_df"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abraham_grampa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apu_nahasapeemapetilon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bart_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>charles_montgomery_burns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chief_wiggum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>comic_book_guy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>edna_krabappel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>homer_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>kent_brockman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>krusty_the_clown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lisa_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>marge_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>milhouse_van_houten</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>moe_szyslak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ned_flanders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>nelson_muntz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>principal_skinner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>sideshow_bob</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           0\n",
              "0     abraham_grampa_simpson\n",
              "1     apu_nahasapeemapetilon\n",
              "2               bart_simpson\n",
              "3   charles_montgomery_burns\n",
              "4               chief_wiggum\n",
              "5             comic_book_guy\n",
              "6             edna_krabappel\n",
              "7              homer_simpson\n",
              "8              kent_brockman\n",
              "9           krusty_the_clown\n",
              "10              lisa_simpson\n",
              "11             marge_simpson\n",
              "12       milhouse_van_houten\n",
              "13               moe_szyslak\n",
              "14              ned_flanders\n",
              "15              nelson_muntz\n",
              "16         principal_skinner\n",
              "17              sideshow_bob"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhO0pxl6Tp4S"
      },
      "source": [
        "simpson_classes_df.to_csv('simpson_classes.txt', sep='\\t', index=False, header=False)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L05LRXK9NVCf",
        "outputId": "9bde4811-01d3-46f3-e632-307e8ac2a888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "annotation_df['box_info'] = annotation_df[1].astype(str)+','+annotation_df[2].astype(str)+','+annotation_df[3].astype(str)+','+annotation_df[4].astype(str)+','+annotation_df['label'].astype(str)\n",
        "annotation_df[['path', 'box_info']].head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>box_info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "      <td>57,72,52,72,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "      <td>80,31,337,354,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "      <td>128,48,285,407,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "      <td>72,126,158,275,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>../ObjectDetection/simpsons_dataset/abraham_gr...</td>\n",
              "      <td>123,61,294,416,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path          box_info\n",
              "0  ../ObjectDetection/simpsons_dataset/abraham_gr...     57,72,52,72,0\n",
              "1  ../ObjectDetection/simpsons_dataset/abraham_gr...   80,31,337,354,0\n",
              "2  ../ObjectDetection/simpsons_dataset/abraham_gr...  128,48,285,407,0\n",
              "3  ../ObjectDetection/simpsons_dataset/abraham_gr...  72,126,158,275,0\n",
              "4  ../ObjectDetection/simpsons_dataset/abraham_gr...  123,61,294,416,0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH0fV22vO9NR"
      },
      "source": [
        "annotation_df[['path', 'box_info']].to_csv('simpson_annotation_edit.txt', sep='\\t', index=False, header=False)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ehw6vB_ZLx-",
        "outputId": "a37cf2a1-e9c0-4bab-a18b-3a00a893e168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd -"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/keras-yolo3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MyQ87ouZdJD",
        "outputId": "ff11b153-1fec-4e69-c762-7587b5818bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python convert.py -w yolov3.cfg yolov3.weights model_data/yolo_weights.h5"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "Loading weights.\n",
            "Weights Header:  0 2 0 [32013312]\n",
            "Parsing Darknet config.\n",
            "Creating Keras model.\n",
            "Parsing section net_0\n",
            "Parsing section convolutional_0\n",
            "conv2d bn leaky (3, 3, 3, 32)\n",
            "2020-09-27 11:50:04.302617: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "Parsing section convolutional_1\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section convolutional_2\n",
            "conv2d bn leaky (1, 1, 64, 32)\n",
            "Parsing section convolutional_3\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section shortcut_0\n",
            "Parsing section convolutional_4\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section convolutional_5\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_6\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_1\n",
            "Parsing section convolutional_7\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_8\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_2\n",
            "Parsing section convolutional_9\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_10\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_11\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_3\n",
            "Parsing section convolutional_12\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_13\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_4\n",
            "Parsing section convolutional_14\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_15\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_5\n",
            "Parsing section convolutional_16\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_17\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_6\n",
            "Parsing section convolutional_18\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_19\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_7\n",
            "Parsing section convolutional_20\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_21\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_8\n",
            "Parsing section convolutional_22\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_23\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_9\n",
            "Parsing section convolutional_24\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_25\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_10\n",
            "Parsing section convolutional_26\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_27\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_28\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_11\n",
            "Parsing section convolutional_29\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_30\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_12\n",
            "Parsing section convolutional_31\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_32\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_13\n",
            "Parsing section convolutional_33\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_34\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_14\n",
            "Parsing section convolutional_35\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_36\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_15\n",
            "Parsing section convolutional_37\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_38\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_16\n",
            "Parsing section convolutional_39\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_40\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_17\n",
            "Parsing section convolutional_41\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_42\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_18\n",
            "Parsing section convolutional_43\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_44\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_45\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_19\n",
            "Parsing section convolutional_46\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_47\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_20\n",
            "Parsing section convolutional_48\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_49\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_21\n",
            "Parsing section convolutional_50\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_51\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_22\n",
            "Parsing section convolutional_52\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_53\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_54\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_55\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_56\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_57\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_58\n",
            "conv2d    linear (1, 1, 1024, 255)\n",
            "Parsing section yolo_0\n",
            "Parsing section route_0\n",
            "Parsing section convolutional_59\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section upsample_0\n",
            "Parsing section route_1\n",
            "Concatenating route layers: [<tf.Tensor 'up_sampling2d_1/ResizeNearestNeighbor:0' shape=(?, ?, ?, 256) dtype=float32>, <tf.Tensor 'add_19/add:0' shape=(?, ?, ?, 512) dtype=float32>]\n",
            "Parsing section convolutional_60\n",
            "conv2d bn leaky (1, 1, 768, 256)\n",
            "Parsing section convolutional_61\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_62\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_63\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_64\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_65\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_66\n",
            "conv2d    linear (1, 1, 512, 255)\n",
            "Parsing section yolo_1\n",
            "Parsing section route_2\n",
            "Parsing section convolutional_67\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section upsample_1\n",
            "Parsing section route_3\n",
            "Concatenating route layers: [<tf.Tensor 'up_sampling2d_2/ResizeNearestNeighbor:0' shape=(?, ?, ?, 128) dtype=float32>, <tf.Tensor 'add_11/add:0' shape=(?, ?, ?, 256) dtype=float32>]\n",
            "Parsing section convolutional_68\n",
            "conv2d bn leaky (1, 1, 384, 128)\n",
            "Parsing section convolutional_69\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_70\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_71\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_72\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_73\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_74\n",
            "conv2d    linear (1, 1, 256, 255)\n",
            "Parsing section yolo_2\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 6 18432       zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 3 2048        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 3 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 6 0           leaky_re_lu_2[0][0]              \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 1 73728       zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 6 8192        leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 1 0           leaky_re_lu_5[0][0]              \n",
            "                                                                 leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 8192        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 1 0           add_2[0][0]                      \n",
            "                                                                 leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, None, None, 1 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 2 294912      zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 2 0           leaky_re_lu_10[0][0]             \n",
            "                                                                 leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 1 32768       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n",
            "                                                                 leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 1 32768       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 1 512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
            "                                                                 leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 1 32768       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 1 512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 2 1024        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n",
            "                                                                 leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 1 32768       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 1 512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 1 32768       add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n",
            "                                                                 leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 1 32768       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 1 512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 2 1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n",
            "                                                                 leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 1 32768       add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 1 512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 2 1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 2 0           add_10[0][0]                     \n",
            "                                                                 leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, None, None, 2 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 5 1179648     zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 5 0           leaky_re_lu_27[0][0]             \n",
            "                                                                 leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 2 131072      add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 2 1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n",
            "                                                                 leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 2 131072      add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 2 1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n",
            "                                                                 leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 2 131072      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 2 1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n",
            "                                                                 leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 2 131072      add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 2 1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n",
            "                                                                 leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 2 131072      add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 2 1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n",
            "                                                                 leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 2 131072      add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 2 1024        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 5 2048        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n",
            "                                                                 leaky_re_lu_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 2 131072      add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 5 2048        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, None, None, 5 0           add_18[0][0]                     \n",
            "                                                                 leaky_re_lu_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, None, None, 5 0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 1 4718592     zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 1 4096        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 5 2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 1 4096        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, None, None, 1 0           leaky_re_lu_44[0][0]             \n",
            "                                                                 leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 5 524288      add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 5 2048        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 1 4096        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n",
            "                                                                 leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 5 524288      add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 5 2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 1 4096        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n",
            "                                                                 leaky_re_lu_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 5 524288      add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 5 2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 1 4096        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, None, None, 1 0           add_22[0][0]                     \n",
            "                                                                 leaky_re_lu_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, None, None, 5 524288      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, None, None, 5 2048        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_53 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, None, None, 1 4096        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_54 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, None, None, 5 2048        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_55 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, None, None, 1 4096        conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_56 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, None, None, 5 2048        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_57 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, None, None, 2 1024        conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_59 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, None, None, 2 196608      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, None, None, 2 1024        conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, None, None, 5 2048        conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_61 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, None, None, 2 1024        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_62 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, None, None, 5 2048        conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_63 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, None, None, 2 1024        conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_64 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, None, None, 1 512         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, None, None, 1 49152       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, None, None, 1 512         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, None, None, 2 1024        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, None, None, 1 512         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_69 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, None, None, 2 1024        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_70 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, None, None, 1 512         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_71 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, None, None, 1 4096        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, None, None, 5 2048        conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, None, None, 2 1024        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_58 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, None, None, 2 261375      leaky_re_lu_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, None, None, 2 130815      leaky_re_lu_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, None, None, 2 65535       leaky_re_lu_72[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Saved Keras weights to model_data/yolo_weights.h5\n",
            "Read 62001757 of 62001757.0 from Darknet weights.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zwO0jQsbNsw",
        "outputId": "77153678-8e7e-4120-cfc3-bb0be2c32c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# annotation_path, classes_pathを作成したファイルに書き換えて実行\n",
        "!python train.py"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "2020-09-27 12:40:54.058978: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "Create YOLOv3 model with 9 anchors and 18 classes.\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1009: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 69) vs (255, 1024, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1009: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((69,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1009: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 69) vs (255, 512, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1009: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((69,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1009: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 69) vs (255, 256, 1, 1)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1009: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((69,) vs (255,)).\n",
            "  weight_values[i].shape))\n",
            "Load weights model_data/yolo_weights.h5.\n",
            "Freeze the first 249 layers of total 252 layers.\n",
            "Train on 7101 samples, val on 788 samples, with batch size 32.\n",
            "Epoch 1/50\n",
            "tcmalloc: large alloc 1594982400 bytes == 0x2faaac000 @  0x7fd42f08c1e7 0x7fd3c00b61bf 0x7fd3c1da3db9 0x7fd3c1db07cd 0x7fd3c1ddca39 0x7fd3c1ddcf0f 0x7fd3c1ddec39 0x7fd41af638ec 0x7fd41af2f3a0 0x7fd41af1e130 0x7fd41abd2b02 0x7fd41abd1bb2 0x7fd42d96ea50 0x7fd42ea506db 0x7fd42ed89a3f\n",
            "tcmalloc: large alloc 1594982400 bytes == 0x2faaac000 @  0x7fd42f08c1e7 0x7fd3c00b61bf 0x7fd3c1da3db9 0x7fd3c1db07cd 0x7fd3c1ddca39 0x7fd3c1ddcf0f 0x7fd3c1ddec39 0x7fd41af638ec 0x7fd41af2f3a0 0x7fd41af1e130 0x7fd41abd2b02 0x7fd41abd1bb2 0x7fd42d96ea50 0x7fd42ea506db 0x7fd42ed89a3f\n",
            "  1/221 [..............................] - ETA: 26:50:44 - loss: 7772.6313tcmalloc: large alloc 1594982400 bytes == 0x2faaac000 @  0x7fd42f08c1e7 0x7fd3c00b61bf 0x7fd3c1da3db9 0x7fd3c1db07cd 0x7fd3c1ddca39 0x7fd3c1ddcf0f 0x7fd3c1ddec39 0x7fd41af638ec 0x7fd41af2f3a0 0x7fd41af1e130 0x7fd41abd2b02 0x7fd41abd1bb2 0x7fd42d96ea50 0x7fd42ea506db 0x7fd42ed89a3f\n",
            "tcmalloc: large alloc 1594982400 bytes == 0x2faaac000 @  0x7fd42f08c1e7 0x7fd3c00b61bf 0x7fd3c1da3db9 0x7fd3c1db07cd 0x7fd3c1ddca39 0x7fd3c1ddcf0f 0x7fd3c1ddec39 0x7fd41af638ec 0x7fd41af2f3a0 0x7fd41af1e130 0x7fd41abd2b02 0x7fd41abd1bb2 0x7fd42d96ea50 0x7fd42ea506db 0x7fd42ed89a3f\n",
            "221/221 [==============================] - 3183s 14s/step - loss: 405.1315 - val_loss: 53.9141\n",
            "Epoch 2/50\n",
            "221/221 [==============================] - 2470s 11s/step - loss: 43.2412 - val_loss: 33.0432\n",
            "Epoch 3/50\n",
            " 18/221 [=>............................] - ETA: 34:01 - loss: 34.0909Traceback (most recent call last):\n",
            "  File \"train.py\", line 192, in <module>\n",
            "    _main()\n",
            "  File \"train.py\", line 67, in _main\n",
            "    callbacks=[logging, checkpoint])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1426, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\", line 191, in fit_generator\n",
            "    class_weight=class_weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1220, in train_on_batch\n",
            "    outputs = self.train_function(ins)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2667, in __call__\n",
            "    return self._legacy_call(inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2649, in _legacy_call\n",
            "    **self.session_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 895, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1128, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1344, in _do_run\n",
            "    options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1329, in _run_fn\n",
            "    status, run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHCbBC75QSoC"
      },
      "source": [
        "- １epochに30m程時間がかかる"
      ]
    }
  ]
}