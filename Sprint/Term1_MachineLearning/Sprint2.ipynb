{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スクラッチの意義\n",
    "ここでのスクラッチとは、NumPyなどの基本的なライブラリを組み合わせることで、scikit-learnのような応用的なライブラリと同じ機能のクラス・関数を自作することを指します。\n",
    "\n",
    "スクラッチをすることでscikit-learnなどのライブラリを動かすだけでは掴みづらい、アルゴリズムの深い理解を目指します。コーディングのスキル向上も兼ねますが、それは主な目的ではありません。\n",
    "\n",
    "以下のような効果を狙っています。\n",
    "\n",
    "- 新たな手法に出会った時に理論・数式を理解しやすくする\n",
    "- ライブラリを使う上での曖昧さを減らす\n",
    "- 既存の実装を読みやすくする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_splitのスクラッチ\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil, floor\n",
    "import random\n",
    "def scratch_train_test_split(X, y, train_size=0.8,):\n",
    "    \"\"\"\n",
    "    検証データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      訓練データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    if type(X) != np.ndarray :\n",
    "        raise TypeError(\"Type of X input must be numpy.array\")\n",
    "    elif type(y) != np.ndarray:\n",
    "        raise TypeError(\"Type of y input must be numpy.array\")\n",
    "    elif len(X) == 0 or len(y) == 0:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    elif X.shape[0] != y.shape[0]:\n",
    "        raise SyntaxError('The number of rows in the array must be match')\n",
    "    elif type(train_size) != float:\n",
    "        raise TypeError(\"Type of train_size input must be float\")\n",
    "    elif train_size >= 1 or train_size <= 0:\n",
    "        raise ValueError('Value of train_size must be between 0 and 1')\n",
    "    n_samples = len(X)\n",
    "    n_train = int(floor(train_size * n_samples))\n",
    "    n_test = int(n_samples - n_train)\n",
    "    if n_train == 0:\n",
    "        raise ValueError(\n",
    "            'With n_samples={}, test_size={} and train_size={}, the '\n",
    "            'resulting train set will be empty. Adjust any of the '\n",
    "            'aforementioned parameters.'.format(n_samples, test_size,\n",
    "                                                train_size)\n",
    "        )\n",
    "    index_lst = [i for i in range(n_samples)]\n",
    "    test_index = random.sample(index_lst, n_test)\n",
    "    train_index = list(set(index_lst)-set(test_index))\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 60  61  62  63  64  65  66  67  68  69]\n",
      " [130 131 132 133 134 135 136 137 138 139]\n",
      " [120 121 122 123 124 125 126 127 128 129]] [ 6 13 12]\n",
      "12 3 12 3\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(150).reshape(15, -1)\n",
    "y = np.arange(15)\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8)\n",
    "print(X_test, y_test)\n",
    "print(len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20  21  22  23  24  25  26  27  28  29]\n",
      " [  0   1   2   3   4   5   6   7   8   9]\n",
      " [120 121 122 123 124 125 126 127 128 129]] [ 2  0 12]\n",
      "12 3 12 3\n"
     ]
    }
   ],
   "source": [
    "# sklearn で確認\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "print(X_test, y_test)\n",
    "print(len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類問題\n",
    "分類は3種類の手法をスクラッチします。\n",
    "\n",
    "- ロジスティック回帰\n",
    "- SVM\n",
    "- 決定木\n",
    "\n",
    "ロジスティック回帰はscikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数で`loss=\"log\"`とすることでロジスティック回帰の計算になります。\n",
    "\n",
    "- [sklearn.linear_model.SGDClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)\n",
    "- [sklearn.svm.SVC — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "- [sklearn.tree.DecisionTreeClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "\n",
    "データセットは3種類用意します。\n",
    "\n",
    "1つ目は事前学習期間同様にirisデータセットです。\n",
    "\n",
    "[sklearn.datasets.load_iris — scikit-learn 0.20.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "\n",
    "- virgicolorとvirginica\n",
    "\n",
    "残り2つは特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数`X`,目的変数`y`が作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "data = load_iris()\n",
    "names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "iris_df = pd.DataFrame(data.data, columns=names)\n",
    "iris_df['Species'] = data.target\n",
    "iris_df_choice = iris_df[(iris_df['Species'] == 1) | (iris_df['Species'] == 2)]\n",
    "X = iris_df_choice.iloc[:, 0:4].values\n",
    "y = iris_df_choice.iloc[:, -1].values\n",
    "iris_data = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット1作成コード\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data1 = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット2作成コード\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_data2 = X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰（勾配降下法）\n",
    "def scratch_SGDClassifier(X, y, loss='log'):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "    from sklearn.linear_model import SGDClassifier \n",
    "    clf = SGDClassifier(loss=loss)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def scratch_SVC(X, y):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "    from sklearn.svm import SVC\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木\n",
    "def scratch_DecisionTreeClassifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰（勾配降下法）\n",
      "[1 1 1 1 2 2 2 2 2 1 2 1 2 1 2 2 2 2 2 1]\n",
      "SVM\n",
      "[1 1 2 2 1 1 2 2 1 1 1 1 2 1 2 1 1 2 1 2]\n",
      "決定木\n",
      "[1 1 1 1 2 2 1 1 2 2 1 2 1 1 2 1 2 2 2 1]\n",
      "ロジスティック回帰（勾配降下法）\n",
      "[-1  1 -1  1  1  1  1  1 -1 -1  1 -1 -1  1  1  1  1 -1  1 -1 -1  1  1 -1\n",
      "  1 -1 -1  1  1  1 -1 -1  1 -1 -1 -1  1  1  1  1 -1 -1 -1  1  1  1  1  1\n",
      "  1  1 -1 -1 -1 -1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1\n",
      "  1  1  1  1  1  1 -1  1  1  1 -1  1  1  1 -1  1 -1  1  1  1 -1  1 -1 -1\n",
      " -1  1  1  1]\n",
      "SVM\n",
      "[-1  1  1  1  1 -1  1  1 -1  1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1\n",
      "  1  1 -1  1  1 -1  1  1  1  1 -1  1  1 -1  1  1  1 -1  1 -1 -1  1  1 -1\n",
      "  1 -1 -1 -1  1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1 -1 -1 -1\n",
      "  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1  1  1  1 -1  1 -1  1  1 -1  1  1  1\n",
      "  1  1 -1 -1]\n",
      "決定木\n",
      "[ 1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1  1 -1  1  1  1  1 -1  1  1 -1  1 -1\n",
      "  1 -1 -1  1  1 -1  1 -1  1 -1 -1  1  1  1 -1  1  1  1  1 -1 -1  1 -1  1\n",
      " -1 -1 -1 -1 -1  1  1  1 -1 -1 -1 -1 -1 -1  1 -1  1  1  1  1 -1  1  1 -1\n",
      "  1 -1  1  1  1 -1  1 -1 -1 -1 -1  1 -1 -1  1  1  1  1 -1  1 -1  1 -1 -1\n",
      " -1  1 -1 -1]\n",
      "ロジスティック回帰（勾配降下法）\n",
      "[1 1 1 0 1 0 1 1]\n",
      "SVM\n",
      "[0 1 1 1 0 1 0 0]\n",
      "決定木\n",
      "[0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "data_lst = [iris_data, simple_data1, simple_data2]\n",
    "for data in data_lst:\n",
    "    print('ロジスティック回帰（勾配降下法）', scratch_SGDClassifier(*data), sep='\\n')\n",
    "    print('SVM', scratch_SVC(*data), sep='\\n')\n",
    "    print('決定木', scratch_DecisionTreeClassifier(*data), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回帰問題\n",
    "回帰は1種類をスクラッチします。\n",
    "\n",
    "- 線形回帰\n",
    "\n",
    "線形回帰は勾配降下法を用いて計算するSGDRegressorクラスを利用してください。\n",
    "\n",
    "[sklearn.linear_model.SGDRegressor — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "`train.csv`をダウンロードし、目的変数として`SalePrice`、説明変数として、`GrLivArea`と`YearBuilt`を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_columns\", 80)\n",
    "df = pd.read_csv('/Users/ikeda/Desktop/dive/diveintocode-ml/Downlowd_data/house-prices-advanced-regression-techniques/train.csv', index_col= 'Id')\n",
    "X = df.loc[:, ['GrLivArea', 'YearBuilt']].values\n",
    "y = df.loc[:, 'SalePrice'].values\n",
    "House_Prices_data = X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形回帰（勾配降下法）\n",
    "def scratch_SGDRegressor(X, y):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "    from sklearn.linear_model import SGDRegressor\n",
    "    clf = SGDRegressor()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰（勾配降下法）\n",
      "[-4.08035173e+14 -1.98411503e+14 -1.51888807e+14 -2.09604425e+14\n",
      " -8.28500515e+13 -2.81505074e+14 -3.54552446e+14 -2.34426776e+14\n",
      " -1.74623508e+14 -1.22166687e+14 -3.50744941e+14 -6.65906776e+13\n",
      " -7.81352728e+13 -3.71193697e+14 -2.04092556e+14 -4.56424060e+14\n",
      " -2.28820846e+14 -9.80417331e+13 -3.51274247e+14 -9.54304105e+13\n",
      " -2.13802888e+14 -2.06572256e+14 -2.84613774e+14 -2.67503942e+14\n",
      " -2.49799223e+14 -7.80166403e+13 -2.72400894e+14 -9.37913109e+13\n",
      " -1.98067187e+14 -1.64998787e+14 -6.77176861e+13 -8.62121384e+13\n",
      " -2.16013395e+14 -2.37291170e+14 -2.01461203e+14 -4.27482910e+14\n",
      " -3.12325090e+14 -9.98008734e+13 -3.66180929e+14 -2.19534492e+14\n",
      " -1.76925259e+14 -1.05835007e+14 -2.02831109e+14 -1.82576108e+14\n",
      " -2.54430114e+14 -1.73791672e+14 -2.67723676e+14 -2.18654922e+14\n",
      " -8.78772176e+13 -2.62744245e+14 -3.01431565e+14 -1.86046654e+14\n",
      " -3.38754612e+14 -1.95053641e+14 -1.52007439e+14 -2.57469640e+14\n",
      " -3.67721743e+14 -1.53263254e+14 -2.13404889e+14 -1.00097455e+14\n",
      " -3.10936245e+14 -7.02037024e+14  1.50400182e+13 -2.68733461e+14\n",
      " -2.16811894e+14 -1.72282787e+14 -2.15210356e+14 -1.90473617e+14\n",
      " -1.15575544e+14 -4.22982233e+14 -1.77557391e+14 -7.80166403e+13\n",
      " -1.88900874e+14 -8.96798679e+13 -1.78327094e+14 -2.39727361e+14\n",
      " -1.45212368e+14 -1.53263254e+14 -4.84287346e+14 -3.55176128e+14\n",
      " -1.34877260e+14 -3.29886605e+14 -2.65177619e+14 -2.16574629e+14\n",
      " -2.04377556e+14 -2.57627242e+14 -4.52117138e+14 -2.00244358e+14\n",
      " -1.22356218e+14 -1.19041865e+14 -2.57102161e+14 -7.87877513e+13\n",
      " -1.59605550e+14 -2.87595392e+14 -2.60632023e+14 -2.69207990e+14\n",
      " -7.25669035e+13 -1.46918140e+14 -1.57067942e+14 -1.56479320e+14\n",
      " -2.78348324e+14 -2.18469932e+14 -1.58992041e+14 -7.83104050e+13\n",
      " -1.11582733e+14  4.00533077e+13 -1.17440327e+14 -3.90506995e+14\n",
      " -2.14757581e+14 -8.84935432e+13 -2.38334291e+14 -1.27739281e+14\n",
      " -7.92377098e+13 -2.58482241e+14 -5.32132279e+13 -2.18488555e+14\n",
      " -1.56615167e+14 -1.35599229e+14 -4.95519237e+14 -2.53253712e+13\n",
      " -2.64023222e+14 -5.86064648e+13 -2.92687823e+14 -1.41860454e+14\n",
      " -2.21976631e+14 -4.50514192e+14 -3.50511901e+14 -8.96798679e+13\n",
      " -2.67699105e+14 -1.98627013e+14 -1.85812206e+14 -2.27073287e+14\n",
      " -1.05894324e+14 -2.51638026e+14 -1.35574657e+14 -2.36365274e+14\n",
      " -1.28639198e+14 -1.52182571e+14 -2.20531287e+14 -1.87175071e+14\n",
      " -3.88141702e+14 -1.88449508e+14 -2.20966847e+14 -2.84602192e+14\n",
      " -2.98947640e+14 -2.30800037e+14 -3.03785276e+14 -2.68121675e+14\n",
      " -7.31354945e+13 -4.32096586e+14 -2.25706197e+14 -2.48148542e+14\n",
      " -1.82926057e+14 -1.61432772e+14 -2.32006392e+14 -1.09279574e+14\n",
      " -2.04554096e+14 -3.16304911e+14 -5.45646919e+14 -8.20789404e+13\n",
      " -1.83267556e+14 -4.05556881e+14 -1.77949442e+14 -1.40350160e+14\n",
      " -3.58530858e+14 -1.18152122e+14 -1.23995317e+14 -1.37666532e+14\n",
      " -3.20533578e+14 -5.43402364e+13 -6.63477798e+13 -1.50505911e+14\n",
      " -3.09391207e+14 -2.20496542e+14 -2.07393918e+14 -2.53041269e+14\n",
      " -2.14973091e+14 -3.91646993e+14 -2.07095929e+14 -1.80118163e+14\n",
      " -3.81227998e+14 -2.73138668e+14 -2.21030388e+14 -2.57068825e+14\n",
      " -2.36686426e+14 -2.48629021e+14 -2.40517410e+14 -2.62687745e+14\n",
      " -2.62770224e+14 -3.22956778e+14 -2.81823094e+14 -2.04306658e+14\n",
      " -1.68896128e+14 -2.87332147e+14 -8.47871405e+13 -1.49483137e+14\n",
      " -2.60771003e+14 -3.06289548e+14 -4.37663231e+14 -1.19041865e+14\n",
      " -2.21380653e+14 -2.09292038e+14 -4.14346949e+14 -1.04017959e+14\n",
      " -3.63125596e+14 -7.81352728e+13 -6.65906776e+13 -6.52661515e+14\n",
      " -1.63265627e+14 -7.25075873e+13 -8.95250824e+13 -2.64849109e+14\n",
      " -4.36701182e+14 -2.86562444e+14 -1.60259437e+14 -5.12221213e+14\n",
      " -2.83764724e+14 -1.63980238e+14 -1.05942058e+14 -1.73043724e+14\n",
      " -8.73868815e+13 -8.91460218e+13 -1.51731205e+14 -3.17196062e+14\n",
      " -1.44342971e+14 -2.98505039e+14 -7.80759565e+13 -2.83423224e+14\n",
      " -2.82271644e+14 -4.64285416e+14 -2.43989364e+14 -2.59444291e+14\n",
      " -3.21828362e+14 -2.70167224e+14 -4.51914618e+14 -2.17051976e+14\n",
      " -2.84670274e+14 -8.30280002e+13 -1.70556983e+14 -4.75530298e+14\n",
      " -2.85474721e+14 -2.28846826e+14 -7.80759565e+13 -1.87309509e+14\n",
      " -3.16575512e+14 -2.26490995e+13 -1.28044627e+14 -6.38189366e+13\n",
      " -2.54799001e+14 -2.09613191e+14 -1.87580111e+14 -3.83800351e+14\n",
      " -1.04480907e+14 -1.60386835e+14 -1.90699300e+14 -2.71168243e+14\n",
      " -3.11920050e+14 -2.87437790e+14 -2.98642294e+14 -2.67733850e+14\n",
      " -2.66820943e+14 -2.66820943e+14 -2.52602893e+14 -1.70130188e+14\n",
      " -2.54526992e+14 -2.37019160e+14 -1.33715507e+14 -2.10518740e+14\n",
      " -2.55056613e+14 -1.09730940e+14 -1.53912916e+14 -2.86999413e+14\n",
      " -2.19083126e+14 -1.89803608e+14 -3.66677214e+14 -2.89908725e+14\n",
      " -2.29697600e+14 -2.40805226e+14 -2.29034948e+14 -1.96627791e+14\n",
      " -2.46710554e+14 -1.40519344e+14 -3.24976347e+14 -3.85067431e+14\n",
      " -1.86331654e+14 -2.18970442e+14 -8.46685080e+13 -1.81260977e+14\n",
      " -1.86189858e+14 -2.29244825e+14 -1.53151978e+14 -1.94774590e+14]\n"
     ]
    }
   ],
   "source": [
    "print('線形回帰（勾配降下法）', scratch_SGDRegressor(*House_Prices_data), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
